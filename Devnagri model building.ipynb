{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "317d5d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense,Embedding\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cea73b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14531bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.json', 'r', encoding='utf8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c1697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words = []\n",
    "output_words = []\n",
    "for key in data:\n",
    "    input_words.append(key.lower())\n",
    "    output_words.append(data[key][0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8641fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_chars = sorted(list(set(''.join(input_words))))\n",
    "input_char_indices = dict((c, i) for i, c in enumerate(input_chars))\n",
    "input_indices_char = dict((i, c) for i, c in enumerate(input_chars))\n",
    "\n",
    "output_chars = sorted(list(set(''.join(output_words))))\n",
    "output_char_indices = dict((c, i) for i, c in enumerate(output_chars))\n",
    "output_indices_char = dict((i, c) for i, c in enumerate(output_chars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d885c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8f69191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12937"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56857725",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input_char_indices.json1', 'w') as f:\n",
    "    json.dump(input_char_indices, f)\n",
    "\n",
    "with open('output_char_indices.json1', 'w') as f:\n",
    "    json.dump(output_char_indices, f)\n",
    "\n",
    "with open('input_indices_char.json1', 'w') as f:\n",
    "    json.dump(input_indices_char, f)\n",
    "\n",
    "with open('output_indices_char.json1', 'w') as f:\n",
    "    json.dump(output_indices_char, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50665735",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max([len(word) for word in input_words])\n",
    "max_decoder_seq_length = max([len(word) for word in output_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb7763cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_decoder_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a6e4071",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_encoder_seq_length = max([len(word) for word in input_words])\n",
    "max_decoder_seq_length = max([len(word) for word in output_words])\n",
    "\n",
    "encoder_input_data = np.zeros((len(input_words), max_encoder_seq_length, len(input_chars)), dtype='float32')\n",
    "decoder_input_data = np.zeros((len(input_words), max_decoder_seq_length, len(output_chars)), dtype='float32')\n",
    "decoder_target_data = np.zeros((len(input_words), max_decoder_seq_length, len(output_chars)), dtype='float32')\n",
    "\n",
    "for i, (input_word, output_word) in enumerate(zip(input_words, output_words)):\n",
    "    for t, char in enumerate(input_word):\n",
    "        encoder_input_data[i, t, input_char_indices[char]] = 1.\n",
    "    for t, char in enumerate(output_word):\n",
    "        decoder_input_data[i, t, output_char_indices[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, output_char_indices[char]] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "836634b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 50\n",
    "latent_dim = 256\n",
    "\n",
    "encoder_inputs = Input(shape=(None, len(input_chars)))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, len(output_chars)))\n",
    "decoder = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(output_chars), activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "190c0687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Batch: 1 Loss: 0.4850185811519623\n",
      "Batch: 65 Loss: 0.5584812760353088\n",
      "Batch: 129 Loss: 0.4856483042240143\n",
      "Batch: 193 Loss: 0.7069913148880005\n",
      "Batch: 257 Loss: 0.470507949590683\n",
      "Batch: 321 Loss: 0.457257479429245\n",
      "Batch: 385 Loss: 0.4632970094680786\n",
      "Batch: 449 Loss: 0.40953290462493896\n",
      "Batch: 513 Loss: 0.431883841753006\n",
      "Batch: 577 Loss: 0.4343436658382416\n",
      "Batch: 641 Loss: 0.5240647792816162\n",
      "Batch: 705 Loss: 0.44022560119628906\n",
      "Batch: 769 Loss: 0.5230588316917419\n",
      "Batch: 833 Loss: 0.36939725279808044\n",
      "Batch: 897 Loss: 0.6504051685333252\n",
      "Batch: 961 Loss: 0.3948502242565155\n",
      "Batch: 1025 Loss: 0.4375607371330261\n",
      "Batch: 1089 Loss: 0.421008437871933\n",
      "Batch: 1153 Loss: 0.4713257849216461\n",
      "Batch: 1217 Loss: 0.43104884028434753\n",
      "Batch: 1281 Loss: 0.46846911311149597\n",
      "Batch: 1345 Loss: 0.4768661558628082\n",
      "Batch: 1409 Loss: 0.40034762024879456\n",
      "Batch: 1473 Loss: 0.44411081075668335\n",
      "Batch: 1537 Loss: 0.41657957434654236\n",
      "Batch: 1601 Loss: 0.35593700408935547\n",
      "Batch: 1665 Loss: 0.3959711194038391\n",
      "Batch: 1729 Loss: 0.48487189412117004\n",
      "Batch: 1793 Loss: 0.36592742800712585\n",
      "Batch: 1857 Loss: 0.4438597857952118\n",
      "Batch: 1921 Loss: 0.5183309316635132\n",
      "Batch: 1985 Loss: 0.38812878727912903\n",
      "Batch: 2049 Loss: 0.3702656328678131\n",
      "Batch: 2113 Loss: 0.42873549461364746\n",
      "Batch: 2177 Loss: 0.47857335209846497\n",
      "Batch: 2241 Loss: 0.5449046492576599\n",
      "Batch: 2305 Loss: 0.5725933313369751\n",
      "Batch: 2369 Loss: 0.5676407217979431\n",
      "Batch: 2433 Loss: 0.4917451739311218\n",
      "Batch: 2497 Loss: 0.5511338710784912\n",
      "Batch: 2561 Loss: 0.47825565934181213\n",
      "Batch: 2625 Loss: 0.46641263365745544\n",
      "Batch: 2689 Loss: 0.4783051609992981\n",
      "Batch: 2753 Loss: 0.41273829340934753\n",
      "Batch: 2817 Loss: 0.6188114881515503\n",
      "Batch: 2881 Loss: 0.5328662395477295\n",
      "Batch: 2945 Loss: 0.4665724039077759\n",
      "Batch: 3009 Loss: 0.6524301767349243\n",
      "Batch: 3073 Loss: 0.5150076746940613\n",
      "Batch: 3137 Loss: 0.46343517303466797\n",
      "Batch: 3201 Loss: 0.430005818605423\n",
      "Batch: 3265 Loss: 0.41098347306251526\n",
      "Batch: 3329 Loss: 0.4461987614631653\n",
      "Batch: 3393 Loss: 0.49059486389160156\n",
      "Batch: 3457 Loss: 0.4522083103656769\n",
      "Batch: 3521 Loss: 0.33168262243270874\n",
      "Batch: 3585 Loss: 0.3267284035682678\n",
      "Batch: 3649 Loss: 0.5631734728813171\n",
      "Batch: 3713 Loss: 0.45308807492256165\n",
      "Batch: 3777 Loss: 0.4891054332256317\n",
      "Batch: 3841 Loss: 0.4874281585216522\n",
      "Batch: 3905 Loss: 0.41381460428237915\n",
      "Batch: 3969 Loss: 0.5876995325088501\n",
      "Batch: 4033 Loss: 0.43655896186828613\n",
      "Batch: 4097 Loss: 0.4345114827156067\n",
      "Batch: 4161 Loss: 0.5167959928512573\n",
      "Batch: 4225 Loss: 0.3697555959224701\n",
      "Batch: 4289 Loss: 0.4064803421497345\n",
      "Batch: 4353 Loss: 0.5582953691482544\n",
      "Batch: 4417 Loss: 0.7379317879676819\n",
      "Batch: 4481 Loss: 0.732740581035614\n",
      "Batch: 4545 Loss: 0.6162689924240112\n",
      "Batch: 4609 Loss: 0.4130909740924835\n",
      "Batch: 4673 Loss: 0.38092872500419617\n",
      "Batch: 4737 Loss: 0.5190442800521851\n",
      "Batch: 4801 Loss: 0.4149482548236847\n",
      "Batch: 4865 Loss: 0.4343213737010956\n",
      "Batch: 4929 Loss: 0.475100576877594\n",
      "Batch: 4993 Loss: 0.6103485226631165\n",
      "Batch: 5057 Loss: 0.5984351634979248\n",
      "Batch: 5121 Loss: 0.47361722588539124\n",
      "Batch: 5185 Loss: 0.9877313375473022\n",
      "Batch: 5249 Loss: 0.4109847843647003\n",
      "Batch: 5313 Loss: 0.4836214482784271\n",
      "Batch: 5377 Loss: 0.4632342457771301\n",
      "Batch: 5441 Loss: 0.5947586894035339\n",
      "Batch: 5505 Loss: 0.5429292321205139\n",
      "Batch: 5569 Loss: 0.580481231212616\n",
      "Batch: 5633 Loss: 0.40993085503578186\n",
      "Batch: 5697 Loss: 0.4845927357673645\n",
      "Batch: 5761 Loss: 0.6092636585235596\n",
      "Batch: 5825 Loss: 0.4810888469219208\n",
      "Batch: 5889 Loss: 0.4121190905570984\n",
      "Batch: 5953 Loss: 0.41737133264541626\n",
      "Batch: 6017 Loss: 0.34879419207572937\n",
      "Batch: 6081 Loss: 0.36142027378082275\n",
      "Batch: 6145 Loss: 0.47583481669425964\n",
      "Batch: 6209 Loss: 0.40722426772117615\n",
      "Batch: 6273 Loss: 0.5130680799484253\n",
      "Batch: 6337 Loss: 0.3693816363811493\n",
      "Batch: 6401 Loss: 0.3568900525569916\n",
      "Batch: 6465 Loss: 0.4192114770412445\n",
      "Batch: 6529 Loss: 0.3883179724216461\n",
      "Batch: 6593 Loss: 0.4443914592266083\n",
      "Batch: 6657 Loss: 0.34477895498275757\n",
      "Batch: 6721 Loss: 0.5020955801010132\n",
      "Batch: 6785 Loss: 0.4851692020893097\n",
      "Batch: 6849 Loss: 0.49113357067108154\n",
      "Batch: 6913 Loss: 0.44349682331085205\n",
      "Batch: 6977 Loss: 0.47056007385253906\n",
      "Batch: 7041 Loss: 0.4682326912879944\n",
      "Batch: 7105 Loss: 0.39006558060646057\n",
      "Batch: 7169 Loss: 0.4655410349369049\n",
      "Batch: 7233 Loss: 0.4041409194469452\n",
      "Batch: 7297 Loss: 0.4578360915184021\n",
      "Batch: 7361 Loss: 0.4228942096233368\n",
      "Batch: 7425 Loss: 0.5188783407211304\n",
      "Batch: 7489 Loss: 0.6271522045135498\n",
      "Batch: 7553 Loss: 0.3981846868991852\n",
      "Batch: 7617 Loss: 0.39266884326934814\n",
      "Batch: 7681 Loss: 0.49741142988204956\n",
      "Batch: 7745 Loss: 0.5014986991882324\n",
      "Batch: 7809 Loss: 0.463225394487381\n",
      "Batch: 7873 Loss: 0.38956648111343384\n",
      "Batch: 7937 Loss: 0.6154907941818237\n",
      "Batch: 8001 Loss: 0.4698019027709961\n",
      "Batch: 8065 Loss: 0.6285479068756104\n",
      "Batch: 8129 Loss: 0.47278496623039246\n",
      "Batch: 8193 Loss: 0.5196677446365356\n",
      "Batch: 8257 Loss: 0.5399620532989502\n",
      "Batch: 8321 Loss: 0.7245805859565735\n",
      "Batch: 8385 Loss: 0.34296610951423645\n",
      "Batch: 8449 Loss: 0.38007643818855286\n",
      "Batch: 8513 Loss: 0.7127713561058044\n",
      "Batch: 8577 Loss: 0.3594112694263458\n",
      "Batch: 8641 Loss: 0.5751437544822693\n",
      "Batch: 8705 Loss: 0.4629287123680115\n",
      "Batch: 8769 Loss: 0.5280136466026306\n",
      "Batch: 8833 Loss: 0.5767403841018677\n",
      "Batch: 8897 Loss: 0.8900802731513977\n",
      "Batch: 8961 Loss: 0.4320445656776428\n",
      "Batch: 9025 Loss: 0.4254734218120575\n",
      "Batch: 9089 Loss: 0.431848406791687\n",
      "Batch: 9153 Loss: 0.5129068493843079\n",
      "Batch: 9217 Loss: 0.5606567859649658\n",
      "Batch: 9281 Loss: 0.5158379077911377\n",
      "Batch: 9345 Loss: 0.4349317252635956\n",
      "Batch: 9409 Loss: 0.5771825909614563\n",
      "Batch: 9473 Loss: 0.6417309045791626\n",
      "Batch: 9537 Loss: 0.539961040019989\n",
      "Batch: 9601 Loss: 0.4073871374130249\n",
      "Batch: 9665 Loss: 0.37450581789016724\n",
      "Batch: 9729 Loss: 0.49327483773231506\n",
      "Batch: 9793 Loss: 0.4094488322734833\n",
      "Batch: 9857 Loss: 0.47807762026786804\n",
      "Batch: 9921 Loss: 0.44337666034698486\n",
      "Batch: 9985 Loss: 0.50648033618927\n",
      "Batch: 10049 Loss: 0.5874144434928894\n",
      "Batch: 10113 Loss: 0.4650442898273468\n",
      "Batch: 10177 Loss: 0.5405087471008301\n",
      "Batch: 10241 Loss: 0.40266236662864685\n",
      "Batch: 10305 Loss: 0.4900725483894348\n",
      "Batch: 10369 Loss: 0.5318074822425842\n",
      "Batch: 10433 Loss: 0.43179628252983093\n",
      "Batch: 10497 Loss: 0.42687690258026123\n",
      "Batch: 10561 Loss: 0.3967989981174469\n",
      "Batch: 10625 Loss: 0.47611501812934875\n",
      "Batch: 10689 Loss: 0.4738708734512329\n",
      "Batch: 10753 Loss: 0.38357678055763245\n",
      "Batch: 10817 Loss: 0.33236849308013916\n",
      "Batch: 10881 Loss: 0.3915979862213135\n",
      "Batch: 10945 Loss: 0.40203261375427246\n",
      "Batch: 11009 Loss: 0.44647616147994995\n",
      "Batch: 11073 Loss: 0.5010070204734802\n",
      "Batch: 11137 Loss: 0.4033917784690857\n",
      "Batch: 11201 Loss: 0.4389886260032654\n",
      "Batch: 11265 Loss: 0.579260528087616\n",
      "Batch: 11329 Loss: 0.7414965033531189\n",
      "Batch: 11393 Loss: 0.351783812046051\n",
      "Batch: 11457 Loss: 0.4149790108203888\n",
      "Batch: 11521 Loss: 0.430084228515625\n",
      "Batch: 11585 Loss: 0.5305019617080688\n",
      "Batch: 11649 Loss: 0.35677090287208557\n",
      "Batch: 11713 Loss: 0.4785219430923462\n",
      "Batch: 11777 Loss: 0.6688933372497559\n",
      "Batch: 11841 Loss: 0.6334091424942017\n",
      "Batch: 11905 Loss: 0.5061060786247253\n",
      "Batch: 11969 Loss: 0.48376160860061646\n",
      "Batch: 12033 Loss: 0.408759206533432\n",
      "Batch: 12097 Loss: 1.0564733743667603\n",
      "Batch: 12161 Loss: 0.5566232800483704\n",
      "Batch: 12225 Loss: 0.3228314220905304\n",
      "Batch: 12289 Loss: 0.34094372391700745\n",
      "Batch: 12353 Loss: 0.4746924340724945\n",
      "Batch: 12417 Loss: 0.40088793635368347\n",
      "Batch: 12481 Loss: 0.4399612843990326\n",
      "Batch: 12545 Loss: 0.5324956774711609\n",
      "Batch: 12609 Loss: 0.5723185539245605\n",
      "Batch: 12673 Loss: 0.5950748920440674\n",
      "Batch: 12737 Loss: 0.4869450032711029\n",
      "Batch: 12801 Loss: 0.41552507877349854\n",
      "Batch: 12865 Loss: 0.3542236387729645\n",
      "Batch: 12929 Loss: 0.7397051453590393\n",
      "Epoch: 2\n",
      "Batch: 1 Loss: 0.4285845458507538\n",
      "Batch: 65 Loss: 0.502958357334137\n",
      "Batch: 129 Loss: 0.4385771155357361\n",
      "Batch: 193 Loss: 0.6547553539276123\n",
      "Batch: 257 Loss: 0.446113258600235\n",
      "Batch: 321 Loss: 0.4328746199607849\n",
      "Batch: 385 Loss: 0.4421330988407135\n",
      "Batch: 449 Loss: 0.40567252039909363\n",
      "Batch: 513 Loss: 0.4216283857822418\n",
      "Batch: 577 Loss: 0.4194405972957611\n",
      "Batch: 641 Loss: 0.5032264590263367\n",
      "Batch: 705 Loss: 0.4363557696342468\n",
      "Batch: 769 Loss: 0.5088620781898499\n",
      "Batch: 833 Loss: 0.36788880825042725\n",
      "Batch: 897 Loss: 0.6247496604919434\n",
      "Batch: 961 Loss: 0.3898549973964691\n",
      "Batch: 1025 Loss: 0.4248868227005005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1089 Loss: 0.4177849590778351\n",
      "Batch: 1153 Loss: 0.46188297867774963\n",
      "Batch: 1217 Loss: 0.41874054074287415\n",
      "Batch: 1281 Loss: 0.4535689949989319\n",
      "Batch: 1345 Loss: 0.46112361550331116\n",
      "Batch: 1409 Loss: 0.3922782242298126\n",
      "Batch: 1473 Loss: 0.4388578236103058\n",
      "Batch: 1537 Loss: 0.41097012162208557\n",
      "Batch: 1601 Loss: 0.3536154329776764\n",
      "Batch: 1665 Loss: 0.38978806138038635\n",
      "Batch: 1729 Loss: 0.4714527726173401\n",
      "Batch: 1793 Loss: 0.358114629983902\n",
      "Batch: 1857 Loss: 0.4252123236656189\n",
      "Batch: 1921 Loss: 0.49025166034698486\n",
      "Batch: 1985 Loss: 0.3858853578567505\n",
      "Batch: 2049 Loss: 0.3662634789943695\n",
      "Batch: 2113 Loss: 0.4173298478126526\n",
      "Batch: 2177 Loss: 0.4668968617916107\n",
      "Batch: 2241 Loss: 0.5193275809288025\n",
      "Batch: 2305 Loss: 0.5513496398925781\n",
      "Batch: 2369 Loss: 0.5526253581047058\n",
      "Batch: 2433 Loss: 0.4704301655292511\n",
      "Batch: 2497 Loss: 0.5314379930496216\n",
      "Batch: 2561 Loss: 0.45921337604522705\n",
      "Batch: 2625 Loss: 0.4598776400089264\n",
      "Batch: 2689 Loss: 0.4724312126636505\n",
      "Batch: 2753 Loss: 0.3995489776134491\n",
      "Batch: 2817 Loss: 0.5949193835258484\n",
      "Batch: 2881 Loss: 0.5185138583183289\n",
      "Batch: 2945 Loss: 0.4529823660850525\n",
      "Batch: 3009 Loss: 0.6224883794784546\n",
      "Batch: 3073 Loss: 0.4935228228569031\n",
      "Batch: 3137 Loss: 0.44940242171287537\n",
      "Batch: 3201 Loss: 0.4175605773925781\n",
      "Batch: 3265 Loss: 0.39963582158088684\n",
      "Batch: 3329 Loss: 0.4347105622291565\n",
      "Batch: 3393 Loss: 0.48032090067863464\n",
      "Batch: 3457 Loss: 0.44356033205986023\n",
      "Batch: 3521 Loss: 0.32915717363357544\n",
      "Batch: 3585 Loss: 0.3202059864997864\n",
      "Batch: 3649 Loss: 0.5429330468177795\n",
      "Batch: 3713 Loss: 0.4419715702533722\n",
      "Batch: 3777 Loss: 0.47177639603614807\n",
      "Batch: 3841 Loss: 0.4718416631221771\n",
      "Batch: 3905 Loss: 0.4097375273704529\n",
      "Batch: 3969 Loss: 0.5778983235359192\n",
      "Batch: 4033 Loss: 0.43185827136039734\n",
      "Batch: 4097 Loss: 0.42705899477005005\n",
      "Batch: 4161 Loss: 0.5020259022712708\n",
      "Batch: 4225 Loss: 0.3622857630252838\n",
      "Batch: 4289 Loss: 0.39393702149391174\n",
      "Batch: 4353 Loss: 0.5419139862060547\n",
      "Batch: 4417 Loss: 0.7221303582191467\n",
      "Batch: 4481 Loss: 0.745593249797821\n",
      "Batch: 4545 Loss: 0.6037264466285706\n",
      "Batch: 4609 Loss: 0.4003542363643646\n",
      "Batch: 4673 Loss: 0.37353935837745667\n",
      "Batch: 4737 Loss: 0.49889877438545227\n",
      "Batch: 4801 Loss: 0.4052996039390564\n",
      "Batch: 4865 Loss: 0.4186681807041168\n",
      "Batch: 4929 Loss: 0.4625993072986603\n",
      "Batch: 4993 Loss: 0.5911733508110046\n",
      "Batch: 5057 Loss: 0.5759871602058411\n",
      "Batch: 5121 Loss: 0.4510149657726288\n",
      "Batch: 5185 Loss: 0.9501210451126099\n",
      "Batch: 5249 Loss: 0.40506884455680847\n",
      "Batch: 5313 Loss: 0.4803988039493561\n",
      "Batch: 5377 Loss: 0.4564151167869568\n",
      "Batch: 5441 Loss: 0.5779606699943542\n",
      "Batch: 5505 Loss: 0.530214786529541\n",
      "Batch: 5569 Loss: 0.5665204524993896\n",
      "Batch: 5633 Loss: 0.4074028730392456\n",
      "Batch: 5697 Loss: 0.4791073501110077\n",
      "Batch: 5761 Loss: 0.5995346903800964\n",
      "Batch: 5825 Loss: 0.4708858132362366\n",
      "Batch: 5889 Loss: 0.4073280096054077\n",
      "Batch: 5953 Loss: 0.41114628314971924\n",
      "Batch: 6017 Loss: 0.34660837054252625\n",
      "Batch: 6081 Loss: 0.3559495806694031\n",
      "Batch: 6145 Loss: 0.46931326389312744\n",
      "Batch: 6209 Loss: 0.40717944502830505\n",
      "Batch: 6273 Loss: 0.5022630095481873\n",
      "Batch: 6337 Loss: 0.366920530796051\n",
      "Batch: 6401 Loss: 0.35493552684783936\n",
      "Batch: 6465 Loss: 0.41079381108283997\n",
      "Batch: 6529 Loss: 0.38527369499206543\n",
      "Batch: 6593 Loss: 0.43354740738868713\n",
      "Batch: 6657 Loss: 0.34359464049339294\n",
      "Batch: 6721 Loss: 0.49276819825172424\n",
      "Batch: 6785 Loss: 0.48019373416900635\n",
      "Batch: 6849 Loss: 0.481890469789505\n",
      "Batch: 6913 Loss: 0.4375528395175934\n",
      "Batch: 6977 Loss: 0.462739497423172\n",
      "Batch: 7041 Loss: 0.4560926556587219\n",
      "Batch: 7105 Loss: 0.3831818997859955\n",
      "Batch: 7169 Loss: 0.4587310552597046\n",
      "Batch: 7233 Loss: 0.39558544754981995\n",
      "Batch: 7297 Loss: 0.4473593235015869\n",
      "Batch: 7361 Loss: 0.4144599735736847\n",
      "Batch: 7425 Loss: 0.5097337365150452\n",
      "Batch: 7489 Loss: 0.6113976836204529\n",
      "Batch: 7553 Loss: 0.39349430799484253\n",
      "Batch: 7617 Loss: 0.388038694858551\n",
      "Batch: 7681 Loss: 0.4833412766456604\n",
      "Batch: 7745 Loss: 0.49564146995544434\n",
      "Batch: 7809 Loss: 0.45476529002189636\n",
      "Batch: 7873 Loss: 0.3813875615596771\n",
      "Batch: 7937 Loss: 0.608066201210022\n",
      "Batch: 8001 Loss: 0.4587402045726776\n",
      "Batch: 8065 Loss: 0.6188569664955139\n",
      "Batch: 8129 Loss: 0.4647253155708313\n",
      "Batch: 8193 Loss: 0.5064723491668701\n",
      "Batch: 8257 Loss: 0.5326164960861206\n",
      "Batch: 8321 Loss: 0.7081810832023621\n",
      "Batch: 8385 Loss: 0.33729031682014465\n",
      "Batch: 8449 Loss: 0.3738650679588318\n",
      "Batch: 8513 Loss: 0.6929896473884583\n",
      "Batch: 8577 Loss: 0.3549441397190094\n",
      "Batch: 8641 Loss: 0.5614417195320129\n",
      "Batch: 8705 Loss: 0.45491859316825867\n",
      "Batch: 8769 Loss: 0.5186520218849182\n",
      "Batch: 8833 Loss: 0.5673109292984009\n",
      "Batch: 8897 Loss: 0.8706803917884827\n",
      "Batch: 8961 Loss: 0.42530643939971924\n",
      "Batch: 9025 Loss: 0.4191414415836334\n",
      "Batch: 9089 Loss: 0.42915546894073486\n",
      "Batch: 9153 Loss: 0.5018686652183533\n",
      "Batch: 9217 Loss: 0.5493437051773071\n",
      "Batch: 9281 Loss: 0.5093833804130554\n",
      "Batch: 9345 Loss: 0.4258624017238617\n",
      "Batch: 9409 Loss: 0.5738614201545715\n",
      "Batch: 9473 Loss: 0.6338350772857666\n",
      "Batch: 9537 Loss: 0.5303710103034973\n",
      "Batch: 9601 Loss: 0.4033219516277313\n",
      "Batch: 9665 Loss: 0.3675023913383484\n",
      "Batch: 9729 Loss: 0.4843059182167053\n",
      "Batch: 9793 Loss: 0.4073014557361603\n",
      "Batch: 9857 Loss: 0.46631431579589844\n",
      "Batch: 9921 Loss: 0.43269476294517517\n",
      "Batch: 9985 Loss: 0.4946870505809784\n",
      "Batch: 10049 Loss: 0.5724930167198181\n",
      "Batch: 10113 Loss: 0.4536195695400238\n",
      "Batch: 10177 Loss: 0.531456708908081\n",
      "Batch: 10241 Loss: 0.39469945430755615\n",
      "Batch: 10305 Loss: 0.48014798760414124\n",
      "Batch: 10369 Loss: 0.519248366355896\n",
      "Batch: 10433 Loss: 0.42638617753982544\n",
      "Batch: 10497 Loss: 0.422886461019516\n",
      "Batch: 10561 Loss: 0.39188992977142334\n",
      "Batch: 10625 Loss: 0.4694501459598541\n",
      "Batch: 10689 Loss: 0.46403905749320984\n",
      "Batch: 10753 Loss: 0.38043564558029175\n",
      "Batch: 10817 Loss: 0.33022746443748474\n",
      "Batch: 10881 Loss: 0.3861352801322937\n",
      "Batch: 10945 Loss: 0.39159202575683594\n",
      "Batch: 11009 Loss: 0.4406387507915497\n",
      "Batch: 11073 Loss: 0.4951435327529907\n",
      "Batch: 11137 Loss: 0.4030974507331848\n",
      "Batch: 11201 Loss: 0.4285482168197632\n",
      "Batch: 11265 Loss: 0.5687787532806396\n",
      "Batch: 11329 Loss: 0.7268273830413818\n",
      "Batch: 11393 Loss: 0.34008875489234924\n",
      "Batch: 11457 Loss: 0.4095664322376251\n",
      "Batch: 11521 Loss: 0.42971089482307434\n",
      "Batch: 11585 Loss: 0.5209835767745972\n",
      "Batch: 11649 Loss: 0.3500653803348541\n",
      "Batch: 11713 Loss: 0.46834075450897217\n",
      "Batch: 11777 Loss: 0.6568282246589661\n",
      "Batch: 11841 Loss: 0.6204875707626343\n",
      "Batch: 11905 Loss: 0.4963383078575134\n",
      "Batch: 11969 Loss: 0.4739886224269867\n",
      "Batch: 12033 Loss: 0.4009079337120056\n",
      "Batch: 12097 Loss: 1.0293301343917847\n",
      "Batch: 12161 Loss: 0.5504695773124695\n",
      "Batch: 12225 Loss: 0.317756712436676\n",
      "Batch: 12289 Loss: 0.33722034096717834\n",
      "Batch: 12353 Loss: 0.46612265706062317\n",
      "Batch: 12417 Loss: 0.396140992641449\n",
      "Batch: 12481 Loss: 0.43504664301872253\n",
      "Batch: 12545 Loss: 0.5216758251190186\n",
      "Batch: 12609 Loss: 0.5623614192008972\n",
      "Batch: 12673 Loss: 0.5891859531402588\n",
      "Batch: 12737 Loss: 0.4819733500480652\n",
      "Batch: 12801 Loss: 0.4094987213611603\n",
      "Batch: 12865 Loss: 0.34894129633903503\n",
      "Batch: 12929 Loss: 0.7235881090164185\n",
      "Epoch: 3\n",
      "Batch: 1 Loss: 0.4280436635017395\n",
      "Batch: 65 Loss: 0.4996366500854492\n",
      "Batch: 129 Loss: 0.43195992708206177\n",
      "Batch: 193 Loss: 0.6458869576454163\n",
      "Batch: 257 Loss: 0.44971007108688354\n",
      "Batch: 321 Loss: 0.4333215355873108\n",
      "Batch: 385 Loss: 0.4357840120792389\n",
      "Batch: 449 Loss: 0.400556743144989\n",
      "Batch: 513 Loss: 0.4174104928970337\n",
      "Batch: 577 Loss: 0.41441166400909424\n",
      "Batch: 641 Loss: 0.49418672919273376\n",
      "Batch: 705 Loss: 0.4276164174079895\n",
      "Batch: 769 Loss: 0.4956258237361908\n",
      "Batch: 833 Loss: 0.36559996008872986\n",
      "Batch: 897 Loss: 0.6145001649856567\n",
      "Batch: 961 Loss: 0.3869699537754059\n",
      "Batch: 1025 Loss: 0.4218066334724426\n",
      "Batch: 1089 Loss: 0.4166902005672455\n",
      "Batch: 1153 Loss: 0.45621177554130554\n",
      "Batch: 1217 Loss: 0.41412535309791565\n",
      "Batch: 1281 Loss: 0.44603943824768066\n",
      "Batch: 1345 Loss: 0.45474496483802795\n",
      "Batch: 1409 Loss: 0.3871593475341797\n",
      "Batch: 1473 Loss: 0.43427905440330505\n",
      "Batch: 1537 Loss: 0.4074039161205292\n",
      "Batch: 1601 Loss: 0.35144180059432983\n",
      "Batch: 1665 Loss: 0.38773128390312195\n",
      "Batch: 1729 Loss: 0.46434342861175537\n",
      "Batch: 1793 Loss: 0.3537473976612091\n",
      "Batch: 1857 Loss: 0.4185986816883087\n",
      "Batch: 1921 Loss: 0.48057809472084045\n",
      "Batch: 1985 Loss: 0.38255494832992554\n",
      "Batch: 2049 Loss: 0.3618316650390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2113 Loss: 0.40957486629486084\n",
      "Batch: 2177 Loss: 0.45868560671806335\n",
      "Batch: 2241 Loss: 0.509031355381012\n",
      "Batch: 2305 Loss: 0.5383694171905518\n",
      "Batch: 2369 Loss: 0.5405889749526978\n",
      "Batch: 2433 Loss: 0.4625864326953888\n",
      "Batch: 2497 Loss: 0.5216218829154968\n",
      "Batch: 2561 Loss: 0.45349010825157166\n",
      "Batch: 2625 Loss: 0.4567578136920929\n",
      "Batch: 2689 Loss: 0.46924853324890137\n",
      "Batch: 2753 Loss: 0.39526882767677307\n",
      "Batch: 2817 Loss: 0.5839964747428894\n",
      "Batch: 2881 Loss: 0.5101712942123413\n",
      "Batch: 2945 Loss: 0.4458980858325958\n",
      "Batch: 3009 Loss: 0.6122115254402161\n",
      "Batch: 3073 Loss: 0.48675867915153503\n",
      "Batch: 3137 Loss: 0.4414893090724945\n",
      "Batch: 3201 Loss: 0.41236433386802673\n",
      "Batch: 3265 Loss: 0.39437466859817505\n",
      "Batch: 3329 Loss: 0.42857104539871216\n",
      "Batch: 3393 Loss: 0.4736706018447876\n",
      "Batch: 3457 Loss: 0.4375152587890625\n",
      "Batch: 3521 Loss: 0.3275603652000427\n",
      "Batch: 3585 Loss: 0.3176950216293335\n",
      "Batch: 3649 Loss: 0.5352853536605835\n",
      "Batch: 3713 Loss: 0.43686428666114807\n",
      "Batch: 3777 Loss: 0.46483364701271057\n",
      "Batch: 3841 Loss: 0.4632646441459656\n",
      "Batch: 3905 Loss: 0.40679606795310974\n",
      "Batch: 3969 Loss: 0.5731645226478577\n",
      "Batch: 4033 Loss: 0.42795827984809875\n",
      "Batch: 4097 Loss: 0.4209144115447998\n",
      "Batch: 4161 Loss: 0.4956786334514618\n",
      "Batch: 4225 Loss: 0.3574029505252838\n",
      "Batch: 4289 Loss: 0.3884384334087372\n",
      "Batch: 4353 Loss: 0.5333768725395203\n",
      "Batch: 4417 Loss: 0.7111579179763794\n",
      "Batch: 4481 Loss: 0.7397733330726624\n",
      "Batch: 4545 Loss: 0.5967434644699097\n",
      "Batch: 4609 Loss: 0.3963873088359833\n",
      "Batch: 4673 Loss: 0.3697828948497772\n",
      "Batch: 4737 Loss: 0.4904171824455261\n",
      "Batch: 4801 Loss: 0.40069764852523804\n",
      "Batch: 4865 Loss: 0.41204237937927246\n",
      "Batch: 4929 Loss: 0.4557967483997345\n",
      "Batch: 4993 Loss: 0.5813112854957581\n",
      "Batch: 5057 Loss: 0.5644890666007996\n",
      "Batch: 5121 Loss: 0.43975940346717834\n",
      "Batch: 5185 Loss: 0.9300726652145386\n",
      "Batch: 5249 Loss: 0.40409478545188904\n",
      "Batch: 5313 Loss: 0.4791589081287384\n",
      "Batch: 5377 Loss: 0.4523438513278961\n",
      "Batch: 5441 Loss: 0.5687359571456909\n",
      "Batch: 5505 Loss: 0.5226693153381348\n",
      "Batch: 5569 Loss: 0.5593457818031311\n",
      "Batch: 5633 Loss: 0.4045555889606476\n",
      "Batch: 5697 Loss: 0.4729105234146118\n",
      "Batch: 5761 Loss: 0.590987503528595\n",
      "Batch: 5825 Loss: 0.465746134519577\n",
      "Batch: 5889 Loss: 0.4041401743888855\n",
      "Batch: 5953 Loss: 0.40632763504981995\n",
      "Batch: 6017 Loss: 0.34409773349761963\n",
      "Batch: 6081 Loss: 0.3487890362739563\n",
      "Batch: 6145 Loss: 0.4650382995605469\n",
      "Batch: 6209 Loss: 0.39699825644493103\n",
      "Batch: 6273 Loss: 0.49557599425315857\n",
      "Batch: 6337 Loss: 0.36241430044174194\n",
      "Batch: 6401 Loss: 0.3535735309123993\n",
      "Batch: 6465 Loss: 0.40691640973091125\n",
      "Batch: 6529 Loss: 0.38145509362220764\n",
      "Batch: 6593 Loss: 0.4280407130718231\n",
      "Batch: 6657 Loss: 0.3405973017215729\n",
      "Batch: 6721 Loss: 0.4848420321941376\n",
      "Batch: 6785 Loss: 0.46804186701774597\n",
      "Batch: 6849 Loss: 0.4706428349018097\n",
      "Batch: 6913 Loss: 0.4288727939128876\n",
      "Batch: 6977 Loss: 0.45922383666038513\n",
      "Batch: 7041 Loss: 0.4513168931007385\n",
      "Batch: 7105 Loss: 0.3777795135974884\n",
      "Batch: 7169 Loss: 0.4495866894721985\n",
      "Batch: 7233 Loss: 0.38779768347740173\n",
      "Batch: 7297 Loss: 0.442297101020813\n",
      "Batch: 7361 Loss: 0.41378384828567505\n",
      "Batch: 7425 Loss: 0.5077918767929077\n",
      "Batch: 7489 Loss: 0.6054694652557373\n",
      "Batch: 7553 Loss: 0.3916502296924591\n",
      "Batch: 7617 Loss: 0.38601621985435486\n",
      "Batch: 7681 Loss: 0.47906017303466797\n",
      "Batch: 7745 Loss: 0.49001792073249817\n",
      "Batch: 7809 Loss: 0.44964542984962463\n",
      "Batch: 7873 Loss: 0.3775670826435089\n",
      "Batch: 7937 Loss: 0.5974506735801697\n",
      "Batch: 8001 Loss: 0.4553591310977936\n",
      "Batch: 8065 Loss: 0.6079717874526978\n",
      "Batch: 8129 Loss: 0.455426424741745\n",
      "Batch: 8193 Loss: 0.4988929331302643\n",
      "Batch: 8257 Loss: 0.5207768678665161\n",
      "Batch: 8321 Loss: 0.6964860558509827\n",
      "Batch: 8385 Loss: 0.3385635316371918\n",
      "Batch: 8449 Loss: 0.3741479814052582\n",
      "Batch: 8513 Loss: 0.6832215189933777\n",
      "Batch: 8577 Loss: 0.3553297519683838\n",
      "Batch: 8641 Loss: 0.5532944202423096\n",
      "Batch: 8705 Loss: 0.4495391547679901\n",
      "Batch: 8769 Loss: 0.5136092305183411\n",
      "Batch: 8833 Loss: 0.5638449788093567\n",
      "Batch: 8897 Loss: 0.8577725291252136\n",
      "Batch: 8961 Loss: 0.4234023690223694\n",
      "Batch: 9025 Loss: 0.41567832231521606\n",
      "Batch: 9089 Loss: 0.4243629276752472\n",
      "Batch: 9153 Loss: 0.4980587363243103\n",
      "Batch: 9217 Loss: 0.5422461628913879\n",
      "Batch: 9281 Loss: 0.5042580366134644\n",
      "Batch: 9345 Loss: 0.41751810908317566\n",
      "Batch: 9409 Loss: 0.5663193464279175\n",
      "Batch: 9473 Loss: 0.6218501925468445\n",
      "Batch: 9537 Loss: 0.5216208100318909\n",
      "Batch: 9601 Loss: 0.39600828289985657\n",
      "Batch: 9665 Loss: 0.36477065086364746\n",
      "Batch: 9729 Loss: 0.4750158488750458\n",
      "Batch: 9793 Loss: 0.4038468599319458\n",
      "Batch: 9857 Loss: 0.46301260590553284\n",
      "Batch: 9921 Loss: 0.43080294132232666\n",
      "Batch: 9985 Loss: 0.48870763182640076\n",
      "Batch: 10049 Loss: 0.5652559399604797\n",
      "Batch: 10113 Loss: 0.44495144486427307\n",
      "Batch: 10177 Loss: 0.5225441455841064\n",
      "Batch: 10241 Loss: 0.39304426312446594\n",
      "Batch: 10305 Loss: 0.47428229451179504\n",
      "Batch: 10369 Loss: 0.5163255333900452\n",
      "Batch: 10433 Loss: 0.42450812458992004\n",
      "Batch: 10497 Loss: 0.41866612434387207\n",
      "Batch: 10561 Loss: 0.39051684737205505\n",
      "Batch: 10625 Loss: 0.4647541642189026\n",
      "Batch: 10689 Loss: 0.4581103026866913\n",
      "Batch: 10753 Loss: 0.3786121606826782\n",
      "Batch: 10817 Loss: 0.3282501995563507\n",
      "Batch: 10881 Loss: 0.3821772038936615\n",
      "Batch: 10945 Loss: 0.3890046179294586\n",
      "Batch: 11009 Loss: 0.43831026554107666\n",
      "Batch: 11073 Loss: 0.48927173018455505\n",
      "Batch: 11137 Loss: 0.39816591143608093\n",
      "Batch: 11201 Loss: 0.42151907086372375\n",
      "Batch: 11265 Loss: 0.5608974099159241\n",
      "Batch: 11329 Loss: 0.7102892398834229\n",
      "Batch: 11393 Loss: 0.3356071710586548\n",
      "Batch: 11457 Loss: 0.40064752101898193\n",
      "Batch: 11521 Loss: 0.4197132885456085\n",
      "Batch: 11585 Loss: 0.520585298538208\n",
      "Batch: 11649 Loss: 0.35185205936431885\n",
      "Batch: 11713 Loss: 0.4645886719226837\n",
      "Batch: 11777 Loss: 0.6505076289176941\n",
      "Batch: 11841 Loss: 0.6138743162155151\n",
      "Batch: 11905 Loss: 0.4907098710536957\n",
      "Batch: 11969 Loss: 0.46821072697639465\n",
      "Batch: 12033 Loss: 0.39741185307502747\n",
      "Batch: 12097 Loss: 1.0117937326431274\n",
      "Batch: 12161 Loss: 0.5468143224716187\n",
      "Batch: 12225 Loss: 0.31612807512283325\n",
      "Batch: 12289 Loss: 0.3357016146183014\n",
      "Batch: 12353 Loss: 0.46020543575286865\n",
      "Batch: 12417 Loss: 0.39173227548599243\n",
      "Batch: 12481 Loss: 0.4282502233982086\n",
      "Batch: 12545 Loss: 0.5158626437187195\n",
      "Batch: 12609 Loss: 0.5551184415817261\n",
      "Batch: 12673 Loss: 0.5811168551445007\n",
      "Batch: 12737 Loss: 0.4787060618400574\n",
      "Batch: 12801 Loss: 0.40580376982688904\n",
      "Batch: 12865 Loss: 0.3450525403022766\n",
      "Batch: 12929 Loss: 0.7113147377967834\n",
      "Epoch: 4\n",
      "Batch: 1 Loss: 0.4251115918159485\n",
      "Batch: 65 Loss: 0.4947172999382019\n",
      "Batch: 129 Loss: 0.4277999699115753\n",
      "Batch: 193 Loss: 0.6363499760627747\n",
      "Batch: 257 Loss: 0.4411333501338959\n",
      "Batch: 321 Loss: 0.423523873090744\n",
      "Batch: 385 Loss: 0.4306977689266205\n",
      "Batch: 449 Loss: 0.39629480242729187\n",
      "Batch: 513 Loss: 0.41346102952957153\n",
      "Batch: 577 Loss: 0.41100361943244934\n",
      "Batch: 641 Loss: 0.48836150765419006\n",
      "Batch: 705 Loss: 0.4221149682998657\n",
      "Batch: 769 Loss: 0.4877292215824127\n",
      "Batch: 833 Loss: 0.36203083395957947\n",
      "Batch: 897 Loss: 0.6093425154685974\n",
      "Batch: 961 Loss: 0.3837115168571472\n",
      "Batch: 1025 Loss: 0.41740521788597107\n",
      "Batch: 1089 Loss: 0.41409286856651306\n",
      "Batch: 1153 Loss: 0.45088091492652893\n",
      "Batch: 1217 Loss: 0.4107641875743866\n",
      "Batch: 1281 Loss: 0.4445554316043854\n",
      "Batch: 1345 Loss: 0.45175766944885254\n",
      "Batch: 1409 Loss: 0.3872910141944885\n",
      "Batch: 1473 Loss: 0.43306681513786316\n",
      "Batch: 1537 Loss: 0.40531471371650696\n",
      "Batch: 1601 Loss: 0.3504296839237213\n",
      "Batch: 1665 Loss: 0.386649489402771\n",
      "Batch: 1729 Loss: 0.46103790402412415\n",
      "Batch: 1793 Loss: 0.3511738181114197\n",
      "Batch: 1857 Loss: 0.41521021723747253\n",
      "Batch: 1921 Loss: 0.4736534059047699\n",
      "Batch: 1985 Loss: 0.380322128534317\n",
      "Batch: 2049 Loss: 0.35950377583503723\n",
      "Batch: 2113 Loss: 0.40368643403053284\n",
      "Batch: 2177 Loss: 0.4516426622867584\n",
      "Batch: 2241 Loss: 0.5019417405128479\n",
      "Batch: 2305 Loss: 0.5304004549980164\n",
      "Batch: 2369 Loss: 0.5329811573028564\n",
      "Batch: 2433 Loss: 0.4579114615917206\n",
      "Batch: 2497 Loss: 0.5126935243606567\n",
      "Batch: 2561 Loss: 0.4527401626110077\n",
      "Batch: 2625 Loss: 0.4536987245082855\n",
      "Batch: 2689 Loss: 0.4661618769168854\n",
      "Batch: 2753 Loss: 0.3916986584663391\n",
      "Batch: 2817 Loss: 0.5757206082344055\n",
      "Batch: 2881 Loss: 0.5040059089660645\n",
      "Batch: 2945 Loss: 0.43954774737358093\n",
      "Batch: 3009 Loss: 0.6046125292778015\n",
      "Batch: 3073 Loss: 0.48080021142959595\n",
      "Batch: 3137 Loss: 0.436817467212677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 3201 Loss: 0.4090007543563843\n",
      "Batch: 3265 Loss: 0.3913416564464569\n",
      "Batch: 3329 Loss: 0.42457109689712524\n",
      "Batch: 3393 Loss: 0.4679761826992035\n",
      "Batch: 3457 Loss: 0.4317532777786255\n",
      "Batch: 3521 Loss: 0.325680673122406\n",
      "Batch: 3585 Loss: 0.31638845801353455\n",
      "Batch: 3649 Loss: 0.5267871618270874\n",
      "Batch: 3713 Loss: 0.43194013833999634\n",
      "Batch: 3777 Loss: 0.45940670371055603\n",
      "Batch: 3841 Loss: 0.45819246768951416\n",
      "Batch: 3905 Loss: 0.40485820174217224\n",
      "Batch: 3969 Loss: 0.5686449408531189\n",
      "Batch: 4033 Loss: 0.4279710650444031\n",
      "Batch: 4097 Loss: 0.41871145367622375\n",
      "Batch: 4161 Loss: 0.4912349581718445\n",
      "Batch: 4225 Loss: 0.3569352328777313\n",
      "Batch: 4289 Loss: 0.38253888487815857\n",
      "Batch: 4353 Loss: 0.5247988700866699\n",
      "Batch: 4417 Loss: 0.7033610939979553\n",
      "Batch: 4481 Loss: 0.7377933263778687\n",
      "Batch: 4545 Loss: 0.5922683477401733\n",
      "Batch: 4609 Loss: 0.39232486486434937\n",
      "Batch: 4673 Loss: 0.36803752183914185\n",
      "Batch: 4737 Loss: 0.48434436321258545\n",
      "Batch: 4801 Loss: 0.3976460099220276\n",
      "Batch: 4865 Loss: 0.4069574475288391\n",
      "Batch: 4929 Loss: 0.45187240839004517\n",
      "Batch: 4993 Loss: 0.5758063197135925\n",
      "Batch: 5057 Loss: 0.5585676431655884\n",
      "Batch: 5121 Loss: 0.4348272681236267\n",
      "Batch: 5185 Loss: 0.9170466065406799\n",
      "Batch: 5249 Loss: 0.40096837282180786\n",
      "Batch: 5313 Loss: 0.47874635457992554\n",
      "Batch: 5377 Loss: 0.4499621093273163\n",
      "Batch: 5441 Loss: 0.5616176724433899\n",
      "Batch: 5505 Loss: 0.5164919495582581\n",
      "Batch: 5569 Loss: 0.5523034930229187\n",
      "Batch: 5633 Loss: 0.4035234749317169\n",
      "Batch: 5697 Loss: 0.47122451663017273\n",
      "Batch: 5761 Loss: 0.5891655683517456\n",
      "Batch: 5825 Loss: 0.4595729112625122\n",
      "Batch: 5889 Loss: 0.40208983421325684\n",
      "Batch: 5953 Loss: 0.4035775065422058\n",
      "Batch: 6017 Loss: 0.34909138083457947\n",
      "Batch: 6081 Loss: 0.34157660603523254\n",
      "Batch: 6145 Loss: 0.461749404668808\n",
      "Batch: 6209 Loss: 0.39233484864234924\n",
      "Batch: 6273 Loss: 0.49297070503234863\n",
      "Batch: 6337 Loss: 0.36102965474128723\n",
      "Batch: 6401 Loss: 0.3518756031990051\n",
      "Batch: 6465 Loss: 0.4059160351753235\n",
      "Batch: 6529 Loss: 0.3787260353565216\n",
      "Batch: 6593 Loss: 0.42200347781181335\n",
      "Batch: 6657 Loss: 0.3390423655509949\n",
      "Batch: 6721 Loss: 0.4806767702102661\n",
      "Batch: 6785 Loss: 0.4639294147491455\n",
      "Batch: 6849 Loss: 0.46575871109962463\n",
      "Batch: 6913 Loss: 0.4241617023944855\n",
      "Batch: 6977 Loss: 0.4549838602542877\n",
      "Batch: 7041 Loss: 0.44578394293785095\n",
      "Batch: 7105 Loss: 0.3747926950454712\n",
      "Batch: 7169 Loss: 0.4451404809951782\n",
      "Batch: 7233 Loss: 0.382931649684906\n",
      "Batch: 7297 Loss: 0.43876978754997253\n",
      "Batch: 7361 Loss: 0.41229408979415894\n",
      "Batch: 7425 Loss: 0.5046142339706421\n",
      "Batch: 7489 Loss: 0.5999385714530945\n",
      "Batch: 7553 Loss: 0.3894045948982239\n",
      "Batch: 7617 Loss: 0.3834359049797058\n",
      "Batch: 7681 Loss: 0.47264596819877625\n",
      "Batch: 7745 Loss: 0.4855934679508209\n",
      "Batch: 7809 Loss: 0.44483134150505066\n",
      "Batch: 7873 Loss: 0.37351348996162415\n",
      "Batch: 7937 Loss: 0.5917811393737793\n",
      "Batch: 8001 Loss: 0.4500311613082886\n",
      "Batch: 8065 Loss: 0.6026594042778015\n",
      "Batch: 8129 Loss: 0.4512559175491333\n",
      "Batch: 8193 Loss: 0.49287092685699463\n",
      "Batch: 8257 Loss: 0.5150641798973083\n",
      "Batch: 8321 Loss: 0.6879158616065979\n",
      "Batch: 8385 Loss: 0.3371152877807617\n",
      "Batch: 8449 Loss: 0.3732655644416809\n",
      "Batch: 8513 Loss: 0.6775195598602295\n",
      "Batch: 8577 Loss: 0.3556516170501709\n",
      "Batch: 8641 Loss: 0.546435534954071\n",
      "Batch: 8705 Loss: 0.4427641034126282\n",
      "Batch: 8769 Loss: 0.5072256326675415\n",
      "Batch: 8833 Loss: 0.5610220432281494\n",
      "Batch: 8897 Loss: 0.8512322306632996\n",
      "Batch: 8961 Loss: 0.42069676518440247\n",
      "Batch: 9025 Loss: 0.41292062401771545\n",
      "Batch: 9089 Loss: 0.4228181540966034\n",
      "Batch: 9153 Loss: 0.49220848083496094\n",
      "Batch: 9217 Loss: 0.5352209210395813\n",
      "Batch: 9281 Loss: 0.49973157048225403\n",
      "Batch: 9345 Loss: 0.41613703966140747\n",
      "Batch: 9409 Loss: 0.5593990087509155\n",
      "Batch: 9473 Loss: 0.6109397411346436\n",
      "Batch: 9537 Loss: 0.516474187374115\n",
      "Batch: 9601 Loss: 0.3923506438732147\n",
      "Batch: 9665 Loss: 0.36309224367141724\n",
      "Batch: 9729 Loss: 0.47165581583976746\n",
      "Batch: 9793 Loss: 0.4025154113769531\n",
      "Batch: 9857 Loss: 0.4584352970123291\n",
      "Batch: 9921 Loss: 0.426790326833725\n",
      "Batch: 9985 Loss: 0.48240065574645996\n",
      "Batch: 10049 Loss: 0.5584881901741028\n",
      "Batch: 10113 Loss: 0.43937012553215027\n",
      "Batch: 10177 Loss: 0.5163265466690063\n",
      "Batch: 10241 Loss: 0.3903845548629761\n",
      "Batch: 10305 Loss: 0.46993666887283325\n",
      "Batch: 10369 Loss: 0.5125429034233093\n",
      "Batch: 10433 Loss: 0.4224419891834259\n",
      "Batch: 10497 Loss: 0.41429969668388367\n",
      "Batch: 10561 Loss: 0.3875805139541626\n",
      "Batch: 10625 Loss: 0.46206527948379517\n",
      "Batch: 10689 Loss: 0.4519074261188507\n",
      "Batch: 10753 Loss: 0.3755030333995819\n",
      "Batch: 10817 Loss: 0.3287900984287262\n",
      "Batch: 10881 Loss: 0.3792687654495239\n",
      "Batch: 10945 Loss: 0.38142940402030945\n",
      "Batch: 11009 Loss: 0.43404996395111084\n",
      "Batch: 11073 Loss: 0.4825327396392822\n",
      "Batch: 11137 Loss: 0.39423295855522156\n",
      "Batch: 11201 Loss: 0.416424423456192\n",
      "Batch: 11265 Loss: 0.5557927489280701\n",
      "Batch: 11329 Loss: 0.6982612609863281\n",
      "Batch: 11393 Loss: 0.3317626118659973\n",
      "Batch: 11457 Loss: 0.3990578353404999\n",
      "Batch: 11521 Loss: 0.41584375500679016\n",
      "Batch: 11585 Loss: 0.516438364982605\n",
      "Batch: 11649 Loss: 0.35043004155158997\n",
      "Batch: 11713 Loss: 0.4611635208129883\n",
      "Batch: 11777 Loss: 0.6452993750572205\n",
      "Batch: 11841 Loss: 0.6084845066070557\n",
      "Batch: 11905 Loss: 0.4868501126766205\n",
      "Batch: 11969 Loss: 0.46517065167427063\n",
      "Batch: 12033 Loss: 0.3941914439201355\n",
      "Batch: 12097 Loss: 0.9977949857711792\n",
      "Batch: 12161 Loss: 0.5440248250961304\n",
      "Batch: 12225 Loss: 0.3151782751083374\n",
      "Batch: 12289 Loss: 0.33494001626968384\n",
      "Batch: 12353 Loss: 0.4560386836528778\n",
      "Batch: 12417 Loss: 0.3884277045726776\n",
      "Batch: 12481 Loss: 0.4233878254890442\n",
      "Batch: 12545 Loss: 0.5117259621620178\n",
      "Batch: 12609 Loss: 0.5498022437095642\n",
      "Batch: 12673 Loss: 0.576129674911499\n",
      "Batch: 12737 Loss: 0.47566449642181396\n",
      "Batch: 12801 Loss: 0.4031813144683838\n",
      "Batch: 12865 Loss: 0.3411843776702881\n",
      "Batch: 12929 Loss: 0.7014740705490112\n",
      "Epoch: 5\n",
      "Batch: 1 Loss: 0.42193475365638733\n",
      "Batch: 65 Loss: 0.4910773038864136\n",
      "Batch: 129 Loss: 0.42272284626960754\n",
      "Batch: 193 Loss: 0.6205529570579529\n",
      "Batch: 257 Loss: 0.4263235628604889\n",
      "Batch: 321 Loss: 0.518543541431427\n",
      "Batch: 385 Loss: 0.480360746383667\n",
      "Batch: 449 Loss: 0.39699801802635193\n",
      "Batch: 513 Loss: 0.40884000062942505\n",
      "Batch: 577 Loss: 0.41354334354400635\n",
      "Batch: 641 Loss: 0.49333706498146057\n",
      "Batch: 705 Loss: 0.4343188405036926\n",
      "Batch: 769 Loss: 0.49430811405181885\n",
      "Batch: 833 Loss: 0.3624984920024872\n",
      "Batch: 897 Loss: 0.6104034185409546\n",
      "Batch: 961 Loss: 0.38845938444137573\n",
      "Batch: 1025 Loss: 0.4238218665122986\n",
      "Batch: 1089 Loss: 0.406501829624176\n",
      "Batch: 1153 Loss: 0.4493057131767273\n",
      "Batch: 1217 Loss: 0.4138071835041046\n",
      "Batch: 1281 Loss: 0.44405972957611084\n",
      "Batch: 1345 Loss: 0.44997701048851013\n",
      "Batch: 1409 Loss: 0.3815605342388153\n",
      "Batch: 1473 Loss: 0.430724173784256\n",
      "Batch: 1537 Loss: 0.4072781801223755\n",
      "Batch: 1601 Loss: 0.35313278436660767\n",
      "Batch: 1665 Loss: 0.39006200432777405\n",
      "Batch: 1729 Loss: 0.46483081579208374\n",
      "Batch: 1793 Loss: 0.35752880573272705\n",
      "Batch: 1857 Loss: 0.4111552834510803\n",
      "Batch: 1921 Loss: 0.46920400857925415\n",
      "Batch: 1985 Loss: 0.3870352506637573\n",
      "Batch: 2049 Loss: 0.3640192747116089\n",
      "Batch: 2113 Loss: 0.39480990171432495\n",
      "Batch: 2177 Loss: 0.4488992989063263\n",
      "Batch: 2241 Loss: 0.49772992730140686\n",
      "Batch: 2305 Loss: 0.5328361988067627\n",
      "Batch: 2369 Loss: 0.5390767455101013\n",
      "Batch: 2433 Loss: 0.45934081077575684\n",
      "Batch: 2497 Loss: 0.5242407917976379\n",
      "Batch: 2561 Loss: 0.45030540227890015\n",
      "Batch: 2625 Loss: 0.44993942975997925\n",
      "Batch: 2689 Loss: 0.46978437900543213\n",
      "Batch: 2753 Loss: 0.39116889238357544\n",
      "Batch: 2817 Loss: 0.572647213935852\n",
      "Batch: 2881 Loss: 0.504817545413971\n",
      "Batch: 2945 Loss: 0.44243672490119934\n",
      "Batch: 3009 Loss: 0.6028643250465393\n",
      "Batch: 3073 Loss: 0.48092594742774963\n",
      "Batch: 3137 Loss: 0.43830427527427673\n",
      "Batch: 3201 Loss: 0.4074760973453522\n",
      "Batch: 3265 Loss: 0.3916090130805969\n",
      "Batch: 3329 Loss: 0.42152225971221924\n",
      "Batch: 3393 Loss: 0.4672676920890808\n",
      "Batch: 3457 Loss: 0.43278682231903076\n",
      "Batch: 3521 Loss: 0.3258650302886963\n",
      "Batch: 3585 Loss: 0.31329137086868286\n",
      "Batch: 3649 Loss: 0.5200502872467041\n",
      "Batch: 3713 Loss: 0.4285723567008972\n",
      "Batch: 3777 Loss: 0.45597827434539795\n",
      "Batch: 3841 Loss: 0.45142993330955505\n",
      "Batch: 3905 Loss: 0.40041831135749817\n",
      "Batch: 3969 Loss: 0.5608232617378235\n",
      "Batch: 4033 Loss: 0.42330053448677063\n",
      "Batch: 4097 Loss: 0.4174347221851349\n",
      "Batch: 4161 Loss: 0.48651984333992004\n",
      "Batch: 4225 Loss: 0.35408347845077515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 4289 Loss: 0.3791562616825104\n",
      "Batch: 4353 Loss: 0.5161954760551453\n",
      "Batch: 4417 Loss: 0.6907860636711121\n",
      "Batch: 4481 Loss: 0.7347877025604248\n",
      "Batch: 4545 Loss: 0.585457444190979\n",
      "Batch: 4609 Loss: 0.38826659321784973\n",
      "Batch: 4673 Loss: 0.367742657661438\n",
      "Batch: 4737 Loss: 0.4802986979484558\n",
      "Batch: 4801 Loss: 0.394662082195282\n",
      "Batch: 4865 Loss: 0.4037718176841736\n",
      "Batch: 4929 Loss: 0.4530487656593323\n",
      "Batch: 4993 Loss: 0.5746557116508484\n",
      "Batch: 5057 Loss: 0.5514033436775208\n",
      "Batch: 5121 Loss: 0.4287444055080414\n",
      "Batch: 5185 Loss: 0.918160080909729\n",
      "Batch: 5249 Loss: 0.39441612362861633\n",
      "Batch: 5313 Loss: 0.4709579050540924\n",
      "Batch: 5377 Loss: 0.44668492674827576\n",
      "Batch: 5441 Loss: 0.5564667582511902\n",
      "Batch: 5505 Loss: 0.5123625993728638\n",
      "Batch: 5569 Loss: 0.5475814342498779\n",
      "Batch: 5633 Loss: 0.3989991843700409\n",
      "Batch: 5697 Loss: 0.4668348431587219\n",
      "Batch: 5761 Loss: 0.587019681930542\n",
      "Batch: 5825 Loss: 0.4551815688610077\n",
      "Batch: 5889 Loss: 0.3984215557575226\n",
      "Batch: 5953 Loss: 0.4027496576309204\n",
      "Batch: 6017 Loss: 0.34255003929138184\n",
      "Batch: 6081 Loss: 0.3407765030860901\n",
      "Batch: 6145 Loss: 0.45248547196388245\n",
      "Batch: 6209 Loss: 0.38803279399871826\n",
      "Batch: 6273 Loss: 0.48699674010276794\n",
      "Batch: 6337 Loss: 0.3572034239768982\n",
      "Batch: 6401 Loss: 0.3530779182910919\n",
      "Batch: 6465 Loss: 0.40170761942863464\n",
      "Batch: 6529 Loss: 0.3776341378688812\n",
      "Batch: 6593 Loss: 0.4172656834125519\n",
      "Batch: 6657 Loss: 0.33748552203178406\n",
      "Batch: 6721 Loss: 0.47451260685920715\n",
      "Batch: 6785 Loss: 0.4586260914802551\n",
      "Batch: 6849 Loss: 0.4585973918437958\n",
      "Batch: 6913 Loss: 0.4210948646068573\n",
      "Batch: 6977 Loss: 0.4506813585758209\n",
      "Batch: 7041 Loss: 0.44650042057037354\n",
      "Batch: 7105 Loss: 0.3734295070171356\n",
      "Batch: 7169 Loss: 0.4435904622077942\n",
      "Batch: 7233 Loss: 0.3800213932991028\n",
      "Batch: 7297 Loss: 0.43788331747055054\n",
      "Batch: 7361 Loss: 0.4067496657371521\n",
      "Batch: 7425 Loss: 0.4990100562572479\n",
      "Batch: 7489 Loss: 0.5942623019218445\n",
      "Batch: 7553 Loss: 0.38738781213760376\n",
      "Batch: 7617 Loss: 0.38006091117858887\n",
      "Batch: 7681 Loss: 0.474511057138443\n",
      "Batch: 7745 Loss: 0.4805063307285309\n",
      "Batch: 7809 Loss: 0.4453822076320648\n",
      "Batch: 7873 Loss: 0.3711581826210022\n",
      "Batch: 7937 Loss: 0.5903573036193848\n",
      "Batch: 8001 Loss: 0.4434913098812103\n",
      "Batch: 8065 Loss: 0.5959621667861938\n",
      "Batch: 8129 Loss: 0.44906505942344666\n",
      "Batch: 8193 Loss: 0.49052736163139343\n",
      "Batch: 8257 Loss: 0.5316610932350159\n",
      "Batch: 8321 Loss: 0.6819414496421814\n",
      "Batch: 8385 Loss: 0.33270522952079773\n",
      "Batch: 8449 Loss: 0.3683837354183197\n",
      "Batch: 8513 Loss: 0.6695564985275269\n",
      "Batch: 8577 Loss: 0.35153329372406006\n",
      "Batch: 8641 Loss: 0.5460325479507446\n",
      "Batch: 8705 Loss: 0.44017699360847473\n",
      "Batch: 8769 Loss: 0.5031024217605591\n",
      "Batch: 8833 Loss: 0.5586925745010376\n",
      "Batch: 8897 Loss: 0.8456295728683472\n",
      "Batch: 8961 Loss: 0.41738730669021606\n",
      "Batch: 9025 Loss: 0.4110754728317261\n",
      "Batch: 9089 Loss: 0.4221815764904022\n",
      "Batch: 9153 Loss: 0.4881928861141205\n",
      "Batch: 9217 Loss: 0.5305361747741699\n",
      "Batch: 9281 Loss: 0.49667808413505554\n",
      "Batch: 9345 Loss: 0.40339407324790955\n",
      "Batch: 9409 Loss: 0.5622518062591553\n",
      "Batch: 9473 Loss: 0.7858487367630005\n",
      "Batch: 9537 Loss: 0.6410940289497375\n",
      "Batch: 9601 Loss: 0.48506754636764526\n",
      "Batch: 9665 Loss: 0.36288967728614807\n",
      "Batch: 9729 Loss: 0.47433727979660034\n",
      "Batch: 9793 Loss: 0.4085148274898529\n",
      "Batch: 9857 Loss: 0.4580470025539398\n",
      "Batch: 9921 Loss: 0.42393240332603455\n",
      "Batch: 9985 Loss: 0.47965139150619507\n",
      "Batch: 10049 Loss: 0.5532324910163879\n",
      "Batch: 10113 Loss: 0.4380944073200226\n",
      "Batch: 10177 Loss: 0.5177453756332397\n",
      "Batch: 10241 Loss: 0.3833777606487274\n",
      "Batch: 10305 Loss: 0.46765223145484924\n",
      "Batch: 10369 Loss: 0.5054101347923279\n",
      "Batch: 10433 Loss: 0.4214681386947632\n",
      "Batch: 10497 Loss: 0.41636061668395996\n",
      "Batch: 10561 Loss: 0.3811919093132019\n",
      "Batch: 10625 Loss: 0.46172675490379333\n",
      "Batch: 10689 Loss: 0.45114877820014954\n",
      "Batch: 10753 Loss: 0.3738669753074646\n",
      "Batch: 10817 Loss: 0.32710331678390503\n",
      "Batch: 10881 Loss: 0.380524218082428\n",
      "Batch: 10945 Loss: 0.3774056136608124\n",
      "Batch: 11009 Loss: 0.42662280797958374\n",
      "Batch: 11073 Loss: 0.48173364996910095\n",
      "Batch: 11137 Loss: 0.39709511399269104\n",
      "Batch: 11201 Loss: 0.41599249839782715\n",
      "Batch: 11265 Loss: 0.555286169052124\n",
      "Batch: 11329 Loss: 0.7043735384941101\n",
      "Batch: 11393 Loss: 0.33050933480262756\n",
      "Batch: 11457 Loss: 0.40347665548324585\n",
      "Batch: 11521 Loss: 0.42359083890914917\n",
      "Batch: 11585 Loss: 0.5070484280586243\n",
      "Batch: 11649 Loss: 0.34402385354042053\n",
      "Batch: 11713 Loss: 0.4536629319190979\n",
      "Batch: 11777 Loss: 0.6382439732551575\n",
      "Batch: 11841 Loss: 0.6117255687713623\n",
      "Batch: 11905 Loss: 0.488628089427948\n",
      "Batch: 11969 Loss: 0.4609778821468353\n",
      "Batch: 12033 Loss: 0.39253196120262146\n",
      "Batch: 12097 Loss: 1.0016311407089233\n",
      "Batch: 12161 Loss: 0.5905595421791077\n",
      "Batch: 12225 Loss: 0.3174436092376709\n",
      "Batch: 12289 Loss: 0.34163886308670044\n",
      "Batch: 12353 Loss: 0.48467645049095154\n",
      "Batch: 12417 Loss: 0.41078832745552063\n",
      "Batch: 12481 Loss: 0.4389861822128296\n",
      "Batch: 12545 Loss: 0.5278587341308594\n",
      "Batch: 12609 Loss: 0.5665158629417419\n",
      "Batch: 12673 Loss: 0.5953401327133179\n",
      "Batch: 12737 Loss: 0.4887582063674927\n",
      "Batch: 12801 Loss: 0.433438241481781\n",
      "Batch: 12865 Loss: 0.37201258540153503\n",
      "Batch: 12929 Loss: 0.7349196076393127\n",
      "Epoch: 6\n",
      "Batch: 1 Loss: 0.42036494612693787\n",
      "Batch: 65 Loss: 0.4820837080478668\n",
      "Batch: 129 Loss: 0.41305381059646606\n",
      "Batch: 193 Loss: 0.6205628514289856\n",
      "Batch: 257 Loss: 0.43134427070617676\n",
      "Batch: 321 Loss: 0.42070260643959045\n",
      "Batch: 385 Loss: 0.42633047699928284\n",
      "Batch: 449 Loss: 0.3932969868183136\n",
      "Batch: 513 Loss: 0.41163820028305054\n",
      "Batch: 577 Loss: 0.4051954448223114\n",
      "Batch: 641 Loss: 0.49154576659202576\n",
      "Batch: 705 Loss: 0.4301299452781677\n",
      "Batch: 769 Loss: 0.4921562969684601\n",
      "Batch: 833 Loss: 0.36137691140174866\n",
      "Batch: 897 Loss: 0.6013361811637878\n",
      "Batch: 961 Loss: 0.39120766520500183\n",
      "Batch: 1025 Loss: 0.42452099919319153\n",
      "Batch: 1089 Loss: 0.40569084882736206\n",
      "Batch: 1153 Loss: 0.4481517970561981\n",
      "Batch: 1217 Loss: 0.4086397588253021\n",
      "Batch: 1281 Loss: 0.4363345801830292\n",
      "Batch: 1345 Loss: 0.451103538274765\n",
      "Batch: 1409 Loss: 0.37872445583343506\n",
      "Batch: 1473 Loss: 0.42603185772895813\n",
      "Batch: 1537 Loss: 0.41196903586387634\n",
      "Batch: 1601 Loss: 0.34950920939445496\n",
      "Batch: 1665 Loss: 0.3895954489707947\n",
      "Batch: 1729 Loss: 0.46046534180641174\n",
      "Batch: 1793 Loss: 0.35853785276412964\n",
      "Batch: 1857 Loss: 0.42234718799591064\n",
      "Batch: 1921 Loss: 0.505761981010437\n",
      "Batch: 1985 Loss: 0.389618843793869\n",
      "Batch: 2049 Loss: 0.369184672832489\n",
      "Batch: 2113 Loss: 0.4100128412246704\n",
      "Batch: 2177 Loss: 0.48134899139404297\n",
      "Batch: 2241 Loss: 0.5102581977844238\n",
      "Batch: 2305 Loss: 0.5285335183143616\n",
      "Batch: 2369 Loss: 0.5364423394203186\n",
      "Batch: 2433 Loss: 0.4622781276702881\n",
      "Batch: 2497 Loss: 0.5195377469062805\n",
      "Batch: 2561 Loss: 0.45586809515953064\n",
      "Batch: 2625 Loss: 0.4507904350757599\n",
      "Batch: 2689 Loss: 0.4661670923233032\n",
      "Batch: 2753 Loss: 0.4000934958457947\n",
      "Batch: 2817 Loss: 0.5925030708312988\n",
      "Batch: 2881 Loss: 0.5144784450531006\n",
      "Batch: 2945 Loss: 0.4478698670864105\n",
      "Batch: 3009 Loss: 0.6090764403343201\n",
      "Batch: 3073 Loss: 0.4884057939052582\n",
      "Batch: 3137 Loss: 0.4343307912349701\n",
      "Batch: 3201 Loss: 0.40705937147140503\n",
      "Batch: 3265 Loss: 0.3913547098636627\n",
      "Batch: 3329 Loss: 0.4214247763156891\n",
      "Batch: 3393 Loss: 0.47524648904800415\n",
      "Batch: 3457 Loss: 0.44601181149482727\n",
      "Batch: 3521 Loss: 0.3287525177001953\n",
      "Batch: 3585 Loss: 0.3194301128387451\n",
      "Batch: 3649 Loss: 0.5269748568534851\n",
      "Batch: 3713 Loss: 0.4352641701698303\n",
      "Batch: 3777 Loss: 0.4656660556793213\n",
      "Batch: 3841 Loss: 0.4578975439071655\n",
      "Batch: 3905 Loss: 0.403539776802063\n",
      "Batch: 3969 Loss: 0.5541676878929138\n",
      "Batch: 4033 Loss: 0.4169102609157562\n",
      "Batch: 4097 Loss: 0.41370707750320435\n",
      "Batch: 4161 Loss: 0.4851633310317993\n",
      "Batch: 4225 Loss: 0.3506484627723694\n",
      "Batch: 4289 Loss: 0.37990692257881165\n",
      "Batch: 4353 Loss: 0.518974781036377\n",
      "Batch: 4417 Loss: 0.6986666321754456\n",
      "Batch: 4481 Loss: 0.7465181946754456\n",
      "Batch: 4545 Loss: 0.5841796398162842\n",
      "Batch: 4609 Loss: 0.38534659147262573\n",
      "Batch: 4673 Loss: 0.3665611445903778\n",
      "Batch: 4737 Loss: 0.4808867573738098\n",
      "Batch: 4801 Loss: 0.39234817028045654\n",
      "Batch: 4865 Loss: 0.40526846051216125\n",
      "Batch: 4929 Loss: 0.45551416277885437\n",
      "Batch: 4993 Loss: 0.5738269686698914\n",
      "Batch: 5057 Loss: 0.5548079609870911\n",
      "Batch: 5121 Loss: 0.4494078755378723\n",
      "Batch: 5185 Loss: 0.9589864611625671\n",
      "Batch: 5249 Loss: 0.39664849638938904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 5313 Loss: 0.48434343934059143\n",
      "Batch: 5377 Loss: 0.4442894160747528\n",
      "Batch: 5441 Loss: 0.557489275932312\n",
      "Batch: 5505 Loss: 0.5180889368057251\n",
      "Batch: 5569 Loss: 0.5508463382720947\n",
      "Batch: 5633 Loss: 0.3958415687084198\n",
      "Batch: 5697 Loss: 0.46721571683883667\n",
      "Batch: 5761 Loss: 0.581894040107727\n",
      "Batch: 5825 Loss: 0.4567033052444458\n",
      "Batch: 5889 Loss: 0.39762985706329346\n",
      "Batch: 5953 Loss: 0.40363436937332153\n",
      "Batch: 6017 Loss: 0.3447284996509552\n",
      "Batch: 6081 Loss: 0.348616361618042\n",
      "Batch: 6145 Loss: 0.4698852300643921\n",
      "Batch: 6209 Loss: 0.404718279838562\n",
      "Batch: 6273 Loss: 0.49045827984809875\n",
      "Batch: 6337 Loss: 0.3604257106781006\n",
      "Batch: 6401 Loss: 0.3545447289943695\n",
      "Batch: 6465 Loss: 0.406258761882782\n",
      "Batch: 6529 Loss: 0.3811805546283722\n",
      "Batch: 6593 Loss: 0.43032872676849365\n",
      "Batch: 6657 Loss: 0.34028857946395874\n",
      "Batch: 6721 Loss: 0.4817309081554413\n",
      "Batch: 6785 Loss: 0.47167328000068665\n",
      "Batch: 6849 Loss: 0.4683655798435211\n",
      "Batch: 6913 Loss: 0.4278320074081421\n",
      "Batch: 6977 Loss: 0.4509449601173401\n",
      "Batch: 7041 Loss: 0.4509012699127197\n",
      "Batch: 7105 Loss: 0.3751029968261719\n",
      "Batch: 7169 Loss: 0.44747382402420044\n",
      "Batch: 7233 Loss: 0.38883671164512634\n",
      "Batch: 7297 Loss: 0.43643176555633545\n",
      "Batch: 7361 Loss: 0.39938655495643616\n",
      "Batch: 7425 Loss: 0.4950750768184662\n",
      "Batch: 7489 Loss: 0.5932997465133667\n",
      "Batch: 7553 Loss: 0.38829663395881653\n",
      "Batch: 7617 Loss: 0.3834913671016693\n",
      "Batch: 7681 Loss: 0.47101515531539917\n",
      "Batch: 7745 Loss: 0.47935301065444946\n",
      "Batch: 7809 Loss: 0.44295331835746765\n",
      "Batch: 7873 Loss: 0.3738647997379303\n",
      "Batch: 7937 Loss: 0.5877763032913208\n",
      "Batch: 8001 Loss: 0.44985032081604004\n",
      "Batch: 8065 Loss: 0.5984639525413513\n",
      "Batch: 8129 Loss: 0.4543036222457886\n",
      "Batch: 8193 Loss: 0.4907378554344177\n",
      "Batch: 8257 Loss: 0.5189552903175354\n",
      "Batch: 8321 Loss: 0.6826264262199402\n",
      "Batch: 8385 Loss: 0.33036330342292786\n",
      "Batch: 8449 Loss: 0.3693962097167969\n",
      "Batch: 8513 Loss: 0.6675918102264404\n",
      "Batch: 8577 Loss: 0.3521497845649719\n",
      "Batch: 8641 Loss: 0.5440883040428162\n",
      "Batch: 8705 Loss: 0.44111737608909607\n",
      "Batch: 8769 Loss: 0.5059241652488708\n",
      "Batch: 8833 Loss: 0.5545966625213623\n",
      "Batch: 8897 Loss: 0.8413974642753601\n",
      "Batch: 8961 Loss: 0.4155905246734619\n",
      "Batch: 9025 Loss: 0.41156038641929626\n",
      "Batch: 9089 Loss: 0.4193131923675537\n",
      "Batch: 9153 Loss: 0.4903954565525055\n",
      "Batch: 9217 Loss: 0.5312028527259827\n",
      "Batch: 9281 Loss: 0.4978471100330353\n",
      "Batch: 9345 Loss: 0.4189617335796356\n",
      "Batch: 9409 Loss: 0.5608119368553162\n",
      "Batch: 9473 Loss: 0.6066315174102783\n",
      "Batch: 9537 Loss: 0.5119882822036743\n",
      "Batch: 9601 Loss: 0.38910046219825745\n",
      "Batch: 9665 Loss: 0.3592105507850647\n",
      "Batch: 9729 Loss: 0.4650822579860687\n",
      "Batch: 9793 Loss: 0.39662882685661316\n",
      "Batch: 9857 Loss: 0.4557591676712036\n",
      "Batch: 9921 Loss: 0.42612046003341675\n",
      "Batch: 9985 Loss: 0.4789280593395233\n",
      "Batch: 10049 Loss: 0.5546442866325378\n",
      "Batch: 10113 Loss: 0.4371423125267029\n",
      "Batch: 10177 Loss: 0.5139188170433044\n",
      "Batch: 10241 Loss: 0.38653165102005005\n",
      "Batch: 10305 Loss: 0.4630725681781769\n",
      "Batch: 10369 Loss: 0.5075362920761108\n",
      "Batch: 10433 Loss: 0.4201962351799011\n",
      "Batch: 10497 Loss: 0.41411614418029785\n",
      "Batch: 10561 Loss: 0.38531777262687683\n",
      "Batch: 10625 Loss: 0.4584985673427582\n",
      "Batch: 10689 Loss: 0.45183441042900085\n",
      "Batch: 10753 Loss: 0.37077224254608154\n",
      "Batch: 10817 Loss: 0.32677310705184937\n",
      "Batch: 10881 Loss: 0.37772560119628906\n",
      "Batch: 10945 Loss: 0.38093578815460205\n",
      "Batch: 11009 Loss: 0.4342406392097473\n",
      "Batch: 11073 Loss: 0.4786573350429535\n",
      "Batch: 11137 Loss: 0.39124974608421326\n",
      "Batch: 11201 Loss: 0.4159262180328369\n",
      "Batch: 11265 Loss: 0.5526955127716064\n",
      "Batch: 11329 Loss: 0.6904956102371216\n",
      "Batch: 11393 Loss: 0.3352093994617462\n",
      "Batch: 11457 Loss: 0.39703264832496643\n",
      "Batch: 11521 Loss: 0.413496196269989\n",
      "Batch: 11585 Loss: 0.5107977986335754\n",
      "Batch: 11649 Loss: 0.3483789563179016\n",
      "Batch: 11713 Loss: 0.45626574754714966\n",
      "Batch: 11777 Loss: 0.6376972794532776\n",
      "Batch: 11841 Loss: 0.602410614490509\n",
      "Batch: 11905 Loss: 0.483241468667984\n",
      "Batch: 11969 Loss: 0.4611527919769287\n",
      "Batch: 12033 Loss: 0.3902719020843506\n",
      "Batch: 12097 Loss: 0.9861571192741394\n",
      "Batch: 12161 Loss: 0.5402926802635193\n",
      "Batch: 12225 Loss: 0.3149791657924652\n",
      "Batch: 12289 Loss: 0.3330937623977661\n",
      "Batch: 12353 Loss: 0.45182326436042786\n",
      "Batch: 12417 Loss: 0.38687261939048767\n",
      "Batch: 12481 Loss: 0.419617623090744\n",
      "Batch: 12545 Loss: 0.5071552991867065\n",
      "Batch: 12609 Loss: 0.545341432094574\n",
      "Batch: 12673 Loss: 0.5718258619308472\n",
      "Batch: 12737 Loss: 0.47392165660858154\n",
      "Batch: 12801 Loss: 0.4008914828300476\n",
      "Batch: 12865 Loss: 0.34112444519996643\n",
      "Batch: 12929 Loss: 0.6978842616081238\n",
      "Epoch: 7\n",
      "Batch: 1 Loss: 0.4225771129131317\n",
      "Batch: 65 Loss: 0.4889536201953888\n",
      "Batch: 129 Loss: 0.41834378242492676\n",
      "Batch: 193 Loss: 0.605085551738739\n",
      "Batch: 257 Loss: 0.4215966463088989\n",
      "Batch: 321 Loss: 0.4170173704624176\n",
      "Batch: 385 Loss: 0.43008163571357727\n",
      "Batch: 449 Loss: 0.39202412962913513\n",
      "Batch: 513 Loss: 0.4064091145992279\n",
      "Batch: 577 Loss: 0.4032873809337616\n",
      "Batch: 641 Loss: 0.4823266863822937\n",
      "Batch: 705 Loss: 0.42080244421958923\n",
      "Batch: 769 Loss: 0.4848441481590271\n",
      "Batch: 833 Loss: 0.357313334941864\n",
      "Batch: 897 Loss: 0.5995675325393677\n",
      "Batch: 961 Loss: 0.3817569315433502\n",
      "Batch: 1025 Loss: 0.4125533699989319\n",
      "Batch: 1089 Loss: 0.40949761867523193\n",
      "Batch: 1153 Loss: 0.4441961944103241\n",
      "Batch: 1217 Loss: 0.4048227369785309\n",
      "Batch: 1281 Loss: 0.4403206706047058\n",
      "Batch: 1345 Loss: 0.44809490442276\n",
      "Batch: 1409 Loss: 0.3825398087501526\n",
      "Batch: 1473 Loss: 0.42584630846977234\n",
      "Batch: 1537 Loss: 0.397943913936615\n",
      "Batch: 1601 Loss: 0.34595975279808044\n",
      "Batch: 1665 Loss: 0.3830036520957947\n",
      "Batch: 1729 Loss: 0.45334088802337646\n",
      "Batch: 1793 Loss: 0.3468928635120392\n",
      "Batch: 1857 Loss: 0.4078930914402008\n",
      "Batch: 1921 Loss: 0.4639078378677368\n",
      "Batch: 1985 Loss: 0.3763623535633087\n",
      "Batch: 2049 Loss: 0.355033814907074\n",
      "Batch: 2113 Loss: 0.3965586721897125\n",
      "Batch: 2177 Loss: 0.44399455189704895\n",
      "Batch: 2241 Loss: 0.495850533246994\n",
      "Batch: 2305 Loss: 0.5275654792785645\n",
      "Batch: 2369 Loss: 0.5291332006454468\n",
      "Batch: 2433 Loss: 0.45238223671913147\n",
      "Batch: 2497 Loss: 0.5099279284477234\n",
      "Batch: 2561 Loss: 0.44018682837486267\n",
      "Batch: 2625 Loss: 0.44528210163116455\n",
      "Batch: 2689 Loss: 0.45980313420295715\n",
      "Batch: 2753 Loss: 0.3862890601158142\n",
      "Batch: 2817 Loss: 0.5657058954238892\n",
      "Batch: 2881 Loss: 0.4983639121055603\n",
      "Batch: 2945 Loss: 0.4340904951095581\n",
      "Batch: 3009 Loss: 0.5963834524154663\n",
      "Batch: 3073 Loss: 0.4739459156990051\n",
      "Batch: 3137 Loss: 0.43163901567459106\n",
      "Batch: 3201 Loss: 0.4042975902557373\n",
      "Batch: 3265 Loss: 0.38707998394966125\n",
      "Batch: 3329 Loss: 0.41821756958961487\n",
      "Batch: 3393 Loss: 0.4616325795650482\n",
      "Batch: 3457 Loss: 0.4257587492465973\n",
      "Batch: 3521 Loss: 0.3225414454936981\n",
      "Batch: 3585 Loss: 0.3117838203907013\n",
      "Batch: 3649 Loss: 0.5165061950683594\n",
      "Batch: 3713 Loss: 0.4230007529258728\n",
      "Batch: 3777 Loss: 0.45184817910194397\n",
      "Batch: 3841 Loss: 0.4523462951183319\n",
      "Batch: 3905 Loss: 0.4020068049430847\n",
      "Batch: 3969 Loss: 0.5597680807113647\n",
      "Batch: 4033 Loss: 0.424822598695755\n",
      "Batch: 4097 Loss: 0.4104814827442169\n",
      "Batch: 4161 Loss: 0.48449912667274475\n",
      "Batch: 4225 Loss: 0.3499952256679535\n",
      "Batch: 4289 Loss: 0.37648698687553406\n",
      "Batch: 4353 Loss: 0.5161790251731873\n",
      "Batch: 4417 Loss: 0.6855193376541138\n",
      "Batch: 4481 Loss: 0.7206026315689087\n",
      "Batch: 4545 Loss: 0.5826563835144043\n",
      "Batch: 4609 Loss: 0.386215478181839\n",
      "Batch: 4673 Loss: 0.3633156418800354\n",
      "Batch: 4737 Loss: 0.47489848732948303\n",
      "Batch: 4801 Loss: 0.3921073377132416\n",
      "Batch: 4865 Loss: 0.401082307100296\n",
      "Batch: 4929 Loss: 0.4443208873271942\n",
      "Batch: 4993 Loss: 0.5688913464546204\n",
      "Batch: 5057 Loss: 0.5520372986793518\n",
      "Batch: 5121 Loss: 0.4308066964149475\n",
      "Batch: 5185 Loss: 0.9035382270812988\n",
      "Batch: 5249 Loss: 0.3932090997695923\n",
      "Batch: 5313 Loss: 0.4696429669857025\n",
      "Batch: 5377 Loss: 0.44394955039024353\n",
      "Batch: 5441 Loss: 0.5510652661323547\n",
      "Batch: 5505 Loss: 0.5081972479820251\n",
      "Batch: 5569 Loss: 0.5423683524131775\n",
      "Batch: 5633 Loss: 0.3993366062641144\n",
      "Batch: 5697 Loss: 0.46469271183013916\n",
      "Batch: 5761 Loss: 0.5820609927177429\n",
      "Batch: 5825 Loss: 0.4524921774864197\n",
      "Batch: 5889 Loss: 0.39996978640556335\n",
      "Batch: 5953 Loss: 0.4003618061542511\n",
      "Batch: 6017 Loss: 0.34122416377067566\n",
      "Batch: 6081 Loss: 0.34249651432037354\n",
      "Batch: 6145 Loss: 0.45258036255836487\n",
      "Batch: 6209 Loss: 0.3873419463634491\n",
      "Batch: 6273 Loss: 0.4846297800540924\n",
      "Batch: 6337 Loss: 0.3546999990940094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 6401 Loss: 0.3510702848434448\n",
      "Batch: 6465 Loss: 0.39755502343177795\n",
      "Batch: 6529 Loss: 0.37318113446235657\n",
      "Batch: 6593 Loss: 0.41488325595855713\n",
      "Batch: 6657 Loss: 0.3361782431602478\n",
      "Batch: 6721 Loss: 0.47266584634780884\n",
      "Batch: 6785 Loss: 0.45642557740211487\n",
      "Batch: 6849 Loss: 0.46065640449523926\n",
      "Batch: 6913 Loss: 0.4182526469230652\n",
      "Batch: 6977 Loss: 0.44956448674201965\n",
      "Batch: 7041 Loss: 0.4385084807872772\n",
      "Batch: 7105 Loss: 0.3692711591720581\n",
      "Batch: 7169 Loss: 0.437688410282135\n",
      "Batch: 7233 Loss: 0.37859535217285156\n",
      "Batch: 7297 Loss: 0.4339654743671417\n",
      "Batch: 7361 Loss: 0.4048915207386017\n",
      "Batch: 7425 Loss: 0.49408289790153503\n",
      "Batch: 7489 Loss: 0.5898749828338623\n",
      "Batch: 7553 Loss: 0.3862212002277374\n",
      "Batch: 7617 Loss: 0.382123202085495\n",
      "Batch: 7681 Loss: 0.4649888873100281\n",
      "Batch: 7745 Loss: 0.477032333612442\n",
      "Batch: 7809 Loss: 0.4384867250919342\n",
      "Batch: 7873 Loss: 0.36704710125923157\n",
      "Batch: 7937 Loss: 0.580491840839386\n",
      "Batch: 8001 Loss: 0.4467097818851471\n",
      "Batch: 8065 Loss: 0.5894428491592407\n",
      "Batch: 8129 Loss: 0.4441564083099365\n",
      "Batch: 8193 Loss: 0.48645487427711487\n",
      "Batch: 8257 Loss: 0.5109451413154602\n",
      "Batch: 8321 Loss: 0.6752392649650574\n",
      "Batch: 8385 Loss: 0.3322262167930603\n",
      "Batch: 8449 Loss: 0.36785098910331726\n",
      "Batch: 8513 Loss: 0.6643725037574768\n",
      "Batch: 8577 Loss: 0.3517000377178192\n",
      "Batch: 8641 Loss: 0.536187469959259\n",
      "Batch: 8705 Loss: 0.4362669587135315\n",
      "Batch: 8769 Loss: 0.5006489753723145\n",
      "Batch: 8833 Loss: 0.5534249544143677\n",
      "Batch: 8897 Loss: 0.8378410339355469\n",
      "Batch: 8961 Loss: 0.4147511422634125\n",
      "Batch: 9025 Loss: 0.4068337082862854\n",
      "Batch: 9089 Loss: 0.4172460436820984\n",
      "Batch: 9153 Loss: 0.48521533608436584\n",
      "Batch: 9217 Loss: 0.5262894034385681\n",
      "Batch: 9281 Loss: 0.49161410331726074\n",
      "Batch: 9345 Loss: 0.4123789966106415\n",
      "Batch: 9409 Loss: 0.5555329918861389\n",
      "Batch: 9473 Loss: 0.6013715267181396\n",
      "Batch: 9537 Loss: 0.5010907649993896\n",
      "Batch: 9601 Loss: 0.38651177287101746\n",
      "Batch: 9665 Loss: 0.3581913411617279\n",
      "Batch: 9729 Loss: 0.46352988481521606\n",
      "Batch: 9793 Loss: 0.397832453250885\n",
      "Batch: 9857 Loss: 0.4514607787132263\n",
      "Batch: 9921 Loss: 0.42312848567962646\n",
      "Batch: 9985 Loss: 0.4741850793361664\n",
      "Batch: 10049 Loss: 0.5488361120223999\n",
      "Batch: 10113 Loss: 0.4321580231189728\n",
      "Batch: 10177 Loss: 0.5117576718330383\n",
      "Batch: 10241 Loss: 0.38639387488365173\n",
      "Batch: 10305 Loss: 0.46163836121559143\n",
      "Batch: 10369 Loss: 0.5031797289848328\n",
      "Batch: 10433 Loss: 0.41749030351638794\n",
      "Batch: 10497 Loss: 0.40979886054992676\n",
      "Batch: 10561 Loss: 0.3815275728702545\n",
      "Batch: 10625 Loss: 0.45581766963005066\n",
      "Batch: 10689 Loss: 0.44746366143226624\n",
      "Batch: 10753 Loss: 0.37079644203186035\n",
      "Batch: 10817 Loss: 0.32370102405548096\n",
      "Batch: 10881 Loss: 0.37573686242103577\n",
      "Batch: 10945 Loss: 0.3789110481739044\n",
      "Batch: 11009 Loss: 0.4320649206638336\n",
      "Batch: 11073 Loss: 0.47558286786079407\n",
      "Batch: 11137 Loss: 0.3898370563983917\n",
      "Batch: 11201 Loss: 0.410057008266449\n",
      "Batch: 11265 Loss: 0.5498766899108887\n",
      "Batch: 11329 Loss: 0.6834532022476196\n",
      "Batch: 11393 Loss: 0.32555457949638367\n",
      "Batch: 11457 Loss: 0.39364367723464966\n",
      "Batch: 11521 Loss: 0.4099884033203125\n",
      "Batch: 11585 Loss: 0.509607195854187\n",
      "Batch: 11649 Loss: 0.34604379534721375\n",
      "Batch: 11713 Loss: 0.45438098907470703\n",
      "Batch: 11777 Loss: 0.6351291537284851\n",
      "Batch: 11841 Loss: 0.5986412763595581\n",
      "Batch: 11905 Loss: 0.4804174602031708\n",
      "Batch: 11969 Loss: 0.4574224352836609\n",
      "Batch: 12033 Loss: 0.3880529999732971\n",
      "Batch: 12097 Loss: 0.9793605804443359\n",
      "Batch: 12161 Loss: 0.5381075143814087\n",
      "Batch: 12225 Loss: 0.31260553002357483\n",
      "Batch: 12289 Loss: 0.3319278061389923\n",
      "Batch: 12353 Loss: 0.4488527774810791\n",
      "Batch: 12417 Loss: 0.3833218216896057\n",
      "Batch: 12481 Loss: 0.416733056306839\n",
      "Batch: 12545 Loss: 0.5018433332443237\n",
      "Batch: 12609 Loss: 0.5420259237289429\n",
      "Batch: 12673 Loss: 0.5672057867050171\n",
      "Batch: 12737 Loss: 0.47053492069244385\n",
      "Batch: 12801 Loss: 0.39921078085899353\n",
      "Batch: 12865 Loss: 0.3375892639160156\n",
      "Batch: 12929 Loss: 0.6914545297622681\n",
      "Epoch: 8\n",
      "Batch: 1 Loss: 0.4226279854774475\n",
      "Batch: 65 Loss: 0.489838182926178\n",
      "Batch: 129 Loss: 0.4181095361709595\n",
      "Batch: 193 Loss: 0.611866295337677\n",
      "Batch: 257 Loss: 0.4274069666862488\n",
      "Batch: 321 Loss: 0.4167717397212982\n",
      "Batch: 385 Loss: 0.42795032262802124\n",
      "Batch: 449 Loss: 0.3922056257724762\n",
      "Batch: 513 Loss: 0.4077819585800171\n",
      "Batch: 577 Loss: 0.4044080972671509\n",
      "Batch: 641 Loss: 0.4818756878376007\n",
      "Batch: 705 Loss: 0.42225947976112366\n",
      "Batch: 769 Loss: 0.4809524714946747\n",
      "Batch: 833 Loss: 0.3542957603931427\n",
      "Batch: 897 Loss: 0.5923301577568054\n",
      "Batch: 961 Loss: 0.37888965010643005\n",
      "Batch: 1025 Loss: 0.41066256165504456\n",
      "Batch: 1089 Loss: 0.4049395024776459\n",
      "Batch: 1153 Loss: 0.4364641308784485\n",
      "Batch: 1217 Loss: 0.4020650088787079\n",
      "Batch: 1281 Loss: 0.43945467472076416\n",
      "Batch: 1345 Loss: 0.4429682791233063\n",
      "Batch: 1409 Loss: 0.3792169690132141\n",
      "Batch: 1473 Loss: 0.42779862880706787\n",
      "Batch: 1537 Loss: 0.40021488070487976\n",
      "Batch: 1601 Loss: 0.34638723731040955\n",
      "Batch: 1665 Loss: 0.38046199083328247\n",
      "Batch: 1729 Loss: 0.4518374800682068\n",
      "Batch: 1793 Loss: 0.3464524447917938\n",
      "Batch: 1857 Loss: 0.40580812096595764\n",
      "Batch: 1921 Loss: 0.46203556656837463\n",
      "Batch: 1985 Loss: 0.3773882985115051\n",
      "Batch: 2049 Loss: 0.3545722961425781\n",
      "Batch: 2113 Loss: 0.39217162132263184\n",
      "Batch: 2177 Loss: 0.441141813993454\n",
      "Batch: 2241 Loss: 0.4890565574169159\n",
      "Batch: 2305 Loss: 0.5197321772575378\n",
      "Batch: 2369 Loss: 0.5226849317550659\n",
      "Batch: 2433 Loss: 0.44966161251068115\n",
      "Batch: 2497 Loss: 0.5067427754402161\n",
      "Batch: 2561 Loss: 0.4384905695915222\n",
      "Batch: 2625 Loss: 0.4434007704257965\n",
      "Batch: 2689 Loss: 0.4589565098285675\n",
      "Batch: 2753 Loss: 0.3855448365211487\n",
      "Batch: 2817 Loss: 0.5617428421974182\n",
      "Batch: 2881 Loss: 0.4947369694709778\n",
      "Batch: 2945 Loss: 0.4285224974155426\n",
      "Batch: 3009 Loss: 0.5922076106071472\n",
      "Batch: 3073 Loss: 0.47165942192077637\n",
      "Batch: 3137 Loss: 0.4288947284221649\n",
      "Batch: 3201 Loss: 0.4018176198005676\n",
      "Batch: 3265 Loss: 0.3855176270008087\n",
      "Batch: 3329 Loss: 0.4164229929447174\n",
      "Batch: 3393 Loss: 0.45896923542022705\n",
      "Batch: 3457 Loss: 0.4232652187347412\n",
      "Batch: 3521 Loss: 0.32140418887138367\n",
      "Batch: 3585 Loss: 0.3102586269378662\n",
      "Batch: 3649 Loss: 0.5113967657089233\n",
      "Batch: 3713 Loss: 0.42088940739631653\n",
      "Batch: 3777 Loss: 0.4499834179878235\n",
      "Batch: 3841 Loss: 0.45052891969680786\n",
      "Batch: 3905 Loss: 0.40074342489242554\n",
      "Batch: 3969 Loss: 0.5591122508049011\n",
      "Batch: 4033 Loss: 0.423425555229187\n",
      "Batch: 4097 Loss: 0.4096817672252655\n",
      "Batch: 4161 Loss: 0.48123741149902344\n",
      "Batch: 4225 Loss: 0.3465895354747772\n",
      "Batch: 4289 Loss: 0.3745662569999695\n",
      "Batch: 4353 Loss: 0.510859489440918\n",
      "Batch: 4417 Loss: 0.6770755052566528\n",
      "Batch: 4481 Loss: 0.711246132850647\n",
      "Batch: 4545 Loss: 0.5781638622283936\n",
      "Batch: 4609 Loss: 0.3844715654850006\n",
      "Batch: 4673 Loss: 0.3624010384082794\n",
      "Batch: 4737 Loss: 0.4718838930130005\n",
      "Batch: 4801 Loss: 0.38926875591278076\n",
      "Batch: 4865 Loss: 0.3972647190093994\n",
      "Batch: 4929 Loss: 0.44192880392074585\n",
      "Batch: 4993 Loss: 0.565265417098999\n",
      "Batch: 5057 Loss: 0.5473277568817139\n",
      "Batch: 5121 Loss: 0.42566221952438354\n",
      "Batch: 5185 Loss: 0.8941565752029419\n",
      "Batch: 5249 Loss: 0.39169251918792725\n",
      "Batch: 5313 Loss: 0.46778425574302673\n",
      "Batch: 5377 Loss: 0.4426892399787903\n",
      "Batch: 5441 Loss: 0.5487439632415771\n",
      "Batch: 5505 Loss: 0.5054963827133179\n",
      "Batch: 5569 Loss: 0.5402987003326416\n",
      "Batch: 5633 Loss: 0.3979148268699646\n",
      "Batch: 5697 Loss: 0.4613371193408966\n",
      "Batch: 5761 Loss: 0.5799245238304138\n",
      "Batch: 5825 Loss: 0.44984331727027893\n",
      "Batch: 5889 Loss: 0.39799782633781433\n",
      "Batch: 5953 Loss: 0.39721736311912537\n",
      "Batch: 6017 Loss: 0.3377833068370819\n",
      "Batch: 6081 Loss: 0.3662393391132355\n",
      "Batch: 6145 Loss: 0.44891542196273804\n",
      "Batch: 6209 Loss: 0.3860270082950592\n",
      "Batch: 6273 Loss: 0.4829425513744354\n",
      "Batch: 6337 Loss: 0.3513808846473694\n",
      "Batch: 6401 Loss: 0.3486105501651764\n",
      "Batch: 6465 Loss: 0.39564889669418335\n",
      "Batch: 6529 Loss: 0.37256959080696106\n",
      "Batch: 6593 Loss: 0.4142361581325531\n",
      "Batch: 6657 Loss: 0.33464738726615906\n",
      "Batch: 6721 Loss: 0.47032660245895386\n",
      "Batch: 6785 Loss: 0.45350462198257446\n",
      "Batch: 6849 Loss: 0.46173229813575745\n",
      "Batch: 6913 Loss: 0.4178708493709564\n",
      "Batch: 6977 Loss: 0.4464699625968933\n",
      "Batch: 7041 Loss: 0.4356556236743927\n",
      "Batch: 7105 Loss: 0.36745208501815796\n",
      "Batch: 7169 Loss: 0.4343608617782593\n",
      "Batch: 7233 Loss: 0.37700048089027405\n",
      "Batch: 7297 Loss: 0.4321210980415344\n",
      "Batch: 7361 Loss: 0.40414372086524963\n",
      "Batch: 7425 Loss: 0.4918804466724396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 7489 Loss: 0.5867799520492554\n",
      "Batch: 7553 Loss: 0.384095162153244\n",
      "Batch: 7617 Loss: 0.38017961382865906\n",
      "Batch: 7681 Loss: 0.45951229333877563\n",
      "Batch: 7745 Loss: 0.47498416900634766\n",
      "Batch: 7809 Loss: 0.4361746311187744\n",
      "Batch: 7873 Loss: 0.3665572702884674\n",
      "Batch: 7937 Loss: 0.5800071358680725\n",
      "Batch: 8001 Loss: 0.4408547282218933\n",
      "Batch: 8065 Loss: 0.5861721634864807\n",
      "Batch: 8129 Loss: 0.44139277935028076\n",
      "Batch: 8193 Loss: 0.4848664700984955\n",
      "Batch: 8257 Loss: 0.5084599852561951\n",
      "Batch: 8321 Loss: 0.6706777811050415\n",
      "Batch: 8385 Loss: 0.33133646845817566\n",
      "Batch: 8449 Loss: 0.3665030002593994\n",
      "Batch: 8513 Loss: 0.6625804305076599\n",
      "Batch: 8577 Loss: 0.3506428599357605\n",
      "Batch: 8641 Loss: 0.5321930646896362\n",
      "Batch: 8705 Loss: 0.4333660900592804\n",
      "Batch: 8769 Loss: 0.49786266684532166\n",
      "Batch: 8833 Loss: 0.5505560636520386\n",
      "Batch: 8897 Loss: 0.8338812589645386\n",
      "Batch: 8961 Loss: 0.41271740198135376\n",
      "Batch: 9025 Loss: 0.405193030834198\n",
      "Batch: 9089 Loss: 0.4165351986885071\n",
      "Batch: 9153 Loss: 0.48232799768447876\n",
      "Batch: 9217 Loss: 0.523988664150238\n",
      "Batch: 9281 Loss: 0.48896369338035583\n",
      "Batch: 9345 Loss: 0.4110347628593445\n",
      "Batch: 9409 Loss: 0.5543367862701416\n",
      "Batch: 9473 Loss: 0.6016643643379211\n",
      "Batch: 9537 Loss: 0.5014520883560181\n",
      "Batch: 9601 Loss: 0.3842324912548065\n",
      "Batch: 9665 Loss: 0.3581829369068146\n",
      "Batch: 9729 Loss: 0.4638462960720062\n",
      "Batch: 9793 Loss: 0.39819762110710144\n",
      "Batch: 9857 Loss: 0.4499129056930542\n",
      "Batch: 9921 Loss: 0.42164134979248047\n",
      "Batch: 9985 Loss: 0.47157225012779236\n",
      "Batch: 10049 Loss: 0.5439521074295044\n",
      "Batch: 10113 Loss: 0.4295092523097992\n",
      "Batch: 10177 Loss: 0.5100369453430176\n",
      "Batch: 10241 Loss: 0.38470467925071716\n",
      "Batch: 10305 Loss: 0.45947301387786865\n",
      "Batch: 10369 Loss: 0.5006425976753235\n",
      "Batch: 10433 Loss: 0.4158932566642761\n",
      "Batch: 10497 Loss: 0.40743544697761536\n",
      "Batch: 10561 Loss: 0.3800009787082672\n",
      "Batch: 10625 Loss: 0.4548812806606293\n",
      "Batch: 10689 Loss: 0.4442001283168793\n",
      "Batch: 10753 Loss: 0.3684921860694885\n",
      "Batch: 10817 Loss: 0.3229973614215851\n",
      "Batch: 10881 Loss: 0.37411415576934814\n",
      "Batch: 10945 Loss: 0.3788304626941681\n",
      "Batch: 11009 Loss: 0.4281819760799408\n",
      "Batch: 11073 Loss: 0.47309425473213196\n",
      "Batch: 11137 Loss: 0.3881039023399353\n",
      "Batch: 11201 Loss: 0.4081272482872009\n",
      "Batch: 11265 Loss: 0.5482787489891052\n",
      "Batch: 11329 Loss: 0.6805353760719299\n",
      "Batch: 11393 Loss: 0.32245996594429016\n",
      "Batch: 11457 Loss: 0.3914722204208374\n",
      "Batch: 11521 Loss: 0.407844215631485\n",
      "Batch: 11585 Loss: 0.5072396397590637\n",
      "Batch: 11649 Loss: 0.34360402822494507\n",
      "Batch: 11713 Loss: 0.45188233256340027\n",
      "Batch: 11777 Loss: 0.6317211389541626\n",
      "Batch: 11841 Loss: 0.5964550375938416\n",
      "Batch: 11905 Loss: 0.47930434346199036\n",
      "Batch: 11969 Loss: 0.4544413089752197\n",
      "Batch: 12033 Loss: 0.38676121830940247\n",
      "Batch: 12097 Loss: 0.9751532077789307\n",
      "Batch: 12161 Loss: 0.5366665720939636\n",
      "Batch: 12225 Loss: 0.31057947874069214\n",
      "Batch: 12289 Loss: 0.3308309316635132\n",
      "Batch: 12353 Loss: 0.4472072124481201\n",
      "Batch: 12417 Loss: 0.3825031518936157\n",
      "Batch: 12481 Loss: 0.4154793620109558\n",
      "Batch: 12545 Loss: 0.4985930621623993\n",
      "Batch: 12609 Loss: 0.5400278568267822\n",
      "Batch: 12673 Loss: 0.5648210644721985\n",
      "Batch: 12737 Loss: 0.46909743547439575\n",
      "Batch: 12801 Loss: 0.3967861533164978\n",
      "Batch: 12865 Loss: 0.33581486344337463\n",
      "Batch: 12929 Loss: 0.6887405514717102\n",
      "Epoch: 9\n",
      "Batch: 1 Loss: 0.41953620314598083\n",
      "Batch: 65 Loss: 0.48374754190444946\n",
      "Batch: 129 Loss: 0.40825843811035156\n",
      "Batch: 193 Loss: 0.5895024538040161\n",
      "Batch: 257 Loss: 0.41907259821891785\n",
      "Batch: 321 Loss: 0.4366462826728821\n",
      "Batch: 385 Loss: 0.42054298520088196\n",
      "Batch: 449 Loss: 0.39119753241539\n",
      "Batch: 513 Loss: 0.40446195006370544\n",
      "Batch: 577 Loss: 0.404723584651947\n",
      "Batch: 641 Loss: 0.48679402470588684\n",
      "Batch: 705 Loss: 0.4279593229293823\n",
      "Batch: 769 Loss: 0.48210370540618896\n",
      "Batch: 833 Loss: 0.35331547260284424\n",
      "Batch: 897 Loss: 0.5954993367195129\n",
      "Batch: 961 Loss: 0.3838046193122864\n",
      "Batch: 1025 Loss: 0.41364678740501404\n",
      "Batch: 1089 Loss: 0.3988424241542816\n",
      "Batch: 1153 Loss: 0.44278833270072937\n",
      "Batch: 1217 Loss: 0.4002605080604553\n",
      "Batch: 1281 Loss: 0.4306935966014862\n",
      "Batch: 1345 Loss: 0.44158849120140076\n",
      "Batch: 1409 Loss: 0.376426637172699\n",
      "Batch: 1473 Loss: 0.4280126988887787\n",
      "Batch: 1537 Loss: 0.40273186564445496\n",
      "Batch: 1601 Loss: 0.3519880771636963\n",
      "Batch: 1665 Loss: 0.38712647557258606\n",
      "Batch: 1729 Loss: 0.4597662687301636\n",
      "Batch: 1793 Loss: 0.3520408570766449\n",
      "Batch: 1857 Loss: 0.40974050760269165\n",
      "Batch: 1921 Loss: 0.4733065068721771\n",
      "Batch: 1985 Loss: 0.3863866925239563\n",
      "Batch: 2049 Loss: 0.35991987586021423\n",
      "Batch: 2113 Loss: 0.3993532657623291\n",
      "Batch: 2177 Loss: 0.4558395743370056\n",
      "Batch: 2241 Loss: 0.5004212260246277\n",
      "Batch: 2305 Loss: 0.528438925743103\n",
      "Batch: 2369 Loss: 0.5355023145675659\n",
      "Batch: 2433 Loss: 0.45837894082069397\n",
      "Batch: 2497 Loss: 0.5227779150009155\n",
      "Batch: 2561 Loss: 0.449317991733551\n",
      "Batch: 2625 Loss: 0.44378477334976196\n",
      "Batch: 2689 Loss: 0.46218979358673096\n",
      "Batch: 2753 Loss: 0.38945096731185913\n",
      "Batch: 2817 Loss: 0.5716710090637207\n",
      "Batch: 2881 Loss: 0.5055322051048279\n",
      "Batch: 2945 Loss: 0.4377191364765167\n",
      "Batch: 3009 Loss: 0.6017929911613464\n",
      "Batch: 3073 Loss: 0.48153701424598694\n",
      "Batch: 3137 Loss: 0.433111310005188\n",
      "Batch: 3201 Loss: 0.4014090299606323\n",
      "Batch: 3265 Loss: 0.38690969347953796\n",
      "Batch: 3329 Loss: 0.4143706262111664\n",
      "Batch: 3393 Loss: 0.4587126672267914\n",
      "Batch: 3457 Loss: 0.4293997883796692\n",
      "Batch: 3521 Loss: 0.32020267844200134\n",
      "Batch: 3585 Loss: 0.3098149597644806\n",
      "Batch: 3649 Loss: 0.5131040215492249\n",
      "Batch: 3713 Loss: 0.4229251444339752\n",
      "Batch: 3777 Loss: 0.4512239396572113\n",
      "Batch: 3841 Loss: 0.45272597670555115\n",
      "Batch: 3905 Loss: 0.3967324495315552\n",
      "Batch: 3969 Loss: 0.5512580871582031\n",
      "Batch: 4033 Loss: 0.41444435715675354\n",
      "Batch: 4097 Loss: 0.40808504819869995\n",
      "Batch: 4161 Loss: 0.47843146324157715\n",
      "Batch: 4225 Loss: 0.34690091013908386\n",
      "Batch: 4289 Loss: 0.37099334597587585\n",
      "Batch: 4353 Loss: 0.5101810693740845\n",
      "Batch: 4417 Loss: 0.6820080876350403\n",
      "Batch: 4481 Loss: 0.7226042151451111\n",
      "Batch: 4545 Loss: 0.5778042078018188\n",
      "Batch: 4609 Loss: 0.3820936679840088\n",
      "Batch: 4673 Loss: 0.362428218126297\n",
      "Batch: 4737 Loss: 0.4701472222805023\n",
      "Batch: 4801 Loss: 0.3886663317680359\n",
      "Batch: 4865 Loss: 0.3965199887752533\n",
      "Batch: 4929 Loss: 0.4430887699127197\n",
      "Batch: 4993 Loss: 0.5764761567115784\n",
      "Batch: 5057 Loss: 0.5544869303703308\n",
      "Batch: 5121 Loss: 0.4360671639442444\n",
      "Batch: 5185 Loss: 0.9081534147262573\n",
      "Batch: 5249 Loss: 0.38881850242614746\n",
      "Batch: 5313 Loss: 0.4621744751930237\n",
      "Batch: 5377 Loss: 0.43823641538619995\n",
      "Batch: 5441 Loss: 0.5438157320022583\n",
      "Batch: 5505 Loss: 0.5030038356781006\n",
      "Batch: 5569 Loss: 0.5395362377166748\n",
      "Batch: 5633 Loss: 0.39355164766311646\n",
      "Batch: 5697 Loss: 0.45778888463974\n",
      "Batch: 5761 Loss: 0.575684130191803\n",
      "Batch: 5825 Loss: 0.44809210300445557\n",
      "Batch: 5889 Loss: 0.39811769127845764\n",
      "Batch: 5953 Loss: 0.3961183428764343\n",
      "Batch: 6017 Loss: 0.33709996938705444\n",
      "Batch: 6081 Loss: 0.3349530100822449\n",
      "Batch: 6145 Loss: 0.4462282657623291\n",
      "Batch: 6209 Loss: 0.3857857584953308\n",
      "Batch: 6273 Loss: 0.48057684302330017\n",
      "Batch: 6337 Loss: 0.3508836627006531\n",
      "Batch: 6401 Loss: 0.3487606942653656\n",
      "Batch: 6465 Loss: 0.39284008741378784\n",
      "Batch: 6529 Loss: 0.3707934319972992\n",
      "Batch: 6593 Loss: 0.41156843304634094\n",
      "Batch: 6657 Loss: 0.3345334827899933\n",
      "Batch: 6721 Loss: 0.46397584676742554\n",
      "Batch: 6785 Loss: 0.4513404667377472\n",
      "Batch: 6849 Loss: 0.456127792596817\n",
      "Batch: 6913 Loss: 0.41636836528778076\n",
      "Batch: 6977 Loss: 0.4451521635055542\n",
      "Batch: 7041 Loss: 0.4370134472846985\n",
      "Batch: 7105 Loss: 0.36726608872413635\n",
      "Batch: 7169 Loss: 0.4331049621105194\n",
      "Batch: 7233 Loss: 0.37619656324386597\n",
      "Batch: 7297 Loss: 0.4321105480194092\n",
      "Batch: 7361 Loss: 0.40373775362968445\n",
      "Batch: 7425 Loss: 0.48950091004371643\n",
      "Batch: 7489 Loss: 0.5860637426376343\n",
      "Batch: 7553 Loss: 0.3840731978416443\n",
      "Batch: 7617 Loss: 0.37887683510780334\n",
      "Batch: 7681 Loss: 0.4598764479160309\n",
      "Batch: 7745 Loss: 0.47258907556533813\n",
      "Batch: 7809 Loss: 0.4362824261188507\n",
      "Batch: 7873 Loss: 0.36460116505622864\n",
      "Batch: 7937 Loss: 0.579156219959259\n",
      "Batch: 8001 Loss: 0.4375760555267334\n",
      "Batch: 8065 Loss: 0.5823182463645935\n",
      "Batch: 8129 Loss: 0.4391201436519623\n",
      "Batch: 8193 Loss: 0.4867883622646332\n",
      "Batch: 8257 Loss: 0.5086498856544495\n",
      "Batch: 8321 Loss: 0.6670559644699097\n",
      "Batch: 8385 Loss: 0.3314860761165619\n",
      "Batch: 8449 Loss: 0.36573389172554016\n",
      "Batch: 8513 Loss: 0.659675657749176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 8577 Loss: 0.3498382568359375\n",
      "Batch: 8641 Loss: 0.5290856957435608\n",
      "Batch: 8705 Loss: 0.4311653971672058\n",
      "Batch: 8769 Loss: 0.49630478024482727\n",
      "Batch: 8833 Loss: 0.5484781861305237\n",
      "Batch: 8897 Loss: 0.8286666870117188\n",
      "Batch: 8961 Loss: 0.4117898643016815\n",
      "Batch: 9025 Loss: 0.40397799015045166\n",
      "Batch: 9089 Loss: 0.41291195154190063\n",
      "Batch: 9153 Loss: 0.48010870814323425\n",
      "Batch: 9217 Loss: 0.521775484085083\n",
      "Batch: 9281 Loss: 0.4854084253311157\n",
      "Batch: 9345 Loss: 0.4092591106891632\n",
      "Batch: 9409 Loss: 0.5517395734786987\n",
      "Batch: 9473 Loss: 0.5985656976699829\n",
      "Batch: 9537 Loss: 0.5069575905799866\n",
      "Batch: 9601 Loss: 0.3860846757888794\n",
      "Batch: 9665 Loss: 0.35598841309547424\n",
      "Batch: 9729 Loss: 0.461126446723938\n",
      "Batch: 9793 Loss: 0.3978809118270874\n",
      "Batch: 9857 Loss: 0.4478808045387268\n",
      "Batch: 9921 Loss: 0.4199528098106384\n",
      "Batch: 9985 Loss: 0.470756858587265\n",
      "Batch: 10049 Loss: 0.5407199859619141\n",
      "Batch: 10113 Loss: 0.42771032452583313\n",
      "Batch: 10177 Loss: 0.5078105330467224\n",
      "Batch: 10241 Loss: 0.38435280323028564\n",
      "Batch: 10305 Loss: 0.45834359526634216\n",
      "Batch: 10369 Loss: 0.4995620548725128\n",
      "Batch: 10433 Loss: 0.4155500531196594\n",
      "Batch: 10497 Loss: 0.40630900859832764\n",
      "Batch: 10561 Loss: 0.3774964213371277\n",
      "Batch: 10625 Loss: 0.4525192677974701\n",
      "Batch: 10689 Loss: 0.44178512692451477\n",
      "Batch: 10753 Loss: 0.36783432960510254\n",
      "Batch: 10817 Loss: 0.3233756721019745\n",
      "Batch: 10881 Loss: 0.37376686930656433\n",
      "Batch: 10945 Loss: 0.3763321042060852\n",
      "Batch: 11009 Loss: 0.42480283975601196\n",
      "Batch: 11073 Loss: 0.4715944826602936\n",
      "Batch: 11137 Loss: 0.3870488405227661\n",
      "Batch: 11201 Loss: 0.40539705753326416\n",
      "Batch: 11265 Loss: 0.5462021231651306\n",
      "Batch: 11329 Loss: 0.6768737435340881\n",
      "Batch: 11393 Loss: 0.32112032175064087\n",
      "Batch: 11457 Loss: 0.3918423354625702\n",
      "Batch: 11521 Loss: 0.40738898515701294\n",
      "Batch: 11585 Loss: 0.5044127702713013\n",
      "Batch: 11649 Loss: 0.3426046073436737\n",
      "Batch: 11713 Loss: 0.4495944082736969\n",
      "Batch: 11777 Loss: 0.6292499303817749\n",
      "Batch: 11841 Loss: 0.5935950875282288\n",
      "Batch: 11905 Loss: 0.4770885109901428\n",
      "Batch: 11969 Loss: 0.45509541034698486\n",
      "Batch: 12033 Loss: 0.38536927103996277\n",
      "Batch: 12097 Loss: 0.9697717428207397\n",
      "Batch: 12161 Loss: 0.5349459648132324\n",
      "Batch: 12225 Loss: 0.3099242150783539\n",
      "Batch: 12289 Loss: 0.32997003197669983\n",
      "Batch: 12353 Loss: 0.4450952410697937\n",
      "Batch: 12417 Loss: 0.3813598155975342\n",
      "Batch: 12481 Loss: 0.41485369205474854\n",
      "Batch: 12545 Loss: 0.4960034191608429\n",
      "Batch: 12609 Loss: 0.5376847982406616\n",
      "Batch: 12673 Loss: 0.5630887150764465\n",
      "Batch: 12737 Loss: 0.4670681357383728\n",
      "Batch: 12801 Loss: 0.39498791098594666\n",
      "Batch: 12865 Loss: 0.33459582924842834\n",
      "Batch: 12929 Loss: 0.684415340423584\n",
      "Epoch: 10\n",
      "Batch: 1 Loss: 0.4195500612258911\n",
      "Batch: 65 Loss: 0.48394763469696045\n",
      "Batch: 129 Loss: 0.4050511121749878\n",
      "Batch: 193 Loss: 0.6113075017929077\n",
      "Batch: 257 Loss: 0.42967307567596436\n",
      "Batch: 321 Loss: 0.41845259070396423\n",
      "Batch: 385 Loss: 0.42503008246421814\n",
      "Batch: 449 Loss: 0.3916495144367218\n",
      "Batch: 513 Loss: 0.4042641520500183\n",
      "Batch: 577 Loss: 0.40070006251335144\n",
      "Batch: 641 Loss: 0.47736769914627075\n",
      "Batch: 705 Loss: 0.42029818892478943\n",
      "Batch: 769 Loss: 0.4774792492389679\n",
      "Batch: 833 Loss: 0.353688508272171\n",
      "Batch: 897 Loss: 0.5875285863876343\n",
      "Batch: 961 Loss: 0.3786005675792694\n",
      "Batch: 1025 Loss: 0.4088519215583801\n",
      "Batch: 1089 Loss: 0.3998807370662689\n",
      "Batch: 1153 Loss: 0.4350664019584656\n",
      "Batch: 1217 Loss: 0.39821943640708923\n",
      "Batch: 1281 Loss: 0.4308570623397827\n",
      "Batch: 1345 Loss: 0.438912034034729\n",
      "Batch: 1409 Loss: 0.3757992088794708\n",
      "Batch: 1473 Loss: 0.4251939058303833\n",
      "Batch: 1537 Loss: 0.39708849787712097\n",
      "Batch: 1601 Loss: 0.3431497812271118\n",
      "Batch: 1665 Loss: 0.37661436200141907\n",
      "Batch: 1729 Loss: 0.44744762778282166\n",
      "Batch: 1793 Loss: 0.3453924059867859\n",
      "Batch: 1857 Loss: 0.4016001224517822\n",
      "Batch: 1921 Loss: 0.45722973346710205\n",
      "Batch: 1985 Loss: 0.374591588973999\n",
      "Batch: 2049 Loss: 0.35240522027015686\n",
      "Batch: 2113 Loss: 0.3893982172012329\n",
      "Batch: 2177 Loss: 0.4383515417575836\n",
      "Batch: 2241 Loss: 0.4833877980709076\n",
      "Batch: 2305 Loss: 0.5156410336494446\n",
      "Batch: 2369 Loss: 0.5187647342681885\n",
      "Batch: 2433 Loss: 0.4454016387462616\n",
      "Batch: 2497 Loss: 0.5028954744338989\n",
      "Batch: 2561 Loss: 0.43392041325569153\n",
      "Batch: 2625 Loss: 0.4405829906463623\n",
      "Batch: 2689 Loss: 0.4565710127353668\n",
      "Batch: 2753 Loss: 0.3827987313270569\n",
      "Batch: 2817 Loss: 0.556574285030365\n",
      "Batch: 2881 Loss: 0.49178096652030945\n",
      "Batch: 2945 Loss: 0.42489975690841675\n",
      "Batch: 3009 Loss: 0.5868587493896484\n",
      "Batch: 3073 Loss: 0.4681611955165863\n",
      "Batch: 3137 Loss: 0.4259718656539917\n",
      "Batch: 3201 Loss: 0.39828070998191833\n",
      "Batch: 3265 Loss: 0.38314124941825867\n",
      "Batch: 3329 Loss: 0.41330087184906006\n",
      "Batch: 3393 Loss: 0.4553412199020386\n",
      "Batch: 3457 Loss: 0.4211822748184204\n",
      "Batch: 3521 Loss: 0.3205479383468628\n",
      "Batch: 3585 Loss: 0.3082285523414612\n",
      "Batch: 3649 Loss: 0.5070944428443909\n",
      "Batch: 3713 Loss: 0.41785112023353577\n",
      "Batch: 3777 Loss: 0.44598910212516785\n",
      "Batch: 3841 Loss: 0.4464288353919983\n",
      "Batch: 3905 Loss: 0.3977869749069214\n",
      "Batch: 3969 Loss: 0.5538982152938843\n",
      "Batch: 4033 Loss: 0.4171110987663269\n",
      "Batch: 4097 Loss: 0.40707558393478394\n",
      "Batch: 4161 Loss: 0.47653141617774963\n",
      "Batch: 4225 Loss: 0.3441665470600128\n",
      "Batch: 4289 Loss: 0.3708391487598419\n",
      "Batch: 4353 Loss: 0.5078967213630676\n",
      "Batch: 4417 Loss: 0.6749292016029358\n",
      "Batch: 4481 Loss: 0.7166751027107239\n",
      "Batch: 4545 Loss: 0.575743556022644\n",
      "Batch: 4609 Loss: 0.38187673687934875\n",
      "Batch: 4673 Loss: 0.3612333834171295\n",
      "Batch: 4737 Loss: 0.46786874532699585\n",
      "Batch: 4801 Loss: 0.38690218329429626\n",
      "Batch: 4865 Loss: 0.3942977488040924\n",
      "Batch: 4929 Loss: 0.439794659614563\n",
      "Batch: 4993 Loss: 0.5635542273521423\n",
      "Batch: 5057 Loss: 0.5440881848335266\n",
      "Batch: 5121 Loss: 0.4246186912059784\n",
      "Batch: 5185 Loss: 0.8909164071083069\n",
      "Batch: 5249 Loss: 0.3889213800430298\n",
      "Batch: 5313 Loss: 0.46505260467529297\n",
      "Batch: 5377 Loss: 0.4401177167892456\n",
      "Batch: 5441 Loss: 0.5426689386367798\n",
      "Batch: 5505 Loss: 0.5026031136512756\n",
      "Batch: 5569 Loss: 0.5353302955627441\n",
      "Batch: 5633 Loss: 0.3957153856754303\n",
      "Batch: 5697 Loss: 0.4578424394130707\n",
      "Batch: 5761 Loss: 0.577041745185852\n",
      "Batch: 5825 Loss: 0.4457859396934509\n",
      "Batch: 5889 Loss: 0.3944920003414154\n",
      "Batch: 5953 Loss: 0.39430350065231323\n",
      "Batch: 6017 Loss: 0.3365519642829895\n",
      "Batch: 6081 Loss: 0.3357352614402771\n",
      "Batch: 6145 Loss: 0.45038041472435\n",
      "Batch: 6209 Loss: 0.38363000750541687\n",
      "Batch: 6273 Loss: 0.47924578189849854\n",
      "Batch: 6337 Loss: 0.3486793339252472\n",
      "Batch: 6401 Loss: 0.3473111689090729\n",
      "Batch: 6465 Loss: 0.3929356038570404\n",
      "Batch: 6529 Loss: 0.37051716446876526\n",
      "Batch: 6593 Loss: 0.4099408984184265\n",
      "Batch: 6657 Loss: 0.3322724997997284\n",
      "Batch: 6721 Loss: 0.4678771197795868\n",
      "Batch: 6785 Loss: 0.4508991241455078\n",
      "Batch: 6849 Loss: 0.4590609669685364\n",
      "Batch: 6913 Loss: 0.4137336015701294\n",
      "Batch: 6977 Loss: 0.4438956677913666\n",
      "Batch: 7041 Loss: 0.4321156144142151\n",
      "Batch: 7105 Loss: 0.3643271028995514\n",
      "Batch: 7169 Loss: 0.431688129901886\n",
      "Batch: 7233 Loss: 0.3748840391635895\n",
      "Batch: 7297 Loss: 0.4291965663433075\n",
      "Batch: 7361 Loss: 0.4016401171684265\n",
      "Batch: 7425 Loss: 0.4877631366252899\n",
      "Batch: 7489 Loss: 0.5820748209953308\n",
      "Batch: 7553 Loss: 0.38126471638679504\n",
      "Batch: 7617 Loss: 0.37687453627586365\n",
      "Batch: 7681 Loss: 0.45674729347229004\n",
      "Batch: 7745 Loss: 0.4720323383808136\n",
      "Batch: 7809 Loss: 0.43245580792427063\n",
      "Batch: 7873 Loss: 0.3632791042327881\n",
      "Batch: 7937 Loss: 0.5750548243522644\n",
      "Batch: 8001 Loss: 0.4373851716518402\n",
      "Batch: 8065 Loss: 0.5815520882606506\n",
      "Batch: 8129 Loss: 0.4393341541290283\n",
      "Batch: 8193 Loss: 0.4817720949649811\n",
      "Batch: 8257 Loss: 0.503746747970581\n",
      "Batch: 8321 Loss: 0.6645104289054871\n",
      "Batch: 8385 Loss: 0.329855740070343\n",
      "Batch: 8449 Loss: 0.36413151025772095\n",
      "Batch: 8513 Loss: 0.6587774753570557\n",
      "Batch: 8577 Loss: 0.3485625684261322\n",
      "Batch: 8641 Loss: 0.5276052355766296\n",
      "Batch: 8705 Loss: 0.4313063323497772\n",
      "Batch: 8769 Loss: 0.4947347044944763\n",
      "Batch: 8833 Loss: 0.5462889671325684\n",
      "Batch: 8897 Loss: 0.8266579508781433\n",
      "Batch: 8961 Loss: 0.410603791475296\n",
      "Batch: 9025 Loss: 0.4027251601219177\n",
      "Batch: 9089 Loss: 0.41427358984947205\n",
      "Batch: 9153 Loss: 0.47827357053756714\n",
      "Batch: 9217 Loss: 0.5201598405838013\n",
      "Batch: 9281 Loss: 0.4860142171382904\n",
      "Batch: 9345 Loss: 0.4093674123287201\n",
      "Batch: 9409 Loss: 0.5514779686927795\n",
      "Batch: 9473 Loss: 0.5984077453613281\n",
      "Batch: 9537 Loss: 0.4994041323661804\n",
      "Batch: 9601 Loss: 0.3816620111465454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 9665 Loss: 0.355572372674942\n",
      "Batch: 9729 Loss: 0.4599306583404541\n",
      "Batch: 9793 Loss: 0.39572760462760925\n",
      "Batch: 9857 Loss: 0.4474957585334778\n",
      "Batch: 9921 Loss: 0.4190785586833954\n",
      "Batch: 9985 Loss: 0.46943676471710205\n",
      "Batch: 10049 Loss: 0.5404919981956482\n",
      "Batch: 10113 Loss: 0.4260093867778778\n",
      "Batch: 10177 Loss: 0.5053431987762451\n",
      "Batch: 10241 Loss: 0.38361990451812744\n",
      "Batch: 10305 Loss: 0.45634686946868896\n",
      "Batch: 10369 Loss: 0.4970240294933319\n",
      "Batch: 10433 Loss: 0.41351425647735596\n",
      "Batch: 10497 Loss: 0.40478256344795227\n",
      "Batch: 10561 Loss: 0.3777671456336975\n",
      "Batch: 10625 Loss: 0.45071151852607727\n",
      "Batch: 10689 Loss: 0.44442126154899597\n",
      "Batch: 10753 Loss: 0.36659133434295654\n",
      "Batch: 10817 Loss: 0.3197195529937744\n",
      "Batch: 10881 Loss: 0.3729270100593567\n",
      "Batch: 10945 Loss: 0.3771483600139618\n",
      "Batch: 11009 Loss: 0.42786458134651184\n",
      "Batch: 11073 Loss: 0.4710348844528198\n",
      "Batch: 11137 Loss: 0.3863922357559204\n",
      "Batch: 11201 Loss: 0.4052545428276062\n",
      "Batch: 11265 Loss: 0.5458420515060425\n",
      "Batch: 11329 Loss: 0.6762198805809021\n",
      "Batch: 11393 Loss: 0.319644033908844\n",
      "Batch: 11457 Loss: 0.39003434777259827\n",
      "Batch: 11521 Loss: 0.40569427609443665\n",
      "Batch: 11585 Loss: 0.5043803453445435\n",
      "Batch: 11649 Loss: 0.37306249141693115\n",
      "Batch: 11713 Loss: 0.5029686689376831\n",
      "Batch: 11777 Loss: 0.6638855338096619\n",
      "Batch: 11841 Loss: 0.6319108605384827\n",
      "Batch: 11905 Loss: 0.5164404511451721\n",
      "Batch: 11969 Loss: 0.49994006752967834\n",
      "Batch: 12033 Loss: 0.40579625964164734\n",
      "Batch: 12097 Loss: 0.9653045535087585\n",
      "Batch: 12161 Loss: 0.5425224304199219\n",
      "Batch: 12225 Loss: 0.32490789890289307\n",
      "Batch: 12289 Loss: 0.35526224970817566\n",
      "Batch: 12353 Loss: 0.4791068136692047\n",
      "Batch: 12417 Loss: 0.41363391280174255\n",
      "Batch: 12481 Loss: 0.44166383147239685\n",
      "Batch: 12545 Loss: 0.5143399834632874\n",
      "Batch: 12609 Loss: 0.565741777420044\n",
      "Batch: 12673 Loss: 0.591806948184967\n",
      "Batch: 12737 Loss: 0.47923246026039124\n",
      "Batch: 12801 Loss: 0.4179286062717438\n",
      "Batch: 12865 Loss: 0.3479551374912262\n",
      "Batch: 12929 Loss: 0.6883934140205383\n",
      "Epoch: 11\n",
      "Batch: 1 Loss: 0.4082544445991516\n",
      "Batch: 65 Loss: 0.4784342348575592\n",
      "Batch: 129 Loss: 0.4149598181247711\n",
      "Batch: 193 Loss: 0.6184867024421692\n",
      "Batch: 257 Loss: 0.44230687618255615\n",
      "Batch: 321 Loss: 0.4221739172935486\n",
      "Batch: 385 Loss: 0.4256938695907593\n",
      "Batch: 449 Loss: 0.3899851441383362\n",
      "Batch: 513 Loss: 0.410284161567688\n",
      "Batch: 577 Loss: 0.4059242904186249\n",
      "Batch: 641 Loss: 0.4935910999774933\n",
      "Batch: 705 Loss: 0.4361860752105713\n",
      "Batch: 769 Loss: 0.48870664834976196\n",
      "Batch: 833 Loss: 0.3614325225353241\n",
      "Batch: 897 Loss: 0.5901822447776794\n",
      "Batch: 961 Loss: 0.3910919427871704\n",
      "Batch: 1025 Loss: 0.4205368459224701\n",
      "Batch: 1089 Loss: 0.40715113282203674\n",
      "Batch: 1153 Loss: 0.456900954246521\n",
      "Batch: 1217 Loss: 0.40635570883750916\n",
      "Batch: 1281 Loss: 0.4295043647289276\n",
      "Batch: 1345 Loss: 0.4464814066886902\n",
      "Batch: 1409 Loss: 0.37031862139701843\n",
      "Batch: 1473 Loss: 0.42317402362823486\n",
      "Batch: 1537 Loss: 0.4046250283718109\n",
      "Batch: 1601 Loss: 0.3498108685016632\n",
      "Batch: 1665 Loss: 0.38807493448257446\n",
      "Batch: 1729 Loss: 0.45696866512298584\n",
      "Batch: 1793 Loss: 0.36083561182022095\n",
      "Batch: 1857 Loss: 0.41098639369010925\n",
      "Batch: 1921 Loss: 0.4783424139022827\n",
      "Batch: 1985 Loss: 0.3906422555446625\n",
      "Batch: 2049 Loss: 0.3638146221637726\n",
      "Batch: 2113 Loss: 0.3977484405040741\n",
      "Batch: 2177 Loss: 0.45705118775367737\n",
      "Batch: 2241 Loss: 0.4921557903289795\n",
      "Batch: 2305 Loss: 0.5266188979148865\n",
      "Batch: 2369 Loss: 0.533136785030365\n",
      "Batch: 2433 Loss: 0.4538918733596802\n",
      "Batch: 2497 Loss: 0.5168810486793518\n",
      "Batch: 2561 Loss: 0.4475862383842468\n",
      "Batch: 2625 Loss: 0.44093194603919983\n",
      "Batch: 2689 Loss: 0.4629976451396942\n",
      "Batch: 2753 Loss: 0.3908712863922119\n",
      "Batch: 2817 Loss: 0.5704985857009888\n",
      "Batch: 2881 Loss: 0.5035021305084229\n",
      "Batch: 2945 Loss: 0.4356533885002136\n",
      "Batch: 3009 Loss: 0.5913872122764587\n",
      "Batch: 3073 Loss: 0.4749740958213806\n",
      "Batch: 3137 Loss: 0.4316403269767761\n",
      "Batch: 3201 Loss: 0.40118035674095154\n",
      "Batch: 3265 Loss: 0.38686373829841614\n",
      "Batch: 3329 Loss: 0.4124431014060974\n",
      "Batch: 3393 Loss: 0.46030962467193604\n",
      "Batch: 3457 Loss: 0.4305911660194397\n",
      "Batch: 3521 Loss: 0.32196369767189026\n",
      "Batch: 3585 Loss: 0.3095729947090149\n",
      "Batch: 3649 Loss: 0.515206515789032\n",
      "Batch: 3713 Loss: 0.42227795720100403\n",
      "Batch: 3777 Loss: 0.4483909606933594\n",
      "Batch: 3841 Loss: 0.4438740611076355\n",
      "Batch: 3905 Loss: 0.3923848867416382\n",
      "Batch: 3969 Loss: 0.5431875586509705\n",
      "Batch: 4033 Loss: 0.4125235974788666\n",
      "Batch: 4097 Loss: 0.4087282717227936\n",
      "Batch: 4161 Loss: 0.4728580415248871\n",
      "Batch: 4225 Loss: 0.34635481238365173\n",
      "Batch: 4289 Loss: 0.37059909105300903\n",
      "Batch: 4353 Loss: 0.5046024322509766\n",
      "Batch: 4417 Loss: 0.672206699848175\n",
      "Batch: 4481 Loss: 0.7207953929901123\n",
      "Batch: 4545 Loss: 0.5736469030380249\n",
      "Batch: 4609 Loss: 0.38027480244636536\n",
      "Batch: 4673 Loss: 0.36022046208381653\n",
      "Batch: 4737 Loss: 0.46873924136161804\n",
      "Batch: 4801 Loss: 0.3873256742954254\n",
      "Batch: 4865 Loss: 0.3958827555179596\n",
      "Batch: 4929 Loss: 0.4427975118160248\n",
      "Batch: 4993 Loss: 0.5645456910133362\n",
      "Batch: 5057 Loss: 0.5429362654685974\n",
      "Batch: 5121 Loss: 0.425071656703949\n",
      "Batch: 5185 Loss: 0.8961970806121826\n",
      "Batch: 5249 Loss: 0.38719442486763\n",
      "Batch: 5313 Loss: 0.46300944685935974\n",
      "Batch: 5377 Loss: 0.43845999240875244\n",
      "Batch: 5441 Loss: 0.5430845618247986\n",
      "Batch: 5505 Loss: 0.5005616545677185\n",
      "Batch: 5569 Loss: 0.5335404276847839\n",
      "Batch: 5633 Loss: 0.39033177495002747\n",
      "Batch: 5697 Loss: 0.4523865282535553\n",
      "Batch: 5761 Loss: 0.5719597339630127\n",
      "Batch: 5825 Loss: 0.44770175218582153\n",
      "Batch: 5889 Loss: 0.3952067196369171\n",
      "Batch: 5953 Loss: 0.39517101645469666\n",
      "Batch: 6017 Loss: 0.3387049436569214\n",
      "Batch: 6081 Loss: 0.3318248987197876\n",
      "Batch: 6145 Loss: 0.44276872277259827\n",
      "Batch: 6209 Loss: 0.3807865083217621\n",
      "Batch: 6273 Loss: 0.47626951336860657\n",
      "Batch: 6337 Loss: 0.34852924942970276\n",
      "Batch: 6401 Loss: 0.34790167212486267\n",
      "Batch: 6465 Loss: 0.39376676082611084\n",
      "Batch: 6529 Loss: 0.3704759478569031\n",
      "Batch: 6593 Loss: 0.4083646237850189\n",
      "Batch: 6657 Loss: 0.3320421278476715\n",
      "Batch: 6721 Loss: 0.464869886636734\n",
      "Batch: 6785 Loss: 0.47274836897850037\n",
      "Batch: 6849 Loss: 0.4520915746688843\n",
      "Batch: 6913 Loss: 0.41560080647468567\n",
      "Batch: 6977 Loss: 0.44167351722717285\n",
      "Batch: 7041 Loss: 0.43105217814445496\n",
      "Batch: 7105 Loss: 0.36389991641044617\n",
      "Batch: 7169 Loss: 0.4321385622024536\n",
      "Batch: 7233 Loss: 0.3722030520439148\n",
      "Batch: 7297 Loss: 0.42787471413612366\n",
      "Batch: 7361 Loss: 0.39942747354507446\n",
      "Batch: 7425 Loss: 0.48754948377609253\n",
      "Batch: 7489 Loss: 0.5804141163825989\n",
      "Batch: 7553 Loss: 0.3801186978816986\n",
      "Batch: 7617 Loss: 0.3744341731071472\n",
      "Batch: 7681 Loss: 0.45540013909339905\n",
      "Batch: 7745 Loss: 0.4699611961841583\n",
      "Batch: 7809 Loss: 0.4331960082054138\n",
      "Batch: 7873 Loss: 0.366393119096756\n",
      "Batch: 7937 Loss: 0.577659547328949\n",
      "Batch: 8001 Loss: 0.432343453168869\n",
      "Batch: 8065 Loss: 0.5799554586410522\n",
      "Batch: 8129 Loss: 0.45060819387435913\n",
      "Batch: 8193 Loss: 0.4785557985305786\n",
      "Batch: 8257 Loss: 0.4937160909175873\n",
      "Batch: 8321 Loss: 0.6583324670791626\n",
      "Batch: 8385 Loss: 0.329325407743454\n",
      "Batch: 8449 Loss: 0.36434298753738403\n",
      "Batch: 8513 Loss: 0.6573459506034851\n",
      "Batch: 8577 Loss: 0.34817689657211304\n",
      "Batch: 8641 Loss: 0.5246930718421936\n",
      "Batch: 8705 Loss: 0.42958053946495056\n",
      "Batch: 8769 Loss: 0.4952412247657776\n",
      "Batch: 8833 Loss: 0.5457150340080261\n",
      "Batch: 8897 Loss: 0.8221681118011475\n",
      "Batch: 8961 Loss: 0.40993475914001465\n",
      "Batch: 9025 Loss: 0.4045877754688263\n",
      "Batch: 9089 Loss: 0.4141067862510681\n",
      "Batch: 9153 Loss: 0.4771460294723511\n",
      "Batch: 9217 Loss: 0.5181447267532349\n",
      "Batch: 9281 Loss: 0.48298582434654236\n",
      "Batch: 9345 Loss: 0.4060710668563843\n",
      "Batch: 9409 Loss: 0.5434263944625854\n",
      "Batch: 9473 Loss: 0.5917002558708191\n",
      "Batch: 9537 Loss: 0.4952488839626312\n",
      "Batch: 9601 Loss: 0.37965127825737\n",
      "Batch: 9665 Loss: 0.35503655672073364\n",
      "Batch: 9729 Loss: 0.4578470289707184\n",
      "Batch: 9793 Loss: 0.3954692780971527\n",
      "Batch: 9857 Loss: 0.44716015458106995\n",
      "Batch: 9921 Loss: 0.41686123609542847\n",
      "Batch: 9985 Loss: 0.46580713987350464\n",
      "Batch: 10049 Loss: 0.5382675528526306\n",
      "Batch: 10113 Loss: 0.4254656434059143\n",
      "Batch: 10177 Loss: 0.505593478679657\n",
      "Batch: 10241 Loss: 0.3819744884967804\n",
      "Batch: 10305 Loss: 0.4554755389690399\n",
      "Batch: 10369 Loss: 0.4965604841709137\n",
      "Batch: 10433 Loss: 0.41305652260780334\n",
      "Batch: 10497 Loss: 0.4041306972503662\n",
      "Batch: 10561 Loss: 0.37779226899147034\n",
      "Batch: 10625 Loss: 0.4483078122138977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10689 Loss: 0.4412218928337097\n",
      "Batch: 10753 Loss: 0.36472028493881226\n",
      "Batch: 10817 Loss: 0.320978045463562\n",
      "Batch: 10881 Loss: 0.3746478259563446\n",
      "Batch: 10945 Loss: 0.3689892292022705\n",
      "Batch: 11009 Loss: 0.4212888777256012\n",
      "Batch: 11073 Loss: 0.46681565046310425\n",
      "Batch: 11137 Loss: 0.3840598464012146\n",
      "Batch: 11201 Loss: 0.4040890634059906\n",
      "Batch: 11265 Loss: 0.5442602038383484\n",
      "Batch: 11329 Loss: 0.6712096333503723\n",
      "Batch: 11393 Loss: 0.3189587891101837\n",
      "Batch: 11457 Loss: 0.38883376121520996\n",
      "Batch: 11521 Loss: 0.4033704102039337\n",
      "Batch: 11585 Loss: 0.5023595690727234\n",
      "Batch: 11649 Loss: 0.3409222364425659\n",
      "Batch: 11713 Loss: 0.44731807708740234\n",
      "Batch: 11777 Loss: 0.6264367699623108\n",
      "Batch: 11841 Loss: 0.5911042094230652\n",
      "Batch: 11905 Loss: 0.4759649932384491\n",
      "Batch: 11969 Loss: 0.4501689374446869\n",
      "Batch: 12033 Loss: 0.38272517919540405\n",
      "Batch: 12097 Loss: 0.9628525376319885\n",
      "Batch: 12161 Loss: 0.5317795872688293\n",
      "Batch: 12225 Loss: 0.3089599013328552\n",
      "Batch: 12289 Loss: 0.32847151160240173\n",
      "Batch: 12353 Loss: 0.44205930829048157\n",
      "Batch: 12417 Loss: 0.3773442804813385\n",
      "Batch: 12481 Loss: 0.41167739033699036\n",
      "Batch: 12545 Loss: 0.49344995617866516\n",
      "Batch: 12609 Loss: 0.5346347689628601\n",
      "Batch: 12673 Loss: 0.558710515499115\n",
      "Batch: 12737 Loss: 0.46523144841194153\n",
      "Batch: 12801 Loss: 0.39311596751213074\n",
      "Batch: 12865 Loss: 0.3336274027824402\n",
      "Batch: 12929 Loss: 0.6806203722953796\n",
      "Epoch: 12\n",
      "Batch: 1 Loss: 0.4181223511695862\n",
      "Batch: 65 Loss: 0.48432695865631104\n",
      "Batch: 129 Loss: 0.40952208638191223\n",
      "Batch: 193 Loss: 0.5966272950172424\n",
      "Batch: 257 Loss: 0.42347630858421326\n",
      "Batch: 321 Loss: 0.42710235714912415\n",
      "Batch: 385 Loss: 0.417472779750824\n",
      "Batch: 449 Loss: 0.3878638744354248\n",
      "Batch: 513 Loss: 0.4014212489128113\n",
      "Batch: 577 Loss: 0.39957016706466675\n",
      "Batch: 641 Loss: 0.4778464436531067\n",
      "Batch: 705 Loss: 0.4216170012950897\n",
      "Batch: 769 Loss: 0.4745146632194519\n",
      "Batch: 833 Loss: 0.3528314530849457\n",
      "Batch: 897 Loss: 0.581591784954071\n",
      "Batch: 961 Loss: 0.376688688993454\n",
      "Batch: 1025 Loss: 0.40861693024635315\n",
      "Batch: 1089 Loss: 0.4020802974700928\n",
      "Batch: 1153 Loss: 0.43409863114356995\n",
      "Batch: 1217 Loss: 0.4007490873336792\n",
      "Batch: 1281 Loss: 0.42735549807548523\n",
      "Batch: 1345 Loss: 0.4367920160293579\n",
      "Batch: 1409 Loss: 0.37239837646484375\n",
      "Batch: 1473 Loss: 0.42283180356025696\n",
      "Batch: 1537 Loss: 0.3970652222633362\n",
      "Batch: 1601 Loss: 0.3401806950569153\n",
      "Batch: 1665 Loss: 0.37783530354499817\n",
      "Batch: 1729 Loss: 0.4467460811138153\n",
      "Batch: 1793 Loss: 0.3438347280025482\n",
      "Batch: 1857 Loss: 0.39995306730270386\n",
      "Batch: 1921 Loss: 0.4567485451698303\n",
      "Batch: 1985 Loss: 0.3745371997356415\n",
      "Batch: 2049 Loss: 0.351817786693573\n",
      "Batch: 2113 Loss: 0.39105379581451416\n",
      "Batch: 2177 Loss: 0.4465089440345764\n",
      "Batch: 2241 Loss: 0.4915080666542053\n",
      "Batch: 2305 Loss: 0.5145360827445984\n",
      "Batch: 2369 Loss: 0.5219730138778687\n",
      "Batch: 2433 Loss: 0.45461156964302063\n",
      "Batch: 2497 Loss: 0.505333423614502\n",
      "Batch: 2561 Loss: 0.4335027039051056\n",
      "Batch: 2625 Loss: 0.4363994002342224\n",
      "Batch: 2689 Loss: 0.4523988962173462\n",
      "Batch: 2753 Loss: 0.38104724884033203\n",
      "Batch: 2817 Loss: 0.5594063997268677\n",
      "Batch: 2881 Loss: 0.49275439977645874\n",
      "Batch: 2945 Loss: 0.4260794222354889\n",
      "Batch: 3009 Loss: 0.5951670408248901\n",
      "Batch: 3073 Loss: 0.47499749064445496\n",
      "Batch: 3137 Loss: 0.4274957776069641\n",
      "Batch: 3201 Loss: 0.3962002992630005\n",
      "Batch: 3265 Loss: 0.3798486888408661\n",
      "Batch: 3329 Loss: 0.4084027111530304\n",
      "Batch: 3393 Loss: 0.45275890827178955\n",
      "Batch: 3457 Loss: 0.4204818308353424\n",
      "Batch: 3521 Loss: 0.31862393021583557\n",
      "Batch: 3585 Loss: 0.30887261033058167\n",
      "Batch: 3649 Loss: 0.5048674941062927\n",
      "Batch: 3713 Loss: 0.41612327098846436\n",
      "Batch: 3777 Loss: 0.44476118683815\n",
      "Batch: 3841 Loss: 0.4441278874874115\n",
      "Batch: 3905 Loss: 0.3937719464302063\n",
      "Batch: 3969 Loss: 0.5493204593658447\n",
      "Batch: 4033 Loss: 0.41452109813690186\n",
      "Batch: 4097 Loss: 0.4065493941307068\n",
      "Batch: 4161 Loss: 0.4725867807865143\n",
      "Batch: 4225 Loss: 0.34408190846443176\n",
      "Batch: 4289 Loss: 0.36779797077178955\n",
      "Batch: 4353 Loss: 0.5117471218109131\n",
      "Batch: 4417 Loss: 0.6766608357429504\n",
      "Batch: 4481 Loss: 0.7188133597373962\n",
      "Batch: 4545 Loss: 0.5733091235160828\n",
      "Batch: 4609 Loss: 0.38134926557540894\n",
      "Batch: 4673 Loss: 0.3592070937156677\n",
      "Batch: 4737 Loss: 0.4667581021785736\n",
      "Batch: 4801 Loss: 0.38471874594688416\n",
      "Batch: 4865 Loss: 0.39545077085494995\n",
      "Batch: 4929 Loss: 0.4447561204433441\n",
      "Batch: 4993 Loss: 0.5618361234664917\n",
      "Batch: 5057 Loss: 0.5400550365447998\n",
      "Batch: 5121 Loss: 0.43339869379997253\n",
      "Batch: 5185 Loss: 0.886067271232605\n",
      "Batch: 5249 Loss: 0.38592013716697693\n",
      "Batch: 5313 Loss: 0.45861509442329407\n",
      "Batch: 5377 Loss: 0.4368284046649933\n",
      "Batch: 5441 Loss: 0.5381525158882141\n",
      "Batch: 5505 Loss: 0.5004950761795044\n",
      "Batch: 5569 Loss: 0.5356718897819519\n",
      "Batch: 5633 Loss: 0.38831430673599243\n",
      "Batch: 5697 Loss: 0.4517694413661957\n",
      "Batch: 5761 Loss: 0.5771088600158691\n",
      "Batch: 5825 Loss: 0.445413738489151\n",
      "Batch: 5889 Loss: 0.39274436235427856\n",
      "Batch: 5953 Loss: 0.39248126745224\n",
      "Batch: 6017 Loss: 0.3388252258300781\n",
      "Batch: 6081 Loss: 0.3337894082069397\n",
      "Batch: 6145 Loss: 0.44100329279899597\n",
      "Batch: 6209 Loss: 0.3828340768814087\n",
      "Batch: 6273 Loss: 0.4769402742385864\n",
      "Batch: 6337 Loss: 0.3472760021686554\n",
      "Batch: 6401 Loss: 0.3472000062465668\n",
      "Batch: 6465 Loss: 0.3903428316116333\n",
      "Batch: 6529 Loss: 0.3688849210739136\n",
      "Batch: 6593 Loss: 0.40572652220726013\n",
      "Batch: 6657 Loss: 0.33273154497146606\n",
      "Batch: 6721 Loss: 0.4611268937587738\n",
      "Batch: 6785 Loss: 0.4492804706096649\n",
      "Batch: 6849 Loss: 0.4526301324367523\n",
      "Batch: 6913 Loss: 0.4140796661376953\n",
      "Batch: 6977 Loss: 0.44308218359947205\n",
      "Batch: 7041 Loss: 0.4297783076763153\n",
      "Batch: 7105 Loss: 0.3604923486709595\n",
      "Batch: 7169 Loss: 0.4313891530036926\n",
      "Batch: 7233 Loss: 0.3701167702674866\n",
      "Batch: 7297 Loss: 0.4263334572315216\n",
      "Batch: 7361 Loss: 0.39884495735168457\n",
      "Batch: 7425 Loss: 0.4852229058742523\n",
      "Batch: 7489 Loss: 0.582045316696167\n",
      "Batch: 7553 Loss: 0.3800257444381714\n",
      "Batch: 7617 Loss: 0.3724176287651062\n",
      "Batch: 7681 Loss: 0.45360949635505676\n",
      "Batch: 7745 Loss: 0.47226524353027344\n",
      "Batch: 7809 Loss: 0.43211233615875244\n",
      "Batch: 7873 Loss: 0.36311617493629456\n",
      "Batch: 7937 Loss: 0.5742931365966797\n",
      "Batch: 8001 Loss: 0.43007567524909973\n",
      "Batch: 8065 Loss: 0.5765194892883301\n",
      "Batch: 8129 Loss: 0.43693363666534424\n",
      "Batch: 8193 Loss: 0.4824657440185547\n",
      "Batch: 8257 Loss: 0.5068812370300293\n",
      "Batch: 8321 Loss: 0.6622314453125\n",
      "Batch: 8385 Loss: 0.32801297307014465\n",
      "Batch: 8449 Loss: 0.36281469464302063\n",
      "Batch: 8513 Loss: 0.6537972688674927\n",
      "Batch: 8577 Loss: 0.3462713956832886\n",
      "Batch: 8641 Loss: 0.5248509049415588\n",
      "Batch: 8705 Loss: 0.4269169867038727\n",
      "Batch: 8769 Loss: 0.49385637044906616\n",
      "Batch: 8833 Loss: 0.5429636240005493\n",
      "Batch: 8897 Loss: 0.819770336151123\n",
      "Batch: 8961 Loss: 0.4079521596431732\n",
      "Batch: 9025 Loss: 0.40078631043434143\n",
      "Batch: 9089 Loss: 0.4128919541835785\n",
      "Batch: 9153 Loss: 0.4758453667163849\n",
      "Batch: 9217 Loss: 0.5165253281593323\n",
      "Batch: 9281 Loss: 0.4806400239467621\n",
      "Batch: 9345 Loss: 0.4070433974266052\n",
      "Batch: 9409 Loss: 0.538620114326477\n",
      "Batch: 9473 Loss: 0.5872332453727722\n",
      "Batch: 9537 Loss: 0.4952797591686249\n",
      "Batch: 9601 Loss: 0.3799474537372589\n",
      "Batch: 9665 Loss: 0.3543093204498291\n",
      "Batch: 9729 Loss: 0.4569721221923828\n",
      "Batch: 9793 Loss: 0.39677876234054565\n",
      "Batch: 9857 Loss: 0.4461679756641388\n",
      "Batch: 9921 Loss: 0.4115905463695526\n",
      "Batch: 9985 Loss: 0.4735228717327118\n",
      "Batch: 10049 Loss: 0.5370964407920837\n",
      "Batch: 10113 Loss: 0.42325910925865173\n",
      "Batch: 10177 Loss: 0.5061076879501343\n",
      "Batch: 10241 Loss: 0.3808659017086029\n",
      "Batch: 10305 Loss: 0.45328977704048157\n",
      "Batch: 10369 Loss: 0.4931280016899109\n",
      "Batch: 10433 Loss: 0.41143932938575745\n",
      "Batch: 10497 Loss: 0.4020708203315735\n",
      "Batch: 10561 Loss: 0.37519437074661255\n",
      "Batch: 10625 Loss: 0.45097148418426514\n",
      "Batch: 10689 Loss: 0.43642500042915344\n",
      "Batch: 10753 Loss: 0.3642928898334503\n",
      "Batch: 10817 Loss: 0.3180701434612274\n",
      "Batch: 10881 Loss: 0.3712520897388458\n",
      "Batch: 10945 Loss: 0.3763870596885681\n",
      "Batch: 11009 Loss: 0.4289402663707733\n",
      "Batch: 11073 Loss: 0.46837764978408813\n",
      "Batch: 11137 Loss: 0.38629424571990967\n",
      "Batch: 11201 Loss: 0.4060276448726654\n",
      "Batch: 11265 Loss: 0.546542227268219\n",
      "Batch: 11329 Loss: 0.6749770641326904\n",
      "Batch: 11393 Loss: 0.32064729928970337\n",
      "Batch: 11457 Loss: 0.39037469029426575\n",
      "Batch: 11521 Loss: 0.4061548709869385\n",
      "Batch: 11585 Loss: 0.4991739094257355\n",
      "Batch: 11649 Loss: 0.3392793834209442\n",
      "Batch: 11713 Loss: 0.4438917636871338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 11777 Loss: 0.6234559416770935\n",
      "Batch: 11841 Loss: 0.5888248085975647\n",
      "Batch: 11905 Loss: 0.47408953309059143\n",
      "Batch: 11969 Loss: 0.45138019323349\n",
      "Batch: 12033 Loss: 0.381980836391449\n",
      "Batch: 12097 Loss: 0.9576952457427979\n",
      "Batch: 12161 Loss: 0.5295775532722473\n",
      "Batch: 12225 Loss: 0.307621568441391\n",
      "Batch: 12289 Loss: 0.32689911127090454\n",
      "Batch: 12353 Loss: 0.44040894508361816\n",
      "Batch: 12417 Loss: 0.37746840715408325\n",
      "Batch: 12481 Loss: 0.41156551241874695\n",
      "Batch: 12545 Loss: 0.4912455379962921\n",
      "Batch: 12609 Loss: 0.5324984788894653\n",
      "Batch: 12673 Loss: 0.557964563369751\n",
      "Batch: 12737 Loss: 0.4628262221813202\n",
      "Batch: 12801 Loss: 0.3920670747756958\n",
      "Batch: 12865 Loss: 0.3317923843860626\n",
      "Batch: 12929 Loss: 0.6764189600944519\n",
      "Epoch: 13\n",
      "Batch: 1 Loss: 0.4181801378726959\n",
      "Batch: 65 Loss: 0.48316022753715515\n",
      "Batch: 129 Loss: 0.4079318344593048\n",
      "Batch: 193 Loss: 0.599144697189331\n",
      "Batch: 257 Loss: 0.44379550218582153\n",
      "Batch: 321 Loss: 0.41559311747550964\n",
      "Batch: 385 Loss: 0.4250403940677643\n",
      "Batch: 449 Loss: 0.3842461109161377\n",
      "Batch: 513 Loss: 0.40083402395248413\n",
      "Batch: 577 Loss: 0.40382692217826843\n",
      "Batch: 641 Loss: 0.48518821597099304\n",
      "Batch: 705 Loss: 0.42236092686653137\n",
      "Batch: 769 Loss: 0.4756210446357727\n",
      "Batch: 833 Loss: 0.3516210615634918\n",
      "Batch: 897 Loss: 0.5807642936706543\n",
      "Batch: 961 Loss: 0.3750702738761902\n",
      "Batch: 1025 Loss: 0.40739497542381287\n",
      "Batch: 1089 Loss: 0.4068513810634613\n",
      "Batch: 1153 Loss: 0.43646979331970215\n",
      "Batch: 1217 Loss: 0.40136590600013733\n",
      "Batch: 1281 Loss: 0.4283285140991211\n",
      "Batch: 1345 Loss: 0.4360588490962982\n",
      "Batch: 1409 Loss: 0.37124308943748474\n",
      "Batch: 1473 Loss: 0.42262327671051025\n",
      "Batch: 1537 Loss: 0.39334800839424133\n",
      "Batch: 1601 Loss: 0.3404832184314728\n",
      "Batch: 1665 Loss: 0.37900111079216003\n",
      "Batch: 1729 Loss: 0.4455033540725708\n",
      "Batch: 1793 Loss: 0.3434605002403259\n",
      "Batch: 1857 Loss: 0.39916443824768066\n",
      "Batch: 1921 Loss: 0.4576776623725891\n",
      "Batch: 1985 Loss: 0.37808042764663696\n",
      "Batch: 2049 Loss: 0.3519528806209564\n",
      "Batch: 2113 Loss: 0.38790950179100037\n",
      "Batch: 2177 Loss: 0.44785404205322266\n",
      "Batch: 2241 Loss: 0.48383817076683044\n",
      "Batch: 2305 Loss: 0.5136275291442871\n",
      "Batch: 2369 Loss: 0.5265137553215027\n",
      "Batch: 2433 Loss: 0.4476988911628723\n",
      "Batch: 2497 Loss: 0.500982940196991\n",
      "Batch: 2561 Loss: 0.4311859905719757\n",
      "Batch: 2625 Loss: 0.43430233001708984\n",
      "Batch: 2689 Loss: 0.4521149694919586\n",
      "Batch: 2753 Loss: 0.37894341349601746\n",
      "Batch: 2817 Loss: 0.5542036294937134\n",
      "Batch: 2881 Loss: 0.4880754053592682\n",
      "Batch: 2945 Loss: 0.4199536144733429\n",
      "Batch: 3009 Loss: 0.5854468941688538\n",
      "Batch: 3073 Loss: 0.46773892641067505\n",
      "Batch: 3137 Loss: 0.42741554975509644\n",
      "Batch: 3201 Loss: 0.39612966775894165\n",
      "Batch: 3265 Loss: 0.3799091875553131\n",
      "Batch: 3329 Loss: 0.4077650010585785\n",
      "Batch: 3393 Loss: 0.4525265395641327\n",
      "Batch: 3457 Loss: 0.4175477921962738\n",
      "Batch: 3521 Loss: 0.31591489911079407\n",
      "Batch: 3585 Loss: 0.30654817819595337\n",
      "Batch: 3649 Loss: 0.5011911392211914\n",
      "Batch: 3713 Loss: 0.4150063395500183\n",
      "Batch: 3777 Loss: 0.44432923197746277\n",
      "Batch: 3841 Loss: 0.44292792677879333\n",
      "Batch: 3905 Loss: 0.39489811658859253\n",
      "Batch: 3969 Loss: 0.5496335625648499\n",
      "Batch: 4033 Loss: 0.4117981195449829\n",
      "Batch: 4097 Loss: 0.4005151093006134\n",
      "Batch: 4161 Loss: 0.47391489148139954\n",
      "Batch: 4225 Loss: 0.3442350924015045\n",
      "Batch: 4289 Loss: 0.36938145756721497\n",
      "Batch: 4353 Loss: 0.5005013346672058\n",
      "Batch: 4417 Loss: 0.6766360998153687\n",
      "Batch: 4481 Loss: 0.7137513756752014\n",
      "Batch: 4545 Loss: 0.5722541213035583\n",
      "Batch: 4609 Loss: 0.38032087683677673\n",
      "Batch: 4673 Loss: 0.35905420780181885\n",
      "Batch: 4737 Loss: 0.46424600481987\n",
      "Batch: 4801 Loss: 0.3832836151123047\n",
      "Batch: 4865 Loss: 0.39236143231391907\n",
      "Batch: 4929 Loss: 0.4374605715274811\n",
      "Batch: 4993 Loss: 0.5593886971473694\n",
      "Batch: 5057 Loss: 0.5403353571891785\n",
      "Batch: 5121 Loss: 0.42142120003700256\n",
      "Batch: 5185 Loss: 0.8824405670166016\n",
      "Batch: 5249 Loss: 0.38628801703453064\n",
      "Batch: 5313 Loss: 0.4605744779109955\n",
      "Batch: 5377 Loss: 0.43641650676727295\n",
      "Batch: 5441 Loss: 0.5378640294075012\n",
      "Batch: 5505 Loss: 0.49761006236076355\n",
      "Batch: 5569 Loss: 0.5327025651931763\n",
      "Batch: 5633 Loss: 0.39378535747528076\n",
      "Batch: 5697 Loss: 0.4553496241569519\n",
      "Batch: 5761 Loss: 0.5714241862297058\n",
      "Batch: 5825 Loss: 0.4451243579387665\n",
      "Batch: 5889 Loss: 0.3932531476020813\n",
      "Batch: 5953 Loss: 0.3951583504676819\n",
      "Batch: 6017 Loss: 0.33476483821868896\n",
      "Batch: 6081 Loss: 0.3338239789009094\n",
      "Batch: 6145 Loss: 0.4528431296348572\n",
      "Batch: 6209 Loss: 0.38250258564949036\n",
      "Batch: 6273 Loss: 0.4758889675140381\n",
      "Batch: 6337 Loss: 0.346268892288208\n",
      "Batch: 6401 Loss: 0.34534695744514465\n",
      "Batch: 6465 Loss: 0.3891626298427582\n",
      "Batch: 6529 Loss: 0.36878687143325806\n",
      "Batch: 6593 Loss: 0.40550583600997925\n",
      "Batch: 6657 Loss: 0.3306838274002075\n",
      "Batch: 6721 Loss: 0.46273818612098694\n",
      "Batch: 6785 Loss: 0.44850870966911316\n",
      "Batch: 6849 Loss: 0.45566582679748535\n",
      "Batch: 6913 Loss: 0.4111860692501068\n",
      "Batch: 6977 Loss: 0.43896952271461487\n",
      "Batch: 7041 Loss: 0.42885729670524597\n",
      "Batch: 7105 Loss: 0.3620782196521759\n",
      "Batch: 7169 Loss: 0.42876648902893066\n",
      "Batch: 7233 Loss: 0.37401482462882996\n",
      "Batch: 7297 Loss: 0.4261508882045746\n",
      "Batch: 7361 Loss: 0.398173063993454\n",
      "Batch: 7425 Loss: 0.4838238060474396\n",
      "Batch: 7489 Loss: 0.5794180631637573\n",
      "Batch: 7553 Loss: 0.3786928355693817\n",
      "Batch: 7617 Loss: 0.3743659555912018\n",
      "Batch: 7681 Loss: 0.4532387852668762\n",
      "Batch: 7745 Loss: 0.47035667300224304\n",
      "Batch: 7809 Loss: 0.4295533299446106\n",
      "Batch: 7873 Loss: 0.36147379875183105\n",
      "Batch: 7937 Loss: 0.5720599889755249\n",
      "Batch: 8001 Loss: 0.43029797077178955\n",
      "Batch: 8065 Loss: 0.5770279169082642\n",
      "Batch: 8129 Loss: 0.43697258830070496\n",
      "Batch: 8193 Loss: 0.4786468744277954\n",
      "Batch: 8257 Loss: 0.5088695883750916\n",
      "Batch: 8321 Loss: 0.6581750512123108\n",
      "Batch: 8385 Loss: 0.3275977075099945\n",
      "Batch: 8449 Loss: 0.3628522753715515\n",
      "Batch: 8513 Loss: 0.6509312391281128\n",
      "Batch: 8577 Loss: 0.34408876299858093\n",
      "Batch: 8641 Loss: 0.5268849730491638\n",
      "Batch: 8705 Loss: 0.4284919798374176\n",
      "Batch: 8769 Loss: 0.4930392801761627\n",
      "Batch: 8833 Loss: 0.5407804846763611\n",
      "Batch: 8897 Loss: 0.8183626532554626\n",
      "Batch: 8961 Loss: 0.40742039680480957\n",
      "Batch: 9025 Loss: 0.39945581555366516\n",
      "Batch: 9089 Loss: 0.4102274775505066\n",
      "Batch: 9153 Loss: 0.47568216919898987\n",
      "Batch: 9217 Loss: 0.5169994831085205\n",
      "Batch: 9281 Loss: 0.4810827970504761\n",
      "Batch: 9345 Loss: 0.413038045167923\n",
      "Batch: 9409 Loss: 0.5508312582969666\n",
      "Batch: 9473 Loss: 0.5960426330566406\n",
      "Batch: 9537 Loss: 0.4980311095714569\n",
      "Batch: 9601 Loss: 0.3821820914745331\n",
      "Batch: 9665 Loss: 0.3514452278614044\n",
      "Batch: 9729 Loss: 0.45663216710090637\n",
      "Batch: 9793 Loss: 0.394421249628067\n",
      "Batch: 9857 Loss: 0.4427258372306824\n",
      "Batch: 9921 Loss: 0.4131464660167694\n",
      "Batch: 9985 Loss: 0.464138388633728\n",
      "Batch: 10049 Loss: 0.5343086123466492\n",
      "Batch: 10113 Loss: 0.42612510919570923\n",
      "Batch: 10177 Loss: 0.5033380389213562\n",
      "Batch: 10241 Loss: 0.3816564977169037\n",
      "Batch: 10305 Loss: 0.4530549943447113\n",
      "Batch: 10369 Loss: 0.4933737516403198\n",
      "Batch: 10433 Loss: 0.4152267873287201\n",
      "Batch: 10497 Loss: 0.40150707960128784\n",
      "Batch: 10561 Loss: 0.375422865152359\n",
      "Batch: 10625 Loss: 0.4459935426712036\n",
      "Batch: 10689 Loss: 0.43835437297821045\n",
      "Batch: 10753 Loss: 0.36506786942481995\n",
      "Batch: 10817 Loss: 0.3206944763660431\n",
      "Batch: 10881 Loss: 0.37103572487831116\n",
      "Batch: 10945 Loss: 0.36797812581062317\n",
      "Batch: 11009 Loss: 0.42238911986351013\n",
      "Batch: 11073 Loss: 0.4666709899902344\n",
      "Batch: 11137 Loss: 0.38487884402275085\n",
      "Batch: 11201 Loss: 0.4032466411590576\n",
      "Batch: 11265 Loss: 0.542678952217102\n",
      "Batch: 11329 Loss: 0.672116219997406\n",
      "Batch: 11393 Loss: 0.32456547021865845\n",
      "Batch: 11457 Loss: 0.3921317160129547\n",
      "Batch: 11521 Loss: 0.40555277466773987\n",
      "Batch: 11585 Loss: 0.4961043894290924\n",
      "Batch: 11649 Loss: 0.33574387431144714\n",
      "Batch: 11713 Loss: 0.4416930377483368\n",
      "Batch: 11777 Loss: 0.6222354173660278\n",
      "Batch: 11841 Loss: 0.5886120200157166\n",
      "Batch: 11905 Loss: 0.4712134301662445\n",
      "Batch: 11969 Loss: 0.4586426317691803\n",
      "Batch: 12033 Loss: 0.38126981258392334\n",
      "Batch: 12097 Loss: 0.9557123780250549\n",
      "Batch: 12161 Loss: 0.5262351632118225\n",
      "Batch: 12225 Loss: 0.3054039776325226\n",
      "Batch: 12289 Loss: 0.32607606053352356\n",
      "Batch: 12353 Loss: 0.44141510128974915\n",
      "Batch: 12417 Loss: 0.3793061673641205\n",
      "Batch: 12481 Loss: 0.4110424220561981\n",
      "Batch: 12545 Loss: 0.49055612087249756\n",
      "Batch: 12609 Loss: 0.5315858125686646\n",
      "Batch: 12673 Loss: 0.5645474791526794\n",
      "Batch: 12737 Loss: 0.46000248193740845\n",
      "Batch: 12801 Loss: 0.3909926116466522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 12865 Loss: 0.32999008893966675\n",
      "Batch: 12929 Loss: 0.674102246761322\n",
      "Epoch: 14\n",
      "Batch: 1 Loss: 0.4156707227230072\n",
      "Batch: 65 Loss: 0.4824124872684479\n",
      "Batch: 129 Loss: 0.4123334586620331\n",
      "Batch: 193 Loss: 0.603620707988739\n",
      "Batch: 257 Loss: 0.44551658630371094\n",
      "Batch: 321 Loss: 0.42054441571235657\n",
      "Batch: 385 Loss: 0.4183042347431183\n",
      "Batch: 449 Loss: 0.38817745447158813\n",
      "Batch: 513 Loss: 0.39968520402908325\n",
      "Batch: 577 Loss: 0.3995414674282074\n",
      "Batch: 641 Loss: 0.4745529890060425\n",
      "Batch: 705 Loss: 0.419391930103302\n",
      "Batch: 769 Loss: 0.47389453649520874\n",
      "Batch: 833 Loss: 0.35126176476478577\n",
      "Batch: 897 Loss: 0.5815432071685791\n",
      "Batch: 961 Loss: 0.37708163261413574\n",
      "Batch: 1025 Loss: 0.4077122211456299\n",
      "Batch: 1089 Loss: 0.3956988751888275\n",
      "Batch: 1153 Loss: 0.43037131428718567\n",
      "Batch: 1217 Loss: 0.39414918422698975\n",
      "Batch: 1281 Loss: 0.4233887493610382\n",
      "Batch: 1345 Loss: 0.43267858028411865\n",
      "Batch: 1409 Loss: 0.3687913715839386\n",
      "Batch: 1473 Loss: 0.42472198605537415\n",
      "Batch: 1537 Loss: 0.39581453800201416\n",
      "Batch: 1601 Loss: 0.34252116084098816\n",
      "Batch: 1665 Loss: 0.3769036531448364\n",
      "Batch: 1729 Loss: 0.4449622333049774\n",
      "Batch: 1793 Loss: 0.3407911956310272\n",
      "Batch: 1857 Loss: 0.397531121969223\n",
      "Batch: 1921 Loss: 0.45408758521080017\n",
      "Batch: 1985 Loss: 0.37426063418388367\n",
      "Batch: 2049 Loss: 0.34908124804496765\n",
      "Batch: 2113 Loss: 0.3863372504711151\n",
      "Batch: 2177 Loss: 0.4354786276817322\n",
      "Batch: 2241 Loss: 0.4804579019546509\n",
      "Batch: 2305 Loss: 0.5117096900939941\n",
      "Batch: 2369 Loss: 0.513213574886322\n",
      "Batch: 2433 Loss: 0.4422326982021332\n",
      "Batch: 2497 Loss: 0.5471751093864441\n",
      "Batch: 2561 Loss: 0.4312368929386139\n",
      "Batch: 2625 Loss: 0.4383232593536377\n",
      "Batch: 2689 Loss: 0.4543996751308441\n",
      "Batch: 2753 Loss: 0.37918683886528015\n",
      "Batch: 2817 Loss: 0.5499930381774902\n",
      "Batch: 2881 Loss: 0.4867427349090576\n",
      "Batch: 2945 Loss: 0.41938498616218567\n",
      "Batch: 3009 Loss: 0.5831546187400818\n",
      "Batch: 3073 Loss: 0.4656490683555603\n",
      "Batch: 3137 Loss: 0.42056336998939514\n",
      "Batch: 3201 Loss: 0.3949681222438812\n",
      "Batch: 3265 Loss: 0.37947914004325867\n",
      "Batch: 3329 Loss: 0.4081200063228607\n",
      "Batch: 3393 Loss: 0.45021846890449524\n",
      "Batch: 3457 Loss: 0.41664013266563416\n",
      "Batch: 3521 Loss: 0.31745973229408264\n",
      "Batch: 3585 Loss: 0.3052370250225067\n",
      "Batch: 3649 Loss: 0.5000017285346985\n",
      "Batch: 3713 Loss: 0.41342976689338684\n",
      "Batch: 3777 Loss: 0.4430663585662842\n",
      "Batch: 3841 Loss: 0.44272658228874207\n",
      "Batch: 3905 Loss: 0.392826646566391\n",
      "Batch: 3969 Loss: 0.545573353767395\n",
      "Batch: 4033 Loss: 0.4138588309288025\n",
      "Batch: 4097 Loss: 0.40475934743881226\n",
      "Batch: 4161 Loss: 0.4719943404197693\n",
      "Batch: 4225 Loss: 0.3421784043312073\n",
      "Batch: 4289 Loss: 0.3644510507583618\n",
      "Batch: 4353 Loss: 0.500353217124939\n",
      "Batch: 4417 Loss: 0.6659794449806213\n",
      "Batch: 4481 Loss: 0.7113410234451294\n",
      "Batch: 4545 Loss: 0.5658897161483765\n",
      "Batch: 4609 Loss: 0.3785228729248047\n",
      "Batch: 4673 Loss: 0.3568441867828369\n",
      "Batch: 4737 Loss: 0.46366825699806213\n",
      "Batch: 4801 Loss: 0.38206347823143005\n",
      "Batch: 4865 Loss: 0.39291712641716003\n",
      "Batch: 4929 Loss: 0.43719643354415894\n",
      "Batch: 4993 Loss: 0.5557380318641663\n",
      "Batch: 5057 Loss: 0.5310236811637878\n",
      "Batch: 5121 Loss: 0.4169798195362091\n",
      "Batch: 5185 Loss: 0.8777288794517517\n",
      "Batch: 5249 Loss: 0.3856666088104248\n",
      "Batch: 5313 Loss: 0.4637115001678467\n",
      "Batch: 5377 Loss: 0.43730655312538147\n",
      "Batch: 5441 Loss: 0.5376285314559937\n",
      "Batch: 5505 Loss: 0.4982016682624817\n",
      "Batch: 5569 Loss: 0.5313794612884521\n",
      "Batch: 5633 Loss: 0.39160358905792236\n",
      "Batch: 5697 Loss: 0.45392996072769165\n",
      "Batch: 5761 Loss: 0.5699352622032166\n",
      "Batch: 5825 Loss: 0.44177350401878357\n",
      "Batch: 5889 Loss: 0.39207205176353455\n",
      "Batch: 5953 Loss: 0.39160284399986267\n",
      "Batch: 6017 Loss: 0.33441492915153503\n",
      "Batch: 6081 Loss: 0.3304607570171356\n",
      "Batch: 6145 Loss: 0.4416276812553406\n",
      "Batch: 6209 Loss: 0.3820272982120514\n",
      "Batch: 6273 Loss: 0.4746021032333374\n",
      "Batch: 6337 Loss: 0.3457861840724945\n",
      "Batch: 6401 Loss: 0.34501200914382935\n",
      "Batch: 6465 Loss: 0.38827693462371826\n",
      "Batch: 6529 Loss: 0.36722829937934875\n",
      "Batch: 6593 Loss: 0.40468019247055054\n",
      "Batch: 6657 Loss: 0.3300692141056061\n",
      "Batch: 6721 Loss: 0.460488498210907\n",
      "Batch: 6785 Loss: 0.4483458697795868\n",
      "Batch: 6849 Loss: 0.4544455409049988\n",
      "Batch: 6913 Loss: 0.40951016545295715\n",
      "Batch: 6977 Loss: 0.4392848610877991\n",
      "Batch: 7041 Loss: 0.4285312294960022\n",
      "Batch: 7105 Loss: 0.35999950766563416\n",
      "Batch: 7169 Loss: 0.42799830436706543\n",
      "Batch: 7233 Loss: 0.37290170788764954\n",
      "Batch: 7297 Loss: 0.4251744747161865\n",
      "Batch: 7361 Loss: 0.39719879627227783\n",
      "Batch: 7425 Loss: 0.4823418855667114\n",
      "Batch: 7489 Loss: 0.5761560797691345\n",
      "Batch: 7553 Loss: 0.37699374556541443\n",
      "Batch: 7617 Loss: 0.37051108479499817\n",
      "Batch: 7681 Loss: 0.4503626525402069\n",
      "Batch: 7745 Loss: 0.46481162309646606\n",
      "Batch: 7809 Loss: 0.4294208884239197\n",
      "Batch: 7873 Loss: 0.3616832494735718\n",
      "Batch: 7937 Loss: 0.5711512565612793\n",
      "Batch: 8001 Loss: 0.4328136444091797\n",
      "Batch: 8065 Loss: 0.5766280889511108\n",
      "Batch: 8129 Loss: 0.43455806374549866\n",
      "Batch: 8193 Loss: 0.478777140378952\n",
      "Batch: 8257 Loss: 0.5016117095947266\n",
      "Batch: 8321 Loss: 0.658553957939148\n",
      "Batch: 8385 Loss: 0.3275041878223419\n",
      "Batch: 8449 Loss: 0.3612239360809326\n",
      "Batch: 8513 Loss: 0.648810863494873\n",
      "Batch: 8577 Loss: 0.3424564599990845\n",
      "Batch: 8641 Loss: 0.523760974407196\n",
      "Batch: 8705 Loss: 0.42637935280799866\n",
      "Batch: 8769 Loss: 0.49091678857803345\n",
      "Batch: 8833 Loss: 0.5367967486381531\n",
      "Batch: 8897 Loss: 0.815170168876648\n",
      "Batch: 8961 Loss: 0.40637657046318054\n",
      "Batch: 9025 Loss: 0.3981335163116455\n",
      "Batch: 9089 Loss: 0.4096459746360779\n",
      "Batch: 9153 Loss: 0.4750763475894928\n",
      "Batch: 9217 Loss: 0.5168366432189941\n",
      "Batch: 9281 Loss: 0.4847455322742462\n",
      "Batch: 9345 Loss: 0.4107992649078369\n",
      "Batch: 9409 Loss: 0.5516493916511536\n",
      "Batch: 9473 Loss: 0.5939922332763672\n",
      "Batch: 9537 Loss: 0.49491894245147705\n",
      "Batch: 9601 Loss: 0.37880638241767883\n",
      "Batch: 9665 Loss: 0.3508234918117523\n",
      "Batch: 9729 Loss: 0.4562447965145111\n",
      "Batch: 9793 Loss: 0.3933852016925812\n",
      "Batch: 9857 Loss: 0.4409222900867462\n",
      "Batch: 9921 Loss: 0.41231924295425415\n",
      "Batch: 9985 Loss: 0.4654577970504761\n",
      "Batch: 10049 Loss: 0.5323514342308044\n",
      "Batch: 10113 Loss: 0.42466410994529724\n",
      "Batch: 10177 Loss: 0.49936309456825256\n",
      "Batch: 10241 Loss: 0.38083308935165405\n",
      "Batch: 10305 Loss: 0.4532831907272339\n",
      "Batch: 10369 Loss: 0.4914016127586365\n",
      "Batch: 10433 Loss: 0.4090220034122467\n",
      "Batch: 10497 Loss: 0.40192878246307373\n",
      "Batch: 10561 Loss: 0.37645822763442993\n",
      "Batch: 10625 Loss: 0.4453205168247223\n",
      "Batch: 10689 Loss: 0.43854522705078125\n",
      "Batch: 10753 Loss: 0.3640739619731903\n",
      "Batch: 10817 Loss: 0.31794601678848267\n",
      "Batch: 10881 Loss: 0.37017008662223816\n",
      "Batch: 10945 Loss: 0.37146079540252686\n",
      "Batch: 11009 Loss: 0.42204394936561584\n",
      "Batch: 11073 Loss: 0.46623530983924866\n",
      "Batch: 11137 Loss: 0.38644444942474365\n",
      "Batch: 11201 Loss: 0.40238815546035767\n",
      "Batch: 11265 Loss: 0.5455119013786316\n",
      "Batch: 11329 Loss: 0.670914351940155\n",
      "Batch: 11393 Loss: 0.3256962299346924\n",
      "Batch: 11457 Loss: 0.39061927795410156\n",
      "Batch: 11521 Loss: 0.4040769636631012\n",
      "Batch: 11585 Loss: 0.49795398116111755\n",
      "Batch: 11649 Loss: 0.33607229590415955\n",
      "Batch: 11713 Loss: 0.5377795100212097\n",
      "Batch: 11777 Loss: 0.6223562955856323\n",
      "Batch: 11841 Loss: 0.5871536135673523\n",
      "Batch: 11905 Loss: 0.47221681475639343\n",
      "Batch: 11969 Loss: 0.4541500508785248\n",
      "Batch: 12033 Loss: 0.3808180093765259\n",
      "Batch: 12097 Loss: 0.9506415128707886\n",
      "Batch: 12161 Loss: 0.5258262157440186\n",
      "Batch: 12225 Loss: 0.30419689416885376\n",
      "Batch: 12289 Loss: 0.3259229362010956\n",
      "Batch: 12353 Loss: 0.44062909483909607\n",
      "Batch: 12417 Loss: 0.3790891766548157\n",
      "Batch: 12481 Loss: 0.4138134717941284\n",
      "Batch: 12545 Loss: 0.48611465096473694\n",
      "Batch: 12609 Loss: 0.5308142900466919\n",
      "Batch: 12673 Loss: 0.5596391558647156\n",
      "Batch: 12737 Loss: 0.4587722420692444\n",
      "Batch: 12801 Loss: 0.3884928226470947\n",
      "Batch: 12865 Loss: 0.33088618516921997\n",
      "Batch: 12929 Loss: 0.6707889437675476\n",
      "Epoch: 15\n",
      "Batch: 1 Loss: 0.4158967137336731\n",
      "Batch: 65 Loss: 0.48181089758872986\n",
      "Batch: 129 Loss: 0.41459688544273376\n",
      "Batch: 193 Loss: 0.6173256635665894\n",
      "Batch: 257 Loss: 0.4526202380657196\n",
      "Batch: 321 Loss: 0.4263659417629242\n",
      "Batch: 385 Loss: 0.4268110990524292\n",
      "Batch: 449 Loss: 0.3928796648979187\n",
      "Batch: 513 Loss: 0.40725380182266235\n",
      "Batch: 577 Loss: 0.40166226029396057\n",
      "Batch: 641 Loss: 0.4839323163032532\n",
      "Batch: 705 Loss: 0.4256402850151062\n",
      "Batch: 769 Loss: 0.4771505296230316\n",
      "Batch: 833 Loss: 0.35435694456100464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 897 Loss: 0.5832750201225281\n",
      "Batch: 961 Loss: 0.3825380802154541\n",
      "Batch: 1025 Loss: 0.41604170203208923\n",
      "Batch: 1089 Loss: 0.40508729219436646\n",
      "Batch: 1153 Loss: 0.4395787715911865\n",
      "Batch: 1217 Loss: 0.40271684527397156\n",
      "Batch: 1281 Loss: 0.4269751310348511\n",
      "Batch: 1345 Loss: 0.44085976481437683\n",
      "Batch: 1409 Loss: 0.37013736367225647\n",
      "Batch: 1473 Loss: 0.41552409529685974\n",
      "Batch: 1537 Loss: 0.3949144780635834\n",
      "Batch: 1601 Loss: 0.3369812071323395\n",
      "Batch: 1665 Loss: 0.37349608540534973\n",
      "Batch: 1729 Loss: 0.43839260935783386\n",
      "Batch: 1793 Loss: 0.3440033793449402\n",
      "Batch: 1857 Loss: 0.394422709941864\n",
      "Batch: 1921 Loss: 0.4520200192928314\n",
      "Batch: 1985 Loss: 0.3732756972312927\n",
      "Batch: 2049 Loss: 0.3498859703540802\n",
      "Batch: 2113 Loss: 0.379658967256546\n",
      "Batch: 2177 Loss: 0.43294599652290344\n",
      "Batch: 2241 Loss: 0.47495171427726746\n",
      "Batch: 2305 Loss: 0.5029332637786865\n",
      "Batch: 2369 Loss: 0.5067378282546997\n",
      "Batch: 2433 Loss: 0.4423883855342865\n",
      "Batch: 2497 Loss: 0.4990762174129486\n",
      "Batch: 2561 Loss: 0.4306896924972534\n",
      "Batch: 2625 Loss: 0.43579810857772827\n",
      "Batch: 2689 Loss: 0.4481022357940674\n",
      "Batch: 2753 Loss: 0.37917888164520264\n",
      "Batch: 2817 Loss: 0.5506088733673096\n",
      "Batch: 2881 Loss: 0.4839136004447937\n",
      "Batch: 2945 Loss: 0.4187200665473938\n",
      "Batch: 3009 Loss: 0.5827116370201111\n",
      "Batch: 3073 Loss: 0.46282947063446045\n",
      "Batch: 3137 Loss: 0.4190065860748291\n",
      "Batch: 3201 Loss: 0.3944591283798218\n",
      "Batch: 3265 Loss: 0.37795549631118774\n",
      "Batch: 3329 Loss: 0.40742194652557373\n",
      "Batch: 3393 Loss: 0.45055824518203735\n",
      "Batch: 3457 Loss: 0.4204583764076233\n",
      "Batch: 3521 Loss: 0.3164835274219513\n",
      "Batch: 3585 Loss: 0.3047153055667877\n",
      "Batch: 3649 Loss: 0.500889003276825\n",
      "Batch: 3713 Loss: 0.4119327962398529\n",
      "Batch: 3777 Loss: 0.4407263398170471\n",
      "Batch: 3841 Loss: 0.4383181929588318\n",
      "Batch: 3905 Loss: 0.3904072642326355\n",
      "Batch: 3969 Loss: 0.5449944138526917\n",
      "Batch: 4033 Loss: 0.4132983982563019\n",
      "Batch: 4097 Loss: 0.40215128660202026\n",
      "Batch: 4161 Loss: 0.47052934765815735\n",
      "Batch: 4225 Loss: 0.3417201638221741\n",
      "Batch: 4289 Loss: 0.3637327551841736\n",
      "Batch: 4353 Loss: 0.4965568780899048\n",
      "Batch: 4417 Loss: 0.6583078503608704\n",
      "Batch: 4481 Loss: 0.7047121524810791\n",
      "Batch: 4545 Loss: 0.5641104578971863\n",
      "Batch: 4609 Loss: 0.37922942638397217\n",
      "Batch: 4673 Loss: 0.3568964898586273\n",
      "Batch: 4737 Loss: 0.46322885155677795\n",
      "Batch: 4801 Loss: 0.3820848762989044\n",
      "Batch: 4865 Loss: 0.3916528522968292\n",
      "Batch: 4929 Loss: 0.4348228871822357\n",
      "Batch: 4993 Loss: 0.5514190196990967\n",
      "Batch: 5057 Loss: 0.5281197428703308\n",
      "Batch: 5121 Loss: 0.41312703490257263\n",
      "Batch: 5185 Loss: 0.8724305033683777\n",
      "Batch: 5249 Loss: 0.3816602826118469\n",
      "Batch: 5313 Loss: 0.4511597454547882\n",
      "Batch: 5377 Loss: 0.4322013854980469\n",
      "Batch: 5441 Loss: 0.5369105339050293\n",
      "Batch: 5505 Loss: 0.49672576785087585\n",
      "Batch: 5569 Loss: 0.5309668779373169\n",
      "Batch: 5633 Loss: 0.38957709074020386\n",
      "Batch: 5697 Loss: 0.44310370087623596\n",
      "Batch: 5761 Loss: 0.5637142062187195\n",
      "Batch: 5825 Loss: 0.4400169551372528\n",
      "Batch: 5889 Loss: 0.3893263339996338\n",
      "Batch: 5953 Loss: 0.39075008034706116\n",
      "Batch: 6017 Loss: 0.3441213071346283\n",
      "Batch: 6081 Loss: 0.3282482922077179\n",
      "Batch: 6145 Loss: 0.4377627968788147\n",
      "Batch: 6209 Loss: 0.38146886229515076\n",
      "Batch: 6273 Loss: 0.47276434302330017\n",
      "Batch: 6337 Loss: 0.346802294254303\n",
      "Batch: 6401 Loss: 0.3421062231063843\n",
      "Batch: 6465 Loss: 0.3878040909767151\n",
      "Batch: 6529 Loss: 0.3666793406009674\n",
      "Batch: 6593 Loss: 0.40588483214378357\n",
      "Batch: 6657 Loss: 0.32964497804641724\n",
      "Batch: 6721 Loss: 0.45590445399284363\n",
      "Batch: 6785 Loss: 0.4444912374019623\n",
      "Batch: 6849 Loss: 0.4513464868068695\n",
      "Batch: 6913 Loss: 0.41296467185020447\n",
      "Batch: 6977 Loss: 0.43784651160240173\n",
      "Batch: 7041 Loss: 0.42738261818885803\n",
      "Batch: 7105 Loss: 0.36192402243614197\n",
      "Batch: 7169 Loss: 0.42549362778663635\n",
      "Batch: 7233 Loss: 0.3749115765094757\n",
      "Batch: 7297 Loss: 0.42505329847335815\n",
      "Batch: 7361 Loss: 0.39492201805114746\n",
      "Batch: 7425 Loss: 0.48516932129859924\n",
      "Batch: 7489 Loss: 0.5750946402549744\n",
      "Batch: 7553 Loss: 0.3764406442642212\n",
      "Batch: 7617 Loss: 0.36836692690849304\n",
      "Batch: 7681 Loss: 0.4486049711704254\n",
      "Batch: 7745 Loss: 0.4643400311470032\n",
      "Batch: 7809 Loss: 0.43240639567375183\n",
      "Batch: 7873 Loss: 0.36275413632392883\n",
      "Batch: 7937 Loss: 0.5705904960632324\n",
      "Batch: 8001 Loss: 0.4255668520927429\n",
      "Batch: 8065 Loss: 0.5729410648345947\n",
      "Batch: 8129 Loss: 0.436221182346344\n",
      "Batch: 8193 Loss: 0.4776845872402191\n",
      "Batch: 8257 Loss: 0.5012997984886169\n",
      "Batch: 8321 Loss: 0.6594859957695007\n",
      "Batch: 8385 Loss: 0.32733842730522156\n",
      "Batch: 8449 Loss: 0.35930269956588745\n",
      "Batch: 8513 Loss: 0.6463435888290405\n",
      "Batch: 8577 Loss: 0.34136998653411865\n",
      "Batch: 8641 Loss: 0.5247521996498108\n",
      "Batch: 8705 Loss: 0.4296414852142334\n",
      "Batch: 8769 Loss: 0.49014654755592346\n",
      "Batch: 8833 Loss: 0.5372109413146973\n",
      "Batch: 8897 Loss: 0.8132423162460327\n",
      "Batch: 8961 Loss: 0.4085923433303833\n",
      "Batch: 9025 Loss: 0.4014233946800232\n",
      "Batch: 9089 Loss: 0.4107452630996704\n",
      "Batch: 9153 Loss: 0.47222787141799927\n",
      "Batch: 9217 Loss: 0.512939989566803\n",
      "Batch: 9281 Loss: 0.4791117310523987\n",
      "Batch: 9345 Loss: 0.4032024145126343\n",
      "Batch: 9409 Loss: 0.5378328561782837\n",
      "Batch: 9473 Loss: 0.5992446541786194\n",
      "Batch: 9537 Loss: 0.49621662497520447\n",
      "Batch: 9601 Loss: 0.3778868019580841\n",
      "Batch: 9665 Loss: 0.3512086868286133\n",
      "Batch: 9729 Loss: 0.4544590711593628\n",
      "Batch: 9793 Loss: 0.39285093545913696\n",
      "Batch: 9857 Loss: 0.4416137933731079\n",
      "Batch: 9921 Loss: 0.41273191571235657\n",
      "Batch: 9985 Loss: 0.4635274112224579\n",
      "Batch: 10049 Loss: 0.5347421765327454\n",
      "Batch: 10113 Loss: 0.4235001504421234\n",
      "Batch: 10177 Loss: 0.5007125735282898\n",
      "Batch: 10241 Loss: 0.37974005937576294\n",
      "Batch: 10305 Loss: 0.45229801535606384\n",
      "Batch: 10369 Loss: 0.4916173219680786\n",
      "Batch: 10433 Loss: 0.4107134938240051\n",
      "Batch: 10497 Loss: 0.4021848738193512\n",
      "Batch: 10561 Loss: 0.37489205598831177\n",
      "Batch: 10625 Loss: 0.44489312171936035\n",
      "Batch: 10689 Loss: 0.4356411099433899\n",
      "Batch: 10753 Loss: 0.3637046813964844\n",
      "Batch: 10817 Loss: 0.31791189312934875\n",
      "Batch: 10881 Loss: 0.36950162053108215\n",
      "Batch: 10945 Loss: 0.37030526995658875\n",
      "Batch: 11009 Loss: 0.42221057415008545\n",
      "Batch: 11073 Loss: 0.46713268756866455\n",
      "Batch: 11137 Loss: 0.3835534155368805\n",
      "Batch: 11201 Loss: 0.4003068804740906\n",
      "Batch: 11265 Loss: 0.5417868494987488\n",
      "Batch: 11329 Loss: 0.6665025949478149\n",
      "Batch: 11393 Loss: 0.3223351538181305\n",
      "Batch: 11457 Loss: 0.3907863199710846\n",
      "Batch: 11521 Loss: 0.40295177698135376\n",
      "Batch: 11585 Loss: 0.49813058972358704\n",
      "Batch: 11649 Loss: 0.33711057901382446\n",
      "Batch: 11713 Loss: 0.4420510530471802\n",
      "Batch: 11777 Loss: 0.6211772561073303\n",
      "Batch: 11841 Loss: 0.5867369771003723\n",
      "Batch: 11905 Loss: 0.47185075283050537\n",
      "Batch: 11969 Loss: 0.44775092601776123\n",
      "Batch: 12033 Loss: 0.38014259934425354\n",
      "Batch: 12097 Loss: 0.9513959288597107\n",
      "Batch: 12161 Loss: 0.5258967280387878\n",
      "Batch: 12225 Loss: 0.3064047694206238\n",
      "Batch: 12289 Loss: 0.3253697454929352\n",
      "Batch: 12353 Loss: 0.43854522705078125\n",
      "Batch: 12417 Loss: 0.37608104944229126\n",
      "Batch: 12481 Loss: 0.40917667746543884\n",
      "Batch: 12545 Loss: 0.48872947692871094\n",
      "Batch: 12609 Loss: 0.5294487476348877\n",
      "Batch: 12673 Loss: 0.5551336407661438\n",
      "Batch: 12737 Loss: 0.46015411615371704\n",
      "Batch: 12801 Loss: 0.389532208442688\n",
      "Batch: 12865 Loss: 0.3299797475337982\n",
      "Batch: 12929 Loss: 0.6710261702537537\n",
      "Epoch: 16\n",
      "Batch: 1 Loss: 0.4160946011543274\n",
      "Batch: 65 Loss: 0.48019370436668396\n",
      "Batch: 129 Loss: 0.40838468074798584\n",
      "Batch: 193 Loss: 0.601507306098938\n",
      "Batch: 257 Loss: 0.4314435124397278\n",
      "Batch: 321 Loss: 0.4090808033943176\n",
      "Batch: 385 Loss: 0.4146498441696167\n",
      "Batch: 449 Loss: 0.38507312536239624\n",
      "Batch: 513 Loss: 0.39567825198173523\n",
      "Batch: 577 Loss: 0.39613109827041626\n",
      "Batch: 641 Loss: 0.47472381591796875\n",
      "Batch: 705 Loss: 0.4197132885456085\n",
      "Batch: 769 Loss: 0.47163617610931396\n",
      "Batch: 833 Loss: 0.3487435579299927\n",
      "Batch: 897 Loss: 0.5777268409729004\n",
      "Batch: 961 Loss: 0.37358561158180237\n",
      "Batch: 1025 Loss: 0.4073864221572876\n",
      "Batch: 1089 Loss: 0.3950884938240051\n",
      "Batch: 1153 Loss: 0.42971450090408325\n",
      "Batch: 1217 Loss: 0.3941859304904938\n",
      "Batch: 1281 Loss: 0.42060738801956177\n",
      "Batch: 1345 Loss: 0.43199440836906433\n",
      "Batch: 1409 Loss: 0.36855757236480713\n",
      "Batch: 1473 Loss: 0.42055851221084595\n",
      "Batch: 1537 Loss: 0.39290207624435425\n",
      "Batch: 1601 Loss: 0.3412269353866577\n",
      "Batch: 1665 Loss: 0.37439119815826416\n",
      "Batch: 1729 Loss: 0.4423564672470093\n",
      "Batch: 1793 Loss: 0.33995991945266724\n",
      "Batch: 1857 Loss: 0.39595264196395874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1921 Loss: 0.4515465795993805\n",
      "Batch: 1985 Loss: 0.37572842836380005\n",
      "Batch: 2049 Loss: 0.35021698474884033\n",
      "Batch: 2113 Loss: 0.38934269547462463\n",
      "Batch: 2177 Loss: 0.437315970659256\n",
      "Batch: 2241 Loss: 0.48299866914749146\n",
      "Batch: 2305 Loss: 0.5154736638069153\n",
      "Batch: 2369 Loss: 0.5253280401229858\n",
      "Batch: 2433 Loss: 0.4426051676273346\n",
      "Batch: 2497 Loss: 0.5054152011871338\n",
      "Batch: 2561 Loss: 0.42976534366607666\n",
      "Batch: 2625 Loss: 0.43477192521095276\n",
      "Batch: 2689 Loss: 0.4493471682071686\n",
      "Batch: 2753 Loss: 0.3780307471752167\n",
      "Batch: 2817 Loss: 0.5492287874221802\n",
      "Batch: 2881 Loss: 0.4855321943759918\n",
      "Batch: 2945 Loss: 0.42812538146972656\n",
      "Batch: 3009 Loss: 0.5806257128715515\n",
      "Batch: 3073 Loss: 0.4639381766319275\n",
      "Batch: 3137 Loss: 0.4240929186344147\n",
      "Batch: 3201 Loss: 0.39511749148368835\n",
      "Batch: 3265 Loss: 0.3770550787448883\n",
      "Batch: 3329 Loss: 0.4049915671348572\n",
      "Batch: 3393 Loss: 0.4485705494880676\n",
      "Batch: 3457 Loss: 0.4181756377220154\n",
      "Batch: 3521 Loss: 0.3170187771320343\n",
      "Batch: 3585 Loss: 0.305241197347641\n",
      "Batch: 3649 Loss: 0.5043206810951233\n",
      "Batch: 3713 Loss: 0.4157766103744507\n",
      "Batch: 3777 Loss: 0.44293808937072754\n",
      "Batch: 3841 Loss: 0.44446486234664917\n",
      "Batch: 3905 Loss: 0.39207643270492554\n",
      "Batch: 3969 Loss: 0.5429251790046692\n",
      "Batch: 4033 Loss: 0.40867042541503906\n",
      "Batch: 4097 Loss: 0.3992632031440735\n",
      "Batch: 4161 Loss: 0.4708559513092041\n",
      "Batch: 4225 Loss: 0.34030023217201233\n",
      "Batch: 4289 Loss: 0.3640938699245453\n",
      "Batch: 4353 Loss: 0.49875059723854065\n",
      "Batch: 4417 Loss: 0.6687960624694824\n",
      "Batch: 4481 Loss: 0.7095590829849243\n",
      "Batch: 4545 Loss: 0.5674664974212646\n",
      "Batch: 4609 Loss: 0.37754708528518677\n",
      "Batch: 4673 Loss: 0.3572752773761749\n",
      "Batch: 4737 Loss: 0.46290525794029236\n",
      "Batch: 4801 Loss: 0.3812752068042755\n",
      "Batch: 4865 Loss: 0.39341384172439575\n",
      "Batch: 4929 Loss: 0.4417131841182709\n",
      "Batch: 4993 Loss: 0.5547035336494446\n",
      "Batch: 5057 Loss: 0.5335792899131775\n",
      "Batch: 5121 Loss: 0.4343053996562958\n",
      "Batch: 5185 Loss: 0.8763585090637207\n",
      "Batch: 5249 Loss: 0.3829052448272705\n",
      "Batch: 5313 Loss: 0.451237291097641\n",
      "Batch: 5377 Loss: 0.4317493736743927\n",
      "Batch: 5441 Loss: 0.5362564921379089\n",
      "Batch: 5505 Loss: 0.49578747153282166\n",
      "Batch: 5569 Loss: 0.529596745967865\n",
      "Batch: 5633 Loss: 0.3900144696235657\n",
      "Batch: 5697 Loss: 0.44656017422676086\n",
      "Batch: 5761 Loss: 0.5666109919548035\n",
      "Batch: 5825 Loss: 0.4430409371852875\n",
      "Batch: 5889 Loss: 0.3915114998817444\n",
      "Batch: 5953 Loss: 0.39002808928489685\n",
      "Batch: 6017 Loss: 0.33970382809638977\n",
      "Batch: 6081 Loss: 0.3282919228076935\n",
      "Batch: 6145 Loss: 0.43822792172431946\n",
      "Batch: 6209 Loss: 0.37797147035598755\n",
      "Batch: 6273 Loss: 0.4719705879688263\n",
      "Batch: 6337 Loss: 0.3465806245803833\n",
      "Batch: 6401 Loss: 0.34155187010765076\n",
      "Batch: 6465 Loss: 0.3866749405860901\n",
      "Batch: 6529 Loss: 0.3665633797645569\n",
      "Batch: 6593 Loss: 0.40443989634513855\n",
      "Batch: 6657 Loss: 0.3295177221298218\n",
      "Batch: 6721 Loss: 0.4588138163089752\n",
      "Batch: 6785 Loss: 0.44417575001716614\n",
      "Batch: 6849 Loss: 0.45238497853279114\n",
      "Batch: 6913 Loss: 0.40927842259407043\n",
      "Batch: 6977 Loss: 0.43690577149391174\n",
      "Batch: 7041 Loss: 0.4261510372161865\n",
      "Batch: 7105 Loss: 0.360240638256073\n",
      "Batch: 7169 Loss: 0.42571455240249634\n",
      "Batch: 7233 Loss: 0.3704918920993805\n",
      "Batch: 7297 Loss: 0.42658761143684387\n",
      "Batch: 7361 Loss: 0.39680641889572144\n",
      "Batch: 7425 Loss: 0.48504874110221863\n",
      "Batch: 7489 Loss: 0.5739471912384033\n",
      "Batch: 7553 Loss: 0.3754030168056488\n",
      "Batch: 7617 Loss: 0.3669608235359192\n",
      "Batch: 7681 Loss: 0.4510408341884613\n",
      "Batch: 7745 Loss: 0.4658781588077545\n",
      "Batch: 7809 Loss: 0.42704927921295166\n",
      "Batch: 7873 Loss: 0.36171555519104004\n",
      "Batch: 7937 Loss: 0.573019802570343\n",
      "Batch: 8001 Loss: 0.4299953877925873\n",
      "Batch: 8065 Loss: 0.5747875571250916\n",
      "Batch: 8129 Loss: 0.43677905201911926\n",
      "Batch: 8193 Loss: 0.47495996952056885\n",
      "Batch: 8257 Loss: 0.5049186944961548\n",
      "Batch: 8321 Loss: 0.654844343662262\n",
      "Batch: 8385 Loss: 0.3277001678943634\n",
      "Batch: 8449 Loss: 0.3602050840854645\n",
      "Batch: 8513 Loss: 0.6455740332603455\n",
      "Batch: 8577 Loss: 0.3400396406650543\n",
      "Batch: 8641 Loss: 0.5225521326065063\n",
      "Batch: 8705 Loss: 0.42615753412246704\n",
      "Batch: 8769 Loss: 0.48843520879745483\n",
      "Batch: 8833 Loss: 0.5335580706596375\n",
      "Batch: 8897 Loss: 0.8122743964195251\n",
      "Batch: 8961 Loss: 0.4053976535797119\n",
      "Batch: 9025 Loss: 0.3971629738807678\n",
      "Batch: 9089 Loss: 0.411353200674057\n",
      "Batch: 9153 Loss: 0.4726352393627167\n",
      "Batch: 9217 Loss: 0.5125281810760498\n",
      "Batch: 9281 Loss: 0.4775698482990265\n",
      "Batch: 9345 Loss: 0.399646520614624\n",
      "Batch: 9409 Loss: 0.5627415776252747\n",
      "Batch: 9473 Loss: 0.5873737335205078\n",
      "Batch: 9537 Loss: 0.4992160499095917\n",
      "Batch: 9601 Loss: 0.38307955861091614\n",
      "Batch: 9665 Loss: 0.349290668964386\n",
      "Batch: 9729 Loss: 0.45434120297431946\n",
      "Batch: 9793 Loss: 0.39294809103012085\n",
      "Batch: 9857 Loss: 0.4383600950241089\n",
      "Batch: 9921 Loss: 0.4062923789024353\n",
      "Batch: 9985 Loss: 0.4636039733886719\n",
      "Batch: 10049 Loss: 0.5307514667510986\n",
      "Batch: 10113 Loss: 0.42085665464401245\n",
      "Batch: 10177 Loss: 0.497991144657135\n",
      "Batch: 10241 Loss: 0.38072142004966736\n",
      "Batch: 10305 Loss: 0.4506837725639343\n",
      "Batch: 10369 Loss: 0.4875870645046234\n",
      "Batch: 10433 Loss: 0.40690499544143677\n",
      "Batch: 10497 Loss: 0.39892861247062683\n",
      "Batch: 10561 Loss: 0.3774084150791168\n",
      "Batch: 10625 Loss: 0.44418445229530334\n",
      "Batch: 10689 Loss: 0.4349578619003296\n",
      "Batch: 10753 Loss: 0.3626369535923004\n",
      "Batch: 10817 Loss: 0.3146764039993286\n",
      "Batch: 10881 Loss: 0.36880213022232056\n",
      "Batch: 10945 Loss: 0.36574068665504456\n",
      "Batch: 11009 Loss: 0.42227041721343994\n",
      "Batch: 11073 Loss: 0.4728236794471741\n",
      "Batch: 11137 Loss: 0.3836708068847656\n",
      "Batch: 11201 Loss: 0.39791956543922424\n",
      "Batch: 11265 Loss: 0.5395039319992065\n",
      "Batch: 11329 Loss: 0.6584502458572388\n",
      "Batch: 11393 Loss: 0.31509533524513245\n",
      "Batch: 11457 Loss: 0.3922594487667084\n",
      "Batch: 11521 Loss: 0.3990490734577179\n",
      "Batch: 11585 Loss: 0.4974955916404724\n",
      "Batch: 11649 Loss: 0.3316112160682678\n",
      "Batch: 11713 Loss: 0.4374586045742035\n",
      "Batch: 11777 Loss: 0.6184443831443787\n",
      "Batch: 11841 Loss: 0.5854769349098206\n",
      "Batch: 11905 Loss: 0.469482421875\n",
      "Batch: 11969 Loss: 0.45672541856765747\n",
      "Batch: 12033 Loss: 0.3770765960216522\n",
      "Batch: 12097 Loss: 0.9516525864601135\n",
      "Batch: 12161 Loss: 0.5256549715995789\n",
      "Batch: 12225 Loss: 0.30456557869911194\n",
      "Batch: 12289 Loss: 0.3236289918422699\n",
      "Batch: 12353 Loss: 0.4421231746673584\n",
      "Batch: 12417 Loss: 0.38179609179496765\n",
      "Batch: 12481 Loss: 0.41243332624435425\n",
      "Batch: 12545 Loss: 0.48513704538345337\n",
      "Batch: 12609 Loss: 0.5284802913665771\n",
      "Batch: 12673 Loss: 0.5565317273139954\n",
      "Batch: 12737 Loss: 0.45748844742774963\n",
      "Batch: 12801 Loss: 0.38865235447883606\n",
      "Batch: 12865 Loss: 0.32857540249824524\n",
      "Batch: 12929 Loss: 0.6689755916595459\n",
      "Epoch: 17\n",
      "Batch: 1 Loss: 0.41723743081092834\n",
      "Batch: 65 Loss: 0.4787289500236511\n",
      "Batch: 129 Loss: 0.4091920852661133\n",
      "Batch: 193 Loss: 0.6113709807395935\n",
      "Batch: 257 Loss: 0.44536134600639343\n",
      "Batch: 321 Loss: 0.4176257848739624\n",
      "Batch: 385 Loss: 0.4193422198295593\n",
      "Batch: 449 Loss: 0.38578999042510986\n",
      "Batch: 513 Loss: 0.3984330892562866\n",
      "Batch: 577 Loss: 0.39592933654785156\n",
      "Batch: 641 Loss: 0.47118186950683594\n",
      "Batch: 705 Loss: 0.4177189767360687\n",
      "Batch: 769 Loss: 0.46967825293540955\n",
      "Batch: 833 Loss: 0.3474084734916687\n",
      "Batch: 897 Loss: 0.5797940492630005\n",
      "Batch: 961 Loss: 0.3687579333782196\n",
      "Batch: 1025 Loss: 0.40442603826522827\n",
      "Batch: 1089 Loss: 0.39821839332580566\n",
      "Batch: 1153 Loss: 0.43096640706062317\n",
      "Batch: 1217 Loss: 0.3921939432621002\n",
      "Batch: 1281 Loss: 0.4195878207683563\n",
      "Batch: 1345 Loss: 0.42987334728240967\n",
      "Batch: 1409 Loss: 0.3655363619327545\n",
      "Batch: 1473 Loss: 0.42023035883903503\n",
      "Batch: 1537 Loss: 0.3928285539150238\n",
      "Batch: 1601 Loss: 0.3377225399017334\n",
      "Batch: 1665 Loss: 0.37218785285949707\n",
      "Batch: 1729 Loss: 0.4415644407272339\n",
      "Batch: 1793 Loss: 0.3383578062057495\n",
      "Batch: 1857 Loss: 0.39470532536506653\n",
      "Batch: 1921 Loss: 0.4514862895011902\n",
      "Batch: 1985 Loss: 0.3726052939891815\n",
      "Batch: 2049 Loss: 0.34772375226020813\n",
      "Batch: 2113 Loss: 0.38946083188056946\n",
      "Batch: 2177 Loss: 0.43044885993003845\n",
      "Batch: 2241 Loss: 0.47418227791786194\n",
      "Batch: 2305 Loss: 0.5023736953735352\n",
      "Batch: 2369 Loss: 0.5233736634254456\n",
      "Batch: 2433 Loss: 0.44159212708473206\n",
      "Batch: 2497 Loss: 0.5001281499862671\n",
      "Batch: 2561 Loss: 0.4275192320346832\n",
      "Batch: 2625 Loss: 0.43346935510635376\n",
      "Batch: 2689 Loss: 0.4467637538909912\n",
      "Batch: 2753 Loss: 0.37793979048728943\n",
      "Batch: 2817 Loss: 0.5525845885276794\n",
      "Batch: 2881 Loss: 0.4824189245700836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2945 Loss: 0.41555988788604736\n",
      "Batch: 3009 Loss: 0.576720654964447\n",
      "Batch: 3073 Loss: 0.4604407846927643\n",
      "Batch: 3137 Loss: 0.41687309741973877\n",
      "Batch: 3201 Loss: 0.3940645158290863\n",
      "Batch: 3265 Loss: 0.375873327255249\n",
      "Batch: 3329 Loss: 0.4038066267967224\n",
      "Batch: 3393 Loss: 0.4469262957572937\n",
      "Batch: 3457 Loss: 0.4145662784576416\n",
      "Batch: 3521 Loss: 0.31224626302719116\n",
      "Batch: 3585 Loss: 0.30554577708244324\n",
      "Batch: 3649 Loss: 0.5033199191093445\n",
      "Batch: 3713 Loss: 0.4144832193851471\n",
      "Batch: 3777 Loss: 0.4369838535785675\n",
      "Batch: 3841 Loss: 0.43410682678222656\n",
      "Batch: 3905 Loss: 0.3914705216884613\n",
      "Batch: 3969 Loss: 0.5446180105209351\n",
      "Batch: 4033 Loss: 0.4107780158519745\n",
      "Batch: 4097 Loss: 0.400594025850296\n",
      "Batch: 4161 Loss: 0.4692559540271759\n",
      "Batch: 4225 Loss: 0.3393597900867462\n",
      "Batch: 4289 Loss: 0.3633582592010498\n",
      "Batch: 4353 Loss: 0.49626994132995605\n",
      "Batch: 4417 Loss: 0.6594297289848328\n",
      "Batch: 4481 Loss: 0.7049286961555481\n",
      "Batch: 4545 Loss: 0.5623815059661865\n",
      "Batch: 4609 Loss: 0.38415172696113586\n",
      "Batch: 4673 Loss: 0.35944920778274536\n",
      "Batch: 4737 Loss: 0.4632168412208557\n",
      "Batch: 4801 Loss: 0.38048994541168213\n",
      "Batch: 4865 Loss: 0.39240655303001404\n",
      "Batch: 4929 Loss: 0.4303736388683319\n",
      "Batch: 4993 Loss: 0.5486454963684082\n",
      "Batch: 5057 Loss: 0.5347640514373779\n",
      "Batch: 5121 Loss: 0.4249764084815979\n",
      "Batch: 5185 Loss: 0.8730176687240601\n",
      "Batch: 5249 Loss: 0.38543957471847534\n",
      "Batch: 5313 Loss: 0.4585055708885193\n",
      "Batch: 5377 Loss: 0.43040022253990173\n",
      "Batch: 5441 Loss: 0.533802330493927\n",
      "Batch: 5505 Loss: 0.4957488179206848\n",
      "Batch: 5569 Loss: 0.528708279132843\n",
      "Batch: 5633 Loss: 0.39115941524505615\n",
      "Batch: 5697 Loss: 0.4553159177303314\n",
      "Batch: 5761 Loss: 0.570816159248352\n",
      "Batch: 5825 Loss: 0.4384765028953552\n",
      "Batch: 5889 Loss: 0.39006564021110535\n",
      "Batch: 5953 Loss: 0.3871176540851593\n",
      "Batch: 6017 Loss: 0.33117997646331787\n",
      "Batch: 6081 Loss: 0.3270384967327118\n",
      "Batch: 6145 Loss: 0.44322359561920166\n",
      "Batch: 6209 Loss: 0.3782537579536438\n",
      "Batch: 6273 Loss: 0.4717446565628052\n",
      "Batch: 6337 Loss: 0.34476128220558167\n",
      "Batch: 6401 Loss: 0.34193482995033264\n",
      "Batch: 6465 Loss: 0.3858388364315033\n",
      "Batch: 6529 Loss: 0.36445677280426025\n",
      "Batch: 6593 Loss: 0.4017029404640198\n",
      "Batch: 6657 Loss: 0.32766619324684143\n",
      "Batch: 6721 Loss: 0.45590683817863464\n",
      "Batch: 6785 Loss: 0.44150203466415405\n",
      "Batch: 6849 Loss: 0.4398711323738098\n",
      "Batch: 6913 Loss: 0.4079061448574066\n",
      "Batch: 6977 Loss: 0.44267284870147705\n",
      "Batch: 7041 Loss: 0.42942774295806885\n",
      "Batch: 7105 Loss: 0.3589570224285126\n",
      "Batch: 7169 Loss: 0.43136823177337646\n",
      "Batch: 7233 Loss: 0.37475305795669556\n",
      "Batch: 7297 Loss: 0.4271150529384613\n",
      "Batch: 7361 Loss: 0.3966699242591858\n",
      "Batch: 7425 Loss: 0.4823153614997864\n",
      "Batch: 7489 Loss: 0.5727285742759705\n",
      "Batch: 7553 Loss: 0.37537312507629395\n",
      "Batch: 7617 Loss: 0.37009817361831665\n",
      "Batch: 7681 Loss: 0.4491865038871765\n",
      "Batch: 7745 Loss: 0.4637896418571472\n",
      "Batch: 7809 Loss: 0.4242619276046753\n",
      "Batch: 7873 Loss: 0.356262743473053\n",
      "Batch: 7937 Loss: 0.5665861368179321\n",
      "Batch: 8001 Loss: 0.4306212365627289\n",
      "Batch: 8065 Loss: 0.5765154361724854\n",
      "Batch: 8129 Loss: 0.4370061159133911\n",
      "Batch: 8193 Loss: 0.48028048872947693\n",
      "Batch: 8257 Loss: 0.5034123659133911\n",
      "Batch: 8321 Loss: 0.6561436057090759\n",
      "Batch: 8385 Loss: 0.32489243149757385\n",
      "Batch: 8449 Loss: 0.35778334736824036\n",
      "Batch: 8513 Loss: 0.6439220905303955\n",
      "Batch: 8577 Loss: 0.3399350941181183\n",
      "Batch: 8641 Loss: 0.5201297402381897\n",
      "Batch: 8705 Loss: 0.4271850883960724\n",
      "Batch: 8769 Loss: 0.4913288354873657\n",
      "Batch: 8833 Loss: 0.5367503762245178\n",
      "Batch: 8897 Loss: 0.8150008320808411\n",
      "Batch: 8961 Loss: 0.4044022262096405\n",
      "Batch: 9025 Loss: 0.3965083360671997\n",
      "Batch: 9089 Loss: 0.4076458811759949\n",
      "Batch: 9153 Loss: 0.4718300700187683\n",
      "Batch: 9217 Loss: 0.513486921787262\n",
      "Batch: 9281 Loss: 0.48092347383499146\n",
      "Batch: 9345 Loss: 0.40913066267967224\n",
      "Batch: 9409 Loss: 0.5501659512519836\n",
      "Batch: 9473 Loss: 0.5881197452545166\n",
      "Batch: 9537 Loss: 0.4895017743110657\n",
      "Batch: 9601 Loss: 0.37608712911605835\n",
      "Batch: 9665 Loss: 0.35222378373146057\n",
      "Batch: 9729 Loss: 0.4543454051017761\n",
      "Batch: 9793 Loss: 0.3921486735343933\n",
      "Batch: 9857 Loss: 0.43718579411506653\n",
      "Batch: 9921 Loss: 0.4095965027809143\n",
      "Batch: 9985 Loss: 0.463111013174057\n",
      "Batch: 10049 Loss: 0.5326367020606995\n",
      "Batch: 10113 Loss: 0.4239562153816223\n",
      "Batch: 10177 Loss: 0.5000571608543396\n",
      "Batch: 10241 Loss: 0.37831658124923706\n",
      "Batch: 10305 Loss: 0.45048198103904724\n",
      "Batch: 10369 Loss: 0.4907798171043396\n",
      "Batch: 10433 Loss: 0.4087947905063629\n",
      "Batch: 10497 Loss: 0.4004957377910614\n",
      "Batch: 10561 Loss: 0.37271320819854736\n",
      "Batch: 10625 Loss: 0.4438033998012543\n",
      "Batch: 10689 Loss: 0.4327937960624695\n",
      "Batch: 10753 Loss: 0.3624955415725708\n",
      "Batch: 10817 Loss: 0.3156839609146118\n",
      "Batch: 10881 Loss: 0.36766740679740906\n",
      "Batch: 10945 Loss: 0.36933478713035583\n",
      "Batch: 11009 Loss: 0.42624276876449585\n",
      "Batch: 11073 Loss: 0.46564748883247375\n",
      "Batch: 11137 Loss: 0.3831694722175598\n",
      "Batch: 11201 Loss: 0.40253207087516785\n",
      "Batch: 11265 Loss: 0.542299211025238\n",
      "Batch: 11329 Loss: 0.6676155924797058\n",
      "Batch: 11393 Loss: 0.3223223388195038\n",
      "Batch: 11457 Loss: 0.39241981506347656\n",
      "Batch: 11521 Loss: 0.40451085567474365\n",
      "Batch: 11585 Loss: 0.49741923809051514\n",
      "Batch: 11649 Loss: 0.334934264421463\n",
      "Batch: 11713 Loss: 0.44045430421829224\n",
      "Batch: 11777 Loss: 0.6196532845497131\n",
      "Batch: 11841 Loss: 0.5854905843734741\n",
      "Batch: 11905 Loss: 0.47031426429748535\n",
      "Batch: 11969 Loss: 0.448535680770874\n",
      "Batch: 12033 Loss: 0.37920963764190674\n",
      "Batch: 12097 Loss: 0.9470965266227722\n",
      "Batch: 12161 Loss: 0.5237834453582764\n",
      "Batch: 12225 Loss: 0.30484697222709656\n",
      "Batch: 12289 Loss: 0.32441872358322144\n",
      "Batch: 12353 Loss: 0.4373888075351715\n",
      "Batch: 12417 Loss: 0.3756759464740753\n",
      "Batch: 12481 Loss: 0.4083888828754425\n",
      "Batch: 12545 Loss: 0.4861254394054413\n",
      "Batch: 12609 Loss: 0.5281276106834412\n",
      "Batch: 12673 Loss: 0.5537064075469971\n",
      "Batch: 12737 Loss: 0.4583470821380615\n",
      "Batch: 12801 Loss: 0.38844045996665955\n",
      "Batch: 12865 Loss: 0.3291282057762146\n",
      "Batch: 12929 Loss: 0.6696037650108337\n",
      "Epoch: 18\n",
      "Batch: 1 Loss: 0.41485705971717834\n",
      "Batch: 65 Loss: 0.4776739180088043\n",
      "Batch: 129 Loss: 0.40737220644950867\n",
      "Batch: 193 Loss: 0.6026617288589478\n",
      "Batch: 257 Loss: 0.43036386370658875\n",
      "Batch: 321 Loss: 0.4127649664878845\n",
      "Batch: 385 Loss: 0.41383877396583557\n",
      "Batch: 449 Loss: 0.3834572434425354\n",
      "Batch: 513 Loss: 0.39747053384780884\n",
      "Batch: 577 Loss: 0.39447903633117676\n",
      "Batch: 641 Loss: 0.47153380513191223\n",
      "Batch: 705 Loss: 0.4181813895702362\n",
      "Batch: 769 Loss: 0.4709850549697876\n",
      "Batch: 833 Loss: 0.3463442623615265\n",
      "Batch: 897 Loss: 0.5763970613479614\n",
      "Batch: 961 Loss: 0.3698103427886963\n",
      "Batch: 1025 Loss: 0.400936484336853\n",
      "Batch: 1089 Loss: 0.39370495080947876\n",
      "Batch: 1153 Loss: 0.42592549324035645\n",
      "Batch: 1217 Loss: 0.393698126077652\n",
      "Batch: 1281 Loss: 0.4197602868080139\n",
      "Batch: 1345 Loss: 0.4292279779911041\n",
      "Batch: 1409 Loss: 0.36527320742607117\n",
      "Batch: 1473 Loss: 0.4218050539493561\n",
      "Batch: 1537 Loss: 0.3938390910625458\n",
      "Batch: 1601 Loss: 0.3398869037628174\n",
      "Batch: 1665 Loss: 0.37233078479766846\n",
      "Batch: 1729 Loss: 0.4408925473690033\n",
      "Batch: 1793 Loss: 0.3377395570278168\n",
      "Batch: 1857 Loss: 0.394928514957428\n",
      "Batch: 1921 Loss: 0.4507409334182739\n",
      "Batch: 1985 Loss: 0.3732561767101288\n",
      "Batch: 2049 Loss: 0.3485257029533386\n",
      "Batch: 2113 Loss: 0.3840634226799011\n",
      "Batch: 2177 Loss: 0.4344055950641632\n",
      "Batch: 2241 Loss: 0.4778328835964203\n",
      "Batch: 2305 Loss: 0.5110177397727966\n",
      "Batch: 2369 Loss: 0.5019692778587341\n",
      "Batch: 2433 Loss: 0.4463678002357483\n",
      "Batch: 2497 Loss: 0.49735862016677856\n",
      "Batch: 2561 Loss: 0.42841607332229614\n",
      "Batch: 2625 Loss: 0.43293437361717224\n",
      "Batch: 2689 Loss: 0.44888433814048767\n",
      "Batch: 2753 Loss: 0.37634021043777466\n",
      "Batch: 2817 Loss: 0.5486823916435242\n",
      "Batch: 2881 Loss: 0.48676058650016785\n",
      "Batch: 2945 Loss: 0.4205434024333954\n",
      "Batch: 3009 Loss: 0.5768815279006958\n",
      "Batch: 3073 Loss: 0.4610413908958435\n",
      "Batch: 3137 Loss: 0.41946521401405334\n",
      "Batch: 3201 Loss: 0.39201897382736206\n",
      "Batch: 3265 Loss: 0.37636294960975647\n",
      "Batch: 3329 Loss: 0.40476468205451965\n",
      "Batch: 3393 Loss: 0.44778499007225037\n",
      "Batch: 3457 Loss: 0.41420474648475647\n",
      "Batch: 3521 Loss: 0.31448426842689514\n",
      "Batch: 3585 Loss: 0.30324432253837585\n",
      "Batch: 3649 Loss: 0.4992935359477997\n",
      "Batch: 3713 Loss: 0.41076216101646423\n",
      "Batch: 3777 Loss: 0.43918415904045105\n",
      "Batch: 3841 Loss: 0.4406830072402954\n",
      "Batch: 3905 Loss: 0.39119985699653625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 3969 Loss: 0.5414106249809265\n",
      "Batch: 4033 Loss: 0.40787091851234436\n",
      "Batch: 4097 Loss: 0.3977784812450409\n",
      "Batch: 4161 Loss: 0.46717390418052673\n",
      "Batch: 4225 Loss: 0.33910050988197327\n",
      "Batch: 4289 Loss: 0.3632936179637909\n",
      "Batch: 4353 Loss: 0.497895747423172\n",
      "Batch: 4417 Loss: 0.6573657393455505\n",
      "Batch: 4481 Loss: 0.696673572063446\n",
      "Batch: 4545 Loss: 0.5611337423324585\n",
      "Batch: 4609 Loss: 0.3781355619430542\n",
      "Batch: 4673 Loss: 0.35656726360321045\n",
      "Batch: 4737 Loss: 0.4612429141998291\n",
      "Batch: 4801 Loss: 0.3785134553909302\n",
      "Batch: 4865 Loss: 0.3864855170249939\n",
      "Batch: 4929 Loss: 0.42868152260780334\n",
      "Batch: 4993 Loss: 0.546425998210907\n",
      "Batch: 5057 Loss: 0.5265499353408813\n",
      "Batch: 5121 Loss: 0.4104320704936981\n",
      "Batch: 5185 Loss: 0.8652068376541138\n",
      "Batch: 5249 Loss: 0.38101840019226074\n",
      "Batch: 5313 Loss: 0.44938716292381287\n",
      "Batch: 5377 Loss: 0.43000873923301697\n",
      "Batch: 5441 Loss: 0.5379180908203125\n",
      "Batch: 5505 Loss: 0.4943236708641052\n",
      "Batch: 5569 Loss: 0.5280869603157043\n",
      "Batch: 5633 Loss: 0.39050164818763733\n",
      "Batch: 5697 Loss: 0.44639039039611816\n",
      "Batch: 5761 Loss: 0.5607421398162842\n",
      "Batch: 5825 Loss: 0.4383336901664734\n",
      "Batch: 5889 Loss: 0.3868434727191925\n",
      "Batch: 5953 Loss: 0.3898307979106903\n",
      "Batch: 6017 Loss: 0.3275742828845978\n",
      "Batch: 6081 Loss: 0.3308693766593933\n",
      "Batch: 6145 Loss: 0.44457533955574036\n",
      "Batch: 6209 Loss: 0.3799828588962555\n",
      "Batch: 6273 Loss: 0.47056180238723755\n",
      "Batch: 6337 Loss: 0.34380772709846497\n",
      "Batch: 6401 Loss: 0.34143689274787903\n",
      "Batch: 6465 Loss: 0.38308820128440857\n",
      "Batch: 6529 Loss: 0.3641664981842041\n",
      "Batch: 6593 Loss: 0.4021158218383789\n",
      "Batch: 6657 Loss: 0.3284662663936615\n",
      "Batch: 6721 Loss: 0.45914778113365173\n",
      "Batch: 6785 Loss: 0.4399683177471161\n",
      "Batch: 6849 Loss: 0.4392969012260437\n",
      "Batch: 6913 Loss: 0.4085262715816498\n",
      "Batch: 6977 Loss: 0.439079612493515\n",
      "Batch: 7041 Loss: 0.42539700865745544\n",
      "Batch: 7105 Loss: 0.3576247990131378\n",
      "Batch: 7169 Loss: 0.4235532879829407\n",
      "Batch: 7233 Loss: 0.36989471316337585\n",
      "Batch: 7297 Loss: 0.42409518361091614\n",
      "Batch: 7361 Loss: 0.3948257267475128\n",
      "Batch: 7425 Loss: 0.4791718125343323\n",
      "Batch: 7489 Loss: 0.5728245377540588\n",
      "Batch: 7553 Loss: 0.37357571721076965\n",
      "Batch: 7617 Loss: 0.3658801019191742\n",
      "Batch: 7681 Loss: 0.45059752464294434\n",
      "Batch: 7745 Loss: 0.4634973704814911\n",
      "Batch: 7809 Loss: 0.42319828271865845\n",
      "Batch: 7873 Loss: 0.36194324493408203\n",
      "Batch: 7937 Loss: 0.5676053762435913\n",
      "Batch: 8001 Loss: 0.4253027141094208\n",
      "Batch: 8065 Loss: 0.5691348910331726\n",
      "Batch: 8129 Loss: 0.42772454023361206\n",
      "Batch: 8193 Loss: 0.4677797555923462\n",
      "Batch: 8257 Loss: 0.4815899729728699\n",
      "Batch: 8321 Loss: 0.6473944783210754\n",
      "Batch: 8385 Loss: 0.3261216878890991\n",
      "Batch: 8449 Loss: 0.35292208194732666\n",
      "Batch: 8513 Loss: 0.6398042440414429\n",
      "Batch: 8577 Loss: 0.33882302045822144\n",
      "Batch: 8641 Loss: 0.5207770466804504\n",
      "Batch: 8705 Loss: 0.42039474844932556\n",
      "Batch: 8769 Loss: 0.48597994446754456\n",
      "Batch: 8833 Loss: 0.5335530638694763\n",
      "Batch: 8897 Loss: 0.8086485266685486\n",
      "Batch: 8961 Loss: 0.3994537889957428\n",
      "Batch: 9025 Loss: 0.39643990993499756\n",
      "Batch: 9089 Loss: 0.4068721532821655\n",
      "Batch: 9153 Loss: 0.47399410605430603\n",
      "Batch: 9217 Loss: 0.516086757183075\n",
      "Batch: 9281 Loss: 0.48240581154823303\n",
      "Batch: 9345 Loss: 0.3925861418247223\n",
      "Batch: 9409 Loss: 0.527974545955658\n",
      "Batch: 9473 Loss: 0.5792854428291321\n",
      "Batch: 9537 Loss: 0.4843240976333618\n",
      "Batch: 9601 Loss: 0.3750495910644531\n",
      "Batch: 9665 Loss: 0.35592153668403625\n",
      "Batch: 9729 Loss: 0.45922142267227173\n",
      "Batch: 9793 Loss: 0.39597997069358826\n",
      "Batch: 9857 Loss: 0.44372037053108215\n",
      "Batch: 9921 Loss: 0.41552409529685974\n",
      "Batch: 9985 Loss: 0.4605381190776825\n",
      "Batch: 10049 Loss: 0.5310457944869995\n",
      "Batch: 10113 Loss: 0.4186045825481415\n",
      "Batch: 10177 Loss: 0.49790504574775696\n",
      "Batch: 10241 Loss: 0.37993887066841125\n",
      "Batch: 10305 Loss: 0.44767218828201294\n",
      "Batch: 10369 Loss: 0.4911172389984131\n",
      "Batch: 10433 Loss: 0.4092485308647156\n",
      "Batch: 10497 Loss: 0.39822137355804443\n",
      "Batch: 10561 Loss: 0.3718392550945282\n",
      "Batch: 10625 Loss: 0.4426426291465759\n",
      "Batch: 10689 Loss: 0.4347118139266968\n",
      "Batch: 10753 Loss: 0.36049872636795044\n",
      "Batch: 10817 Loss: 0.3140128254890442\n",
      "Batch: 10881 Loss: 0.36846697330474854\n",
      "Batch: 10945 Loss: 0.3754417598247528\n",
      "Batch: 11009 Loss: 0.4259609282016754\n",
      "Batch: 11073 Loss: 0.46594759821891785\n",
      "Batch: 11137 Loss: 0.38018059730529785\n",
      "Batch: 11201 Loss: 0.3945862054824829\n",
      "Batch: 11265 Loss: 0.5352181792259216\n",
      "Batch: 11329 Loss: 0.6533564329147339\n",
      "Batch: 11393 Loss: 0.31108787655830383\n",
      "Batch: 11457 Loss: 0.3811550736427307\n",
      "Batch: 11521 Loss: 0.39571473002433777\n",
      "Batch: 11585 Loss: 0.4987882375717163\n",
      "Batch: 11649 Loss: 0.3381440043449402\n",
      "Batch: 11713 Loss: 0.4390898048877716\n",
      "Batch: 11777 Loss: 0.6160473227500916\n",
      "Batch: 11841 Loss: 0.5887059569358826\n",
      "Batch: 11905 Loss: 0.46480533480644226\n",
      "Batch: 11969 Loss: 0.44091373682022095\n",
      "Batch: 12033 Loss: 0.3765570819377899\n",
      "Batch: 12097 Loss: 0.9500632882118225\n",
      "Batch: 12161 Loss: 0.5271288752555847\n",
      "Batch: 12225 Loss: 0.3084356188774109\n",
      "Batch: 12289 Loss: 0.32600322365760803\n",
      "Batch: 12353 Loss: 0.4381953477859497\n",
      "Batch: 12417 Loss: 0.3739149570465088\n",
      "Batch: 12481 Loss: 0.4078439474105835\n",
      "Batch: 12545 Loss: 0.4872664213180542\n",
      "Batch: 12609 Loss: 0.531383216381073\n",
      "Batch: 12673 Loss: 0.5537589192390442\n",
      "Batch: 12737 Loss: 0.45819681882858276\n",
      "Batch: 12801 Loss: 0.38600799441337585\n",
      "Batch: 12865 Loss: 0.3293132781982422\n",
      "Batch: 12929 Loss: 0.6661157608032227\n",
      "Epoch: 19\n",
      "Batch: 1 Loss: 0.40923231840133667\n",
      "Batch: 65 Loss: 0.48196983337402344\n",
      "Batch: 129 Loss: 0.4094371199607849\n",
      "Batch: 193 Loss: 0.5966977477073669\n",
      "Batch: 257 Loss: 0.4364859163761139\n",
      "Batch: 321 Loss: 0.41406121850013733\n",
      "Batch: 385 Loss: 0.4143368899822235\n",
      "Batch: 449 Loss: 0.38379132747650146\n",
      "Batch: 513 Loss: 0.39968281984329224\n",
      "Batch: 577 Loss: 0.3944613039493561\n",
      "Batch: 641 Loss: 0.47415652871131897\n",
      "Batch: 705 Loss: 0.4177614152431488\n",
      "Batch: 769 Loss: 0.4714972972869873\n",
      "Batch: 833 Loss: 0.3504036068916321\n",
      "Batch: 897 Loss: 0.5757554769515991\n",
      "Batch: 961 Loss: 0.3707762062549591\n",
      "Batch: 1025 Loss: 0.40191584825515747\n",
      "Batch: 1089 Loss: 0.394538938999176\n",
      "Batch: 1153 Loss: 0.42614296078681946\n",
      "Batch: 1217 Loss: 0.38917750120162964\n",
      "Batch: 1281 Loss: 0.4187333583831787\n",
      "Batch: 1345 Loss: 0.4281245172023773\n",
      "Batch: 1409 Loss: 0.36331725120544434\n",
      "Batch: 1473 Loss: 0.4154881536960602\n",
      "Batch: 1537 Loss: 0.3900308609008789\n",
      "Batch: 1601 Loss: 0.33524221181869507\n",
      "Batch: 1665 Loss: 0.37305736541748047\n",
      "Batch: 1729 Loss: 0.43955251574516296\n",
      "Batch: 1793 Loss: 0.3401281237602234\n",
      "Batch: 1857 Loss: 0.39436203241348267\n",
      "Batch: 1921 Loss: 0.45185545086860657\n",
      "Batch: 1985 Loss: 0.36946901679039\n",
      "Batch: 2049 Loss: 0.34768182039260864\n",
      "Batch: 2113 Loss: 0.3902842402458191\n",
      "Batch: 2177 Loss: 0.4362752139568329\n",
      "Batch: 2241 Loss: 0.47711002826690674\n",
      "Batch: 2305 Loss: 0.5115116238594055\n",
      "Batch: 2369 Loss: 0.5104555487632751\n",
      "Batch: 2433 Loss: 0.43950679898262024\n",
      "Batch: 2497 Loss: 0.5014094114303589\n",
      "Batch: 2561 Loss: 0.42787280678749084\n",
      "Batch: 2625 Loss: 0.4304993450641632\n",
      "Batch: 2689 Loss: 0.45053747296333313\n",
      "Batch: 2753 Loss: 0.37849298119544983\n",
      "Batch: 2817 Loss: 0.5532650947570801\n",
      "Batch: 2881 Loss: 0.4914647340774536\n",
      "Batch: 2945 Loss: 0.4166720509529114\n",
      "Batch: 3009 Loss: 0.5751968026161194\n",
      "Batch: 3073 Loss: 0.4664967954158783\n",
      "Batch: 3137 Loss: 0.41555121541023254\n",
      "Batch: 3201 Loss: 0.39385727047920227\n",
      "Batch: 3265 Loss: 0.3767508268356323\n",
      "Batch: 3329 Loss: 0.4043353199958801\n",
      "Batch: 3393 Loss: 0.44575831294059753\n",
      "Batch: 3457 Loss: 0.41549810767173767\n",
      "Batch: 3521 Loss: 0.3152519166469574\n",
      "Batch: 3585 Loss: 0.30523231625556946\n",
      "Batch: 3649 Loss: 0.49940305948257446\n",
      "Batch: 3713 Loss: 0.41127637028694153\n",
      "Batch: 3777 Loss: 0.4352149963378906\n",
      "Batch: 3841 Loss: 0.4385419487953186\n",
      "Batch: 3905 Loss: 0.3904217779636383\n",
      "Batch: 3969 Loss: 0.5424548983573914\n",
      "Batch: 4033 Loss: 0.4098803699016571\n",
      "Batch: 4097 Loss: 0.4004756212234497\n",
      "Batch: 4161 Loss: 0.4672708511352539\n",
      "Batch: 4225 Loss: 0.33959105610847473\n",
      "Batch: 4289 Loss: 0.36238086223602295\n",
      "Batch: 4353 Loss: 0.5018937587738037\n",
      "Batch: 4417 Loss: 0.6646072268486023\n",
      "Batch: 4481 Loss: 0.704349160194397\n",
      "Batch: 4545 Loss: 0.562950074672699\n",
      "Batch: 4609 Loss: 0.3760581612586975\n",
      "Batch: 4673 Loss: 0.35580721497535706\n",
      "Batch: 4737 Loss: 0.46009618043899536\n",
      "Batch: 4801 Loss: 0.3804742693901062\n",
      "Batch: 4865 Loss: 0.3923726975917816\n",
      "Batch: 4929 Loss: 0.43341803550720215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 4993 Loss: 0.5604795813560486\n",
      "Batch: 5057 Loss: 0.53695148229599\n",
      "Batch: 5121 Loss: 0.42342209815979004\n",
      "Batch: 5185 Loss: 0.8743541240692139\n",
      "Batch: 5249 Loss: 0.3828386962413788\n",
      "Batch: 5313 Loss: 0.4537968039512634\n",
      "Batch: 5377 Loss: 0.4329109191894531\n",
      "Batch: 5441 Loss: 0.5368136167526245\n",
      "Batch: 5505 Loss: 0.4956619143486023\n",
      "Batch: 5569 Loss: 0.5296728014945984\n",
      "Batch: 5633 Loss: 0.38953259587287903\n",
      "Batch: 5697 Loss: 0.4508975148200989\n",
      "Batch: 5761 Loss: 0.5685347318649292\n",
      "Batch: 5825 Loss: 0.4367673993110657\n",
      "Batch: 5889 Loss: 0.39159196615219116\n",
      "Batch: 5953 Loss: 0.3871949017047882\n",
      "Batch: 6017 Loss: 0.3370901644229889\n",
      "Batch: 6081 Loss: 0.3277004063129425\n",
      "Batch: 6145 Loss: 0.4369354546070099\n",
      "Batch: 6209 Loss: 0.3717046082019806\n",
      "Batch: 6273 Loss: 0.46904057264328003\n",
      "Batch: 6337 Loss: 0.3434940278530121\n",
      "Batch: 6401 Loss: 0.3415396213531494\n",
      "Batch: 6465 Loss: 0.38595104217529297\n",
      "Batch: 6529 Loss: 0.36362624168395996\n",
      "Batch: 6593 Loss: 0.4021729528903961\n",
      "Batch: 6657 Loss: 0.32666870951652527\n",
      "Batch: 6721 Loss: 0.4588330388069153\n",
      "Batch: 6785 Loss: 0.44866400957107544\n",
      "Batch: 6849 Loss: 0.44008052349090576\n",
      "Batch: 6913 Loss: 0.40356922149658203\n",
      "Batch: 6977 Loss: 0.435162216424942\n",
      "Batch: 7041 Loss: 0.42406216263771057\n",
      "Batch: 7105 Loss: 0.3581274449825287\n",
      "Batch: 7169 Loss: 0.4243265390396118\n",
      "Batch: 7233 Loss: 0.36454853415489197\n",
      "Batch: 7297 Loss: 0.42243415117263794\n",
      "Batch: 7361 Loss: 0.39230504631996155\n",
      "Batch: 7425 Loss: 0.4787120223045349\n",
      "Batch: 7489 Loss: 0.5717630982398987\n",
      "Batch: 7553 Loss: 0.3734819293022156\n",
      "Batch: 7617 Loss: 0.36822688579559326\n",
      "Batch: 7681 Loss: 0.45096927881240845\n",
      "Batch: 7745 Loss: 0.4640389680862427\n",
      "Batch: 7809 Loss: 0.4234076738357544\n",
      "Batch: 7873 Loss: 0.3595207631587982\n",
      "Batch: 7937 Loss: 0.5689562559127808\n",
      "Batch: 8001 Loss: 0.42845842242240906\n",
      "Batch: 8065 Loss: 0.5735353231430054\n",
      "Batch: 8129 Loss: 0.42949843406677246\n",
      "Batch: 8193 Loss: 0.4719316363334656\n",
      "Batch: 8257 Loss: 0.4841526448726654\n",
      "Batch: 8321 Loss: 0.6497153043746948\n",
      "Batch: 8385 Loss: 0.32324230670928955\n",
      "Batch: 8449 Loss: 0.3554999530315399\n",
      "Batch: 8513 Loss: 0.6422175765037537\n",
      "Batch: 8577 Loss: 0.3396845757961273\n",
      "Batch: 8641 Loss: 0.5228634476661682\n",
      "Batch: 8705 Loss: 0.4274505376815796\n",
      "Batch: 8769 Loss: 0.48962071537971497\n",
      "Batch: 8833 Loss: 0.5297139883041382\n",
      "Batch: 8897 Loss: 0.8086725473403931\n",
      "Batch: 8961 Loss: 0.40461236238479614\n",
      "Batch: 9025 Loss: 0.3942326605319977\n",
      "Batch: 9089 Loss: 0.4065171480178833\n",
      "Batch: 9153 Loss: 0.4719739258289337\n",
      "Batch: 9217 Loss: 0.5102810263633728\n",
      "Batch: 9281 Loss: 0.4800672233104706\n",
      "Batch: 9345 Loss: 0.3955257534980774\n",
      "Batch: 9409 Loss: 0.5604166984558105\n",
      "Batch: 9473 Loss: 0.609078586101532\n",
      "Batch: 9537 Loss: 0.5006487369537354\n",
      "Batch: 9601 Loss: 0.3795817494392395\n",
      "Batch: 9665 Loss: 0.3537133038043976\n",
      "Batch: 9729 Loss: 0.4568740725517273\n",
      "Batch: 9793 Loss: 0.3921745717525482\n",
      "Batch: 9857 Loss: 0.43388229608535767\n",
      "Batch: 9921 Loss: 0.40486451983451843\n",
      "Batch: 9985 Loss: 0.45921942591667175\n",
      "Batch: 10049 Loss: 0.5269249081611633\n",
      "Batch: 10113 Loss: 0.4169316589832306\n",
      "Batch: 10177 Loss: 0.49131226539611816\n",
      "Batch: 10241 Loss: 0.37653160095214844\n",
      "Batch: 10305 Loss: 0.4468928575515747\n",
      "Batch: 10369 Loss: 0.48619401454925537\n",
      "Batch: 10433 Loss: 0.4064882695674896\n",
      "Batch: 10497 Loss: 0.39947158098220825\n",
      "Batch: 10561 Loss: 0.37368443608283997\n",
      "Batch: 10625 Loss: 0.4386994242668152\n",
      "Batch: 10689 Loss: 0.4332243800163269\n",
      "Batch: 10753 Loss: 0.3589559495449066\n",
      "Batch: 10817 Loss: 0.3146268427371979\n",
      "Batch: 10881 Loss: 0.3695724904537201\n",
      "Batch: 10945 Loss: 0.363982230424881\n",
      "Batch: 11009 Loss: 0.40475931763648987\n",
      "Batch: 11073 Loss: 0.46556830406188965\n",
      "Batch: 11137 Loss: 0.38115039467811584\n",
      "Batch: 11201 Loss: 0.40481188893318176\n",
      "Batch: 11265 Loss: 0.5419686436653137\n",
      "Batch: 11329 Loss: 0.6573642492294312\n",
      "Batch: 11393 Loss: 0.3197501003742218\n",
      "Batch: 11457 Loss: 0.4045502543449402\n",
      "Batch: 11521 Loss: 0.39649760723114014\n",
      "Batch: 11585 Loss: 0.49366679787635803\n",
      "Batch: 11649 Loss: 0.3306010961532593\n",
      "Batch: 11713 Loss: 0.437984824180603\n",
      "Batch: 11777 Loss: 0.6167771816253662\n",
      "Batch: 11841 Loss: 0.5819985866546631\n",
      "Batch: 11905 Loss: 0.4659751057624817\n",
      "Batch: 11969 Loss: 0.44505786895751953\n",
      "Batch: 12033 Loss: 0.3807286322116852\n",
      "Batch: 12097 Loss: 0.9453117847442627\n",
      "Batch: 12161 Loss: 0.5220381021499634\n",
      "Batch: 12225 Loss: 0.3096475303173065\n",
      "Batch: 12289 Loss: 0.3270168900489807\n",
      "Batch: 12353 Loss: 0.4378328323364258\n",
      "Batch: 12417 Loss: 0.37374576926231384\n",
      "Batch: 12481 Loss: 0.4084700345993042\n",
      "Batch: 12545 Loss: 0.4877834916114807\n",
      "Batch: 12609 Loss: 0.5292890071868896\n",
      "Batch: 12673 Loss: 0.5510251522064209\n",
      "Batch: 12737 Loss: 0.45877745747566223\n",
      "Batch: 12801 Loss: 0.3902108073234558\n",
      "Batch: 12865 Loss: 0.3304668664932251\n",
      "Batch: 12929 Loss: 0.6699842810630798\n",
      "Epoch: 20\n",
      "Batch: 1 Loss: 0.4087403118610382\n",
      "Batch: 65 Loss: 0.4746119976043701\n",
      "Batch: 129 Loss: 0.41215625405311584\n",
      "Batch: 193 Loss: 0.6004675030708313\n",
      "Batch: 257 Loss: 0.4336235821247101\n",
      "Batch: 321 Loss: 0.41489872336387634\n",
      "Batch: 385 Loss: 0.41426336765289307\n",
      "Batch: 449 Loss: 0.3837229907512665\n",
      "Batch: 513 Loss: 0.3983941376209259\n",
      "Batch: 577 Loss: 0.39539268612861633\n",
      "Batch: 641 Loss: 0.4694538116455078\n",
      "Batch: 705 Loss: 0.4169345796108246\n",
      "Batch: 769 Loss: 0.46811443567276\n",
      "Batch: 833 Loss: 0.3459826707839966\n",
      "Batch: 897 Loss: 0.5727900862693787\n",
      "Batch: 961 Loss: 0.37056854367256165\n",
      "Batch: 1025 Loss: 0.41281595826148987\n",
      "Batch: 1089 Loss: 0.39571964740753174\n",
      "Batch: 1153 Loss: 0.4312131404876709\n",
      "Batch: 1217 Loss: 0.39098548889160156\n",
      "Batch: 1281 Loss: 0.41552919149398804\n",
      "Batch: 1345 Loss: 0.4269886016845703\n",
      "Batch: 1409 Loss: 0.3618835508823395\n",
      "Batch: 1473 Loss: 0.41724082827568054\n",
      "Batch: 1537 Loss: 0.39288216829299927\n",
      "Batch: 1601 Loss: 0.33604854345321655\n",
      "Batch: 1665 Loss: 0.3733975291252136\n",
      "Batch: 1729 Loss: 0.441176176071167\n",
      "Batch: 1793 Loss: 0.33809569478034973\n",
      "Batch: 1857 Loss: 0.39390140771865845\n",
      "Batch: 1921 Loss: 0.45302799344062805\n",
      "Batch: 1985 Loss: 0.3744158446788788\n",
      "Batch: 2049 Loss: 0.3484284579753876\n",
      "Batch: 2113 Loss: 0.38929373025894165\n",
      "Batch: 2177 Loss: 0.4325636625289917\n",
      "Batch: 2241 Loss: 0.4840110242366791\n",
      "Batch: 2305 Loss: 0.504671573638916\n",
      "Batch: 2369 Loss: 0.5175764560699463\n",
      "Batch: 2433 Loss: 0.439075231552124\n",
      "Batch: 2497 Loss: 0.4989611506462097\n",
      "Batch: 2561 Loss: 0.4286867082118988\n",
      "Batch: 2625 Loss: 0.4342920482158661\n",
      "Batch: 2689 Loss: 0.44561028480529785\n",
      "Batch: 2753 Loss: 0.37622132897377014\n",
      "Batch: 2817 Loss: 0.5549348592758179\n",
      "Batch: 2881 Loss: 0.4811382293701172\n",
      "Batch: 2945 Loss: 0.4175059497356415\n",
      "Batch: 3009 Loss: 0.5809364318847656\n",
      "Batch: 3073 Loss: 0.46246129274368286\n",
      "Batch: 3137 Loss: 0.4123106300830841\n",
      "Batch: 3201 Loss: 0.39031174778938293\n",
      "Batch: 3265 Loss: 0.3741006553173065\n",
      "Batch: 3329 Loss: 0.40175604820251465\n",
      "Batch: 3393 Loss: 0.4472575783729553\n",
      "Batch: 3457 Loss: 0.4140077531337738\n",
      "Batch: 3521 Loss: 0.31155863404273987\n",
      "Batch: 3585 Loss: 0.304784893989563\n",
      "Batch: 3649 Loss: 0.49917957186698914\n",
      "Batch: 3713 Loss: 0.41096562147140503\n",
      "Batch: 3777 Loss: 0.43655866384506226\n",
      "Batch: 3841 Loss: 0.4346674680709839\n",
      "Batch: 3905 Loss: 0.38806280493736267\n",
      "Batch: 3969 Loss: 0.5394629240036011\n",
      "Batch: 4033 Loss: 0.40402495861053467\n",
      "Batch: 4097 Loss: 0.39916858077049255\n",
      "Batch: 4161 Loss: 0.4656192362308502\n",
      "Batch: 4225 Loss: 0.34009426832199097\n",
      "Batch: 4289 Loss: 0.3615016043186188\n",
      "Batch: 4353 Loss: 0.4939551055431366\n",
      "Batch: 4417 Loss: 0.6547324657440186\n",
      "Batch: 4481 Loss: 0.7004665732383728\n",
      "Batch: 4545 Loss: 0.5629626512527466\n",
      "Batch: 4609 Loss: 0.3766171932220459\n",
      "Batch: 4673 Loss: 0.3558243215084076\n",
      "Batch: 4737 Loss: 0.45987358689308167\n",
      "Batch: 4801 Loss: 0.38111594319343567\n",
      "Batch: 4865 Loss: 0.38874176144599915\n",
      "Batch: 4929 Loss: 0.4301518499851227\n",
      "Batch: 4993 Loss: 0.5467481017112732\n",
      "Batch: 5057 Loss: 0.5297916531562805\n",
      "Batch: 5121 Loss: 0.41581204533576965\n",
      "Batch: 5185 Loss: 0.8739373087882996\n",
      "Batch: 5249 Loss: 0.3778112530708313\n",
      "Batch: 5313 Loss: 0.4507256746292114\n",
      "Batch: 5377 Loss: 0.43255916237831116\n",
      "Batch: 5441 Loss: 0.5336251854896545\n",
      "Batch: 5505 Loss: 0.4913596212863922\n",
      "Batch: 5569 Loss: 0.5257813334465027\n",
      "Batch: 5633 Loss: 0.3882662057876587\n",
      "Batch: 5697 Loss: 0.44372522830963135\n",
      "Batch: 5761 Loss: 0.5601904988288879\n",
      "Batch: 5825 Loss: 0.43576565384864807\n",
      "Batch: 5889 Loss: 0.3871048390865326\n",
      "Batch: 5953 Loss: 0.3864906132221222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 6017 Loss: 0.32779911160469055\n",
      "Batch: 6081 Loss: 0.32759717106819153\n",
      "Batch: 6145 Loss: 0.43402886390686035\n",
      "Batch: 6209 Loss: 0.37022724747657776\n",
      "Batch: 6273 Loss: 0.4683208763599396\n",
      "Batch: 6337 Loss: 0.34242698550224304\n",
      "Batch: 6401 Loss: 0.3399585783481598\n",
      "Batch: 6465 Loss: 0.38234391808509827\n",
      "Batch: 6529 Loss: 0.3626384735107422\n",
      "Batch: 6593 Loss: 0.40325525403022766\n",
      "Batch: 6657 Loss: 0.32591500878334045\n",
      "Batch: 6721 Loss: 0.45120149850845337\n",
      "Batch: 6785 Loss: 0.43960633873939514\n",
      "Batch: 6849 Loss: 0.43976137042045593\n",
      "Batch: 6913 Loss: 0.4040403366088867\n",
      "Batch: 6977 Loss: 0.4331592917442322\n",
      "Batch: 7041 Loss: 0.4238593280315399\n",
      "Batch: 7105 Loss: 0.3567642867565155\n",
      "Batch: 7169 Loss: 0.42072615027427673\n",
      "Batch: 7233 Loss: 0.37210267782211304\n",
      "Batch: 7297 Loss: 0.4274060130119324\n",
      "Batch: 7361 Loss: 0.3898456394672394\n",
      "Batch: 7425 Loss: 0.4772157371044159\n",
      "Batch: 7489 Loss: 0.5698267221450806\n",
      "Batch: 7553 Loss: 0.3713289499282837\n",
      "Batch: 7617 Loss: 0.3662729859352112\n",
      "Batch: 7681 Loss: 0.449222207069397\n",
      "Batch: 7745 Loss: 0.461504727602005\n",
      "Batch: 7809 Loss: 0.4223945438861847\n",
      "Batch: 7873 Loss: 0.35785987973213196\n",
      "Batch: 7937 Loss: 0.5663332939147949\n",
      "Batch: 8001 Loss: 0.42274975776672363\n",
      "Batch: 8065 Loss: 0.5665479898452759\n",
      "Batch: 8129 Loss: 0.423542857170105\n",
      "Batch: 8193 Loss: 0.4627682864665985\n",
      "Batch: 8257 Loss: 0.48313799500465393\n",
      "Batch: 8321 Loss: 0.6487274169921875\n",
      "Batch: 8385 Loss: 0.3261948823928833\n",
      "Batch: 8449 Loss: 0.3591229319572449\n",
      "Batch: 8513 Loss: 0.6378331780433655\n",
      "Batch: 8577 Loss: 0.3362416923046112\n",
      "Batch: 8641 Loss: 0.517549991607666\n",
      "Batch: 8705 Loss: 0.42699918150901794\n",
      "Batch: 8769 Loss: 0.48258280754089355\n",
      "Batch: 8833 Loss: 0.5272712707519531\n",
      "Batch: 8897 Loss: 0.8078870177268982\n",
      "Batch: 8961 Loss: 0.41013628244400024\n",
      "Batch: 9025 Loss: 0.40306079387664795\n",
      "Batch: 9089 Loss: 0.4125998616218567\n",
      "Batch: 9153 Loss: 0.4727676212787628\n",
      "Batch: 9217 Loss: 0.5093308091163635\n",
      "Batch: 9281 Loss: 0.4831591546535492\n",
      "Batch: 9345 Loss: 0.3904895782470703\n",
      "Batch: 9409 Loss: 0.528311550617218\n",
      "Batch: 9473 Loss: 0.5773395299911499\n",
      "Batch: 9537 Loss: 0.4996466338634491\n",
      "Batch: 9601 Loss: 0.3799649477005005\n",
      "Batch: 9665 Loss: 0.35317617654800415\n",
      "Batch: 9729 Loss: 0.45258966088294983\n",
      "Batch: 9793 Loss: 0.3885745406150818\n",
      "Batch: 9857 Loss: 0.432231068611145\n",
      "Batch: 9921 Loss: 0.4050725996494293\n",
      "Batch: 9985 Loss: 0.4603113830089569\n",
      "Batch: 10049 Loss: 0.5264301896095276\n",
      "Batch: 10113 Loss: 0.4204865097999573\n",
      "Batch: 10177 Loss: 0.4990484416484833\n",
      "Batch: 10241 Loss: 0.37676629424095154\n",
      "Batch: 10305 Loss: 0.4449443221092224\n",
      "Batch: 10369 Loss: 0.48476505279541016\n",
      "Batch: 10433 Loss: 0.40664371848106384\n",
      "Batch: 10497 Loss: 0.3961441218852997\n",
      "Batch: 10561 Loss: 0.3702869415283203\n",
      "Batch: 10625 Loss: 0.4362099766731262\n",
      "Batch: 10689 Loss: 0.43179774284362793\n",
      "Batch: 10753 Loss: 0.35844871401786804\n",
      "Batch: 10817 Loss: 0.31244438886642456\n",
      "Batch: 10881 Loss: 0.3681924343109131\n",
      "Batch: 10945 Loss: 0.37137946486473083\n",
      "Batch: 11009 Loss: 0.41731613874435425\n",
      "Batch: 11073 Loss: 0.46680790185928345\n",
      "Batch: 11137 Loss: 0.3791545629501343\n",
      "Batch: 11201 Loss: 0.3940355181694031\n",
      "Batch: 11265 Loss: 0.5345041751861572\n",
      "Batch: 11329 Loss: 0.6645490527153015\n",
      "Batch: 11393 Loss: 0.31214433908462524\n",
      "Batch: 11457 Loss: 0.381616473197937\n",
      "Batch: 11521 Loss: 0.39612284302711487\n",
      "Batch: 11585 Loss: 0.4998495578765869\n",
      "Batch: 11649 Loss: 0.3386574983596802\n",
      "Batch: 11713 Loss: 0.4376286566257477\n",
      "Batch: 11777 Loss: 0.6120962500572205\n",
      "Batch: 11841 Loss: 0.583794116973877\n",
      "Batch: 11905 Loss: 0.4631482660770416\n",
      "Batch: 11969 Loss: 0.4386933743953705\n",
      "Batch: 12033 Loss: 0.3763173818588257\n",
      "Batch: 12097 Loss: 0.9433512687683105\n",
      "Batch: 12161 Loss: 0.5225037336349487\n",
      "Batch: 12225 Loss: 0.308118999004364\n",
      "Batch: 12289 Loss: 0.3241017162799835\n",
      "Batch: 12353 Loss: 0.4354790449142456\n",
      "Batch: 12417 Loss: 0.3763284683227539\n",
      "Batch: 12481 Loss: 0.4077455401420593\n",
      "Batch: 12545 Loss: 0.4864877760410309\n",
      "Batch: 12609 Loss: 0.5269550085067749\n",
      "Batch: 12673 Loss: 0.5528367757797241\n",
      "Batch: 12737 Loss: 0.45463505387306213\n",
      "Batch: 12801 Loss: 0.3824203312397003\n",
      "Batch: 12865 Loss: 0.3261435031890869\n",
      "Batch: 12929 Loss: 0.6625623106956482\n",
      "Epoch: 21\n",
      "Batch: 1 Loss: 0.4063270390033722\n",
      "Batch: 65 Loss: 0.48094847798347473\n",
      "Batch: 129 Loss: 0.40205448865890503\n",
      "Batch: 193 Loss: 0.6008187532424927\n",
      "Batch: 257 Loss: 0.43388134241104126\n",
      "Batch: 321 Loss: 0.4117097556591034\n",
      "Batch: 385 Loss: 0.41368427872657776\n",
      "Batch: 449 Loss: 0.38090768456459045\n",
      "Batch: 513 Loss: 0.3973156809806824\n",
      "Batch: 577 Loss: 0.3928115665912628\n",
      "Batch: 641 Loss: 0.46659165620803833\n",
      "Batch: 705 Loss: 0.4142187833786011\n",
      "Batch: 769 Loss: 0.4660646915435791\n",
      "Batch: 833 Loss: 0.3456724286079407\n",
      "Batch: 897 Loss: 0.5715476274490356\n",
      "Batch: 961 Loss: 0.36896058917045593\n",
      "Batch: 1025 Loss: 0.40125221014022827\n",
      "Batch: 1089 Loss: 0.39370641112327576\n",
      "Batch: 1153 Loss: 0.42744722962379456\n",
      "Batch: 1217 Loss: 0.38888272643089294\n",
      "Batch: 1281 Loss: 0.4162420630455017\n",
      "Batch: 1345 Loss: 0.4244230091571808\n",
      "Batch: 1409 Loss: 0.3599669337272644\n",
      "Batch: 1473 Loss: 0.4116974472999573\n",
      "Batch: 1537 Loss: 0.391053169965744\n",
      "Batch: 1601 Loss: 0.34046435356140137\n",
      "Batch: 1665 Loss: 0.3713935315608978\n",
      "Batch: 1729 Loss: 0.43921348452568054\n",
      "Batch: 1793 Loss: 0.338337779045105\n",
      "Batch: 1857 Loss: 0.39474228024482727\n",
      "Batch: 1921 Loss: 0.45355668663978577\n",
      "Batch: 1985 Loss: 0.37258633971214294\n",
      "Batch: 2049 Loss: 0.3478837311267853\n",
      "Batch: 2113 Loss: 0.39422619342803955\n",
      "Batch: 2177 Loss: 0.4433586299419403\n",
      "Batch: 2241 Loss: 0.47158482670783997\n",
      "Batch: 2305 Loss: 0.4890299141407013\n",
      "Batch: 2369 Loss: 0.4955896735191345\n",
      "Batch: 2433 Loss: 0.43827375769615173\n",
      "Batch: 2497 Loss: 0.4973573088645935\n",
      "Batch: 2561 Loss: 0.42774927616119385\n",
      "Batch: 2625 Loss: 0.43295764923095703\n",
      "Batch: 2689 Loss: 0.44359415769577026\n",
      "Batch: 2753 Loss: 0.3766571879386902\n",
      "Batch: 2817 Loss: 0.550504207611084\n",
      "Batch: 2881 Loss: 0.47751420736312866\n",
      "Batch: 2945 Loss: 0.40985992550849915\n",
      "Batch: 3009 Loss: 0.5740606188774109\n",
      "Batch: 3073 Loss: 0.4543743133544922\n",
      "Batch: 3137 Loss: 0.4154247045516968\n",
      "Batch: 3201 Loss: 0.3892293870449066\n",
      "Batch: 3265 Loss: 0.3732141852378845\n",
      "Batch: 3329 Loss: 0.40241771936416626\n",
      "Batch: 3393 Loss: 0.4467852711677551\n",
      "Batch: 3457 Loss: 0.4115978479385376\n",
      "Batch: 3521 Loss: 0.3112167716026306\n",
      "Batch: 3585 Loss: 0.3061346709728241\n",
      "Batch: 3649 Loss: 0.5019469261169434\n",
      "Batch: 3713 Loss: 0.41250497102737427\n",
      "Batch: 3777 Loss: 0.4321555495262146\n",
      "Batch: 3841 Loss: 0.4315987825393677\n",
      "Batch: 3905 Loss: 0.3911186158657074\n",
      "Batch: 3969 Loss: 0.5427996516227722\n",
      "Batch: 4033 Loss: 0.4084693491458893\n",
      "Batch: 4097 Loss: 0.4019264578819275\n",
      "Batch: 4161 Loss: 0.46857750415802\n",
      "Batch: 4225 Loss: 0.33990478515625\n",
      "Batch: 4289 Loss: 0.3617139160633087\n",
      "Batch: 4353 Loss: 0.5003807544708252\n",
      "Batch: 4417 Loss: 0.6557376384735107\n",
      "Batch: 4481 Loss: 0.6951404809951782\n",
      "Batch: 4545 Loss: 0.5603095293045044\n",
      "Batch: 4609 Loss: 0.3739035725593567\n",
      "Batch: 4673 Loss: 0.3545505404472351\n",
      "Batch: 4737 Loss: 0.45876607298851013\n",
      "Batch: 4801 Loss: 0.37957310676574707\n",
      "Batch: 4865 Loss: 0.3832263648509979\n",
      "Batch: 4929 Loss: 0.4244583547115326\n",
      "Batch: 4993 Loss: 0.5462549328804016\n",
      "Batch: 5057 Loss: 0.5259308218955994\n",
      "Batch: 5121 Loss: 0.4115312099456787\n",
      "Batch: 5185 Loss: 0.8681228756904602\n",
      "Batch: 5249 Loss: 0.3753614127635956\n",
      "Batch: 5313 Loss: 0.4445480704307556\n",
      "Batch: 5377 Loss: 0.4256109297275543\n",
      "Batch: 5441 Loss: 0.5310667157173157\n",
      "Batch: 5505 Loss: 0.49212324619293213\n",
      "Batch: 5569 Loss: 0.5237982273101807\n",
      "Batch: 5633 Loss: 0.3894791305065155\n",
      "Batch: 5697 Loss: 0.4513954520225525\n",
      "Batch: 5761 Loss: 0.5632941722869873\n",
      "Batch: 5825 Loss: 0.4381207227706909\n",
      "Batch: 5889 Loss: 0.38693884015083313\n",
      "Batch: 5953 Loss: 0.3853118121623993\n",
      "Batch: 6017 Loss: 0.3275255858898163\n",
      "Batch: 6081 Loss: 0.3229714035987854\n",
      "Batch: 6145 Loss: 0.43447235226631165\n",
      "Batch: 6209 Loss: 0.3727070093154907\n",
      "Batch: 6273 Loss: 0.4659295380115509\n",
      "Batch: 6337 Loss: 0.3390637934207916\n",
      "Batch: 6401 Loss: 0.341198205947876\n",
      "Batch: 6465 Loss: 0.38049226999282837\n",
      "Batch: 6529 Loss: 0.3613848090171814\n",
      "Batch: 6593 Loss: 0.39585641026496887\n",
      "Batch: 6657 Loss: 0.3264959454536438\n",
      "Batch: 6721 Loss: 0.4608241617679596\n",
      "Batch: 6785 Loss: 0.43677374720573425\n",
      "Batch: 6849 Loss: 0.4368358850479126\n",
      "Batch: 6913 Loss: 0.3998251259326935\n",
      "Batch: 6977 Loss: 0.4330686032772064\n",
      "Batch: 7041 Loss: 0.4229694902896881\n",
      "Batch: 7105 Loss: 0.35889214277267456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 7169 Loss: 0.4237191379070282\n",
      "Batch: 7233 Loss: 0.3613487184047699\n",
      "Batch: 7297 Loss: 0.4189102351665497\n",
      "Batch: 7361 Loss: 0.38908860087394714\n",
      "Batch: 7425 Loss: 0.4784492552280426\n",
      "Batch: 7489 Loss: 0.5681210160255432\n",
      "Batch: 7553 Loss: 0.3702299892902374\n",
      "Batch: 7617 Loss: 0.36715471744537354\n",
      "Batch: 7681 Loss: 0.448676198720932\n",
      "Batch: 7745 Loss: 0.4597553610801697\n",
      "Batch: 7809 Loss: 0.4232950508594513\n",
      "Batch: 7873 Loss: 0.35386309027671814\n",
      "Batch: 7937 Loss: 0.5619473457336426\n",
      "Batch: 8001 Loss: 0.42678409814834595\n",
      "Batch: 8065 Loss: 0.5689651370048523\n",
      "Batch: 8129 Loss: 0.4249456822872162\n",
      "Batch: 8193 Loss: 0.46670398116111755\n",
      "Batch: 8257 Loss: 0.4864232540130615\n",
      "Batch: 8321 Loss: 0.6443723440170288\n",
      "Batch: 8385 Loss: 0.3193338215351105\n",
      "Batch: 8449 Loss: 0.3518041670322418\n",
      "Batch: 8513 Loss: 0.6362636685371399\n",
      "Batch: 8577 Loss: 0.3349073529243469\n",
      "Batch: 8641 Loss: 0.5217794179916382\n",
      "Batch: 8705 Loss: 0.4260854125022888\n",
      "Batch: 8769 Loss: 0.48212334513664246\n",
      "Batch: 8833 Loss: 0.5275607705116272\n",
      "Batch: 8897 Loss: 0.8077086210250854\n",
      "Batch: 8961 Loss: 0.3990975618362427\n",
      "Batch: 9025 Loss: 0.39295694231987\n",
      "Batch: 9089 Loss: 0.4041685461997986\n",
      "Batch: 9153 Loss: 0.4729655385017395\n",
      "Batch: 9217 Loss: 0.512284517288208\n",
      "Batch: 9281 Loss: 0.483836829662323\n",
      "Batch: 9345 Loss: 0.41837170720100403\n",
      "Batch: 9409 Loss: 0.5441559553146362\n",
      "Batch: 9473 Loss: 0.5789832472801208\n",
      "Batch: 9537 Loss: 0.48675692081451416\n",
      "Batch: 9601 Loss: 0.3726811707019806\n",
      "Batch: 9665 Loss: 0.3427296280860901\n",
      "Batch: 9729 Loss: 0.44543707370758057\n",
      "Batch: 9793 Loss: 0.3852698802947998\n",
      "Batch: 9857 Loss: 0.43111544847488403\n",
      "Batch: 9921 Loss: 0.4043538570404053\n",
      "Batch: 9985 Loss: 0.4597972631454468\n",
      "Batch: 10049 Loss: 0.5246005058288574\n",
      "Batch: 10113 Loss: 0.42097240686416626\n",
      "Batch: 10177 Loss: 0.4893692433834076\n",
      "Batch: 10241 Loss: 0.3782876431941986\n",
      "Batch: 10305 Loss: 0.44400307536125183\n",
      "Batch: 10369 Loss: 0.4854791760444641\n",
      "Batch: 10433 Loss: 0.4030100703239441\n",
      "Batch: 10497 Loss: 0.3968799114227295\n",
      "Batch: 10561 Loss: 0.3692634403705597\n",
      "Batch: 10625 Loss: 0.4369342029094696\n",
      "Batch: 10689 Loss: 0.429334431886673\n",
      "Batch: 10753 Loss: 0.3569623529911041\n",
      "Batch: 10817 Loss: 0.3124695420265198\n",
      "Batch: 10881 Loss: 0.36704087257385254\n",
      "Batch: 10945 Loss: 0.35849833488464355\n",
      "Batch: 11009 Loss: 0.39555615186691284\n",
      "Batch: 11073 Loss: 0.4620569348335266\n",
      "Batch: 11137 Loss: 0.3794701397418976\n",
      "Batch: 11201 Loss: 0.40350252389907837\n",
      "Batch: 11265 Loss: 0.5335107445716858\n",
      "Batch: 11329 Loss: 0.650147020816803\n",
      "Batch: 11393 Loss: 0.3087974786758423\n",
      "Batch: 11457 Loss: 0.3781154751777649\n",
      "Batch: 11521 Loss: 0.3915838897228241\n",
      "Batch: 11585 Loss: 0.4914206266403198\n",
      "Batch: 11649 Loss: 0.32831528782844543\n",
      "Batch: 11713 Loss: 0.4375564754009247\n",
      "Batch: 11777 Loss: 0.6178311705589294\n",
      "Batch: 11841 Loss: 0.5792670845985413\n",
      "Batch: 11905 Loss: 0.46170905232429504\n",
      "Batch: 11969 Loss: 0.4404750466346741\n",
      "Batch: 12033 Loss: 0.3767842948436737\n",
      "Batch: 12097 Loss: 0.947133481502533\n",
      "Batch: 12161 Loss: 0.5240224599838257\n",
      "Batch: 12225 Loss: 0.29919397830963135\n",
      "Batch: 12289 Loss: 0.3180246949195862\n",
      "Batch: 12353 Loss: 0.4302091896533966\n",
      "Batch: 12417 Loss: 0.3681318163871765\n",
      "Batch: 12481 Loss: 0.4016280770301819\n",
      "Batch: 12545 Loss: 0.4831254184246063\n",
      "Batch: 12609 Loss: 0.5239534974098206\n",
      "Batch: 12673 Loss: 0.5471325516700745\n",
      "Batch: 12737 Loss: 0.45325881242752075\n",
      "Batch: 12801 Loss: 0.384333997964859\n",
      "Batch: 12865 Loss: 0.32636019587516785\n",
      "Batch: 12929 Loss: 0.6700858473777771\n",
      "Epoch: 22\n",
      "Batch: 1 Loss: 0.4049181640148163\n",
      "Batch: 65 Loss: 0.4671429991722107\n",
      "Batch: 129 Loss: 0.39833858609199524\n",
      "Batch: 193 Loss: 0.594207763671875\n",
      "Batch: 257 Loss: 0.42857861518859863\n",
      "Batch: 321 Loss: 0.4137725830078125\n",
      "Batch: 385 Loss: 0.41472727060317993\n",
      "Batch: 449 Loss: 0.3819500803947449\n",
      "Batch: 513 Loss: 0.39664217829704285\n",
      "Batch: 577 Loss: 0.39414405822753906\n",
      "Batch: 641 Loss: 0.4669148027896881\n",
      "Batch: 705 Loss: 0.41468676924705505\n",
      "Batch: 769 Loss: 0.4641348421573639\n",
      "Batch: 833 Loss: 0.3452710807323456\n",
      "Batch: 897 Loss: 0.5726921558380127\n",
      "Batch: 961 Loss: 0.3684166371822357\n",
      "Batch: 1025 Loss: 0.3998467028141022\n",
      "Batch: 1089 Loss: 0.39439693093299866\n",
      "Batch: 1153 Loss: 0.4267314672470093\n",
      "Batch: 1217 Loss: 0.3836083710193634\n",
      "Batch: 1281 Loss: 0.41499951481819153\n",
      "Batch: 1345 Loss: 0.42683956027030945\n",
      "Batch: 1409 Loss: 0.36002832651138306\n",
      "Batch: 1473 Loss: 0.4112512469291687\n",
      "Batch: 1537 Loss: 0.39361289143562317\n",
      "Batch: 1601 Loss: 0.3353932797908783\n",
      "Batch: 1665 Loss: 0.37004023790359497\n",
      "Batch: 1729 Loss: 0.4351184368133545\n",
      "Batch: 1793 Loss: 0.3366002142429352\n",
      "Batch: 1857 Loss: 0.3914831876754761\n",
      "Batch: 1921 Loss: 0.4438077211380005\n",
      "Batch: 1985 Loss: 0.3699807822704315\n",
      "Batch: 2049 Loss: 0.345879465341568\n",
      "Batch: 2113 Loss: 0.3893446624279022\n",
      "Batch: 2177 Loss: 0.4242839217185974\n",
      "Batch: 2241 Loss: 0.47726285457611084\n",
      "Batch: 2305 Loss: 0.48809006810188293\n",
      "Batch: 2369 Loss: 0.49384328722953796\n",
      "Batch: 2433 Loss: 0.4389283359050751\n",
      "Batch: 2497 Loss: 0.5000303387641907\n",
      "Batch: 2561 Loss: 0.42642471194267273\n",
      "Batch: 2625 Loss: 0.42665648460388184\n",
      "Batch: 2689 Loss: 0.4428708255290985\n",
      "Batch: 2753 Loss: 0.37483617663383484\n",
      "Batch: 2817 Loss: 0.5425498485565186\n",
      "Batch: 2881 Loss: 0.47372812032699585\n",
      "Batch: 2945 Loss: 0.40865978598594666\n",
      "Batch: 3009 Loss: 0.5671496391296387\n",
      "Batch: 3073 Loss: 0.4501217305660248\n",
      "Batch: 3137 Loss: 0.4129718244075775\n",
      "Batch: 3201 Loss: 0.3856538236141205\n",
      "Batch: 3265 Loss: 0.37224701046943665\n",
      "Batch: 3329 Loss: 0.4024658799171448\n",
      "Batch: 3393 Loss: 0.4434989392757416\n",
      "Batch: 3457 Loss: 0.41437438130378723\n",
      "Batch: 3521 Loss: 0.3109653890132904\n",
      "Batch: 3585 Loss: 0.3060193955898285\n",
      "Batch: 3649 Loss: 0.4910542666912079\n",
      "Batch: 3713 Loss: 0.4072515070438385\n",
      "Batch: 3777 Loss: 0.4326171875\n",
      "Batch: 3841 Loss: 0.42899778485298157\n",
      "Batch: 3905 Loss: 0.3861754238605499\n",
      "Batch: 3969 Loss: 0.5403591394424438\n",
      "Batch: 4033 Loss: 0.40382230281829834\n",
      "Batch: 4097 Loss: 0.3960217535495758\n",
      "Batch: 4161 Loss: 0.4606642425060272\n",
      "Batch: 4225 Loss: 0.33624204993247986\n",
      "Batch: 4289 Loss: 0.36197131872177124\n",
      "Batch: 4353 Loss: 0.49465298652648926\n",
      "Batch: 4417 Loss: 0.6376469731330872\n",
      "Batch: 4481 Loss: 0.68525630235672\n",
      "Batch: 4545 Loss: 0.5585643649101257\n",
      "Batch: 4609 Loss: 0.3738500475883484\n",
      "Batch: 4673 Loss: 0.3536003828048706\n",
      "Batch: 4737 Loss: 0.4570559561252594\n",
      "Batch: 4801 Loss: 0.37786778807640076\n",
      "Batch: 4865 Loss: 0.38436126708984375\n",
      "Batch: 4929 Loss: 0.428996741771698\n",
      "Batch: 4993 Loss: 0.5394834876060486\n",
      "Batch: 5057 Loss: 0.5245263576507568\n",
      "Batch: 5121 Loss: 0.4118715226650238\n",
      "Batch: 5185 Loss: 0.8645347356796265\n",
      "Batch: 5249 Loss: 0.3781585097312927\n",
      "Batch: 5313 Loss: 0.44111868739128113\n",
      "Batch: 5377 Loss: 0.42404085397720337\n",
      "Batch: 5441 Loss: 0.5339511632919312\n",
      "Batch: 5505 Loss: 0.486731618642807\n",
      "Batch: 5569 Loss: 0.5252066254615784\n",
      "Batch: 5633 Loss: 0.3879469037055969\n",
      "Batch: 5697 Loss: 0.4394698441028595\n",
      "Batch: 5761 Loss: 0.5558314323425293\n",
      "Batch: 5825 Loss: 0.4320705831050873\n",
      "Batch: 5889 Loss: 0.3847436010837555\n",
      "Batch: 5953 Loss: 0.38679102063179016\n",
      "Batch: 6017 Loss: 0.32459309697151184\n",
      "Batch: 6081 Loss: 0.3263791501522064\n",
      "Batch: 6145 Loss: 0.4302510917186737\n",
      "Batch: 6209 Loss: 0.3657132387161255\n",
      "Batch: 6273 Loss: 0.46692872047424316\n",
      "Batch: 6337 Loss: 0.33990535140037537\n",
      "Batch: 6401 Loss: 0.3365408480167389\n",
      "Batch: 6465 Loss: 0.3785618841648102\n",
      "Batch: 6529 Loss: 0.36080119013786316\n",
      "Batch: 6593 Loss: 0.4002869427204132\n",
      "Batch: 6657 Loss: 0.32667258381843567\n",
      "Batch: 6721 Loss: 0.46124744415283203\n",
      "Batch: 6785 Loss: 0.4388142228126526\n",
      "Batch: 6849 Loss: 0.43558046221733093\n",
      "Batch: 6913 Loss: 0.4008113145828247\n",
      "Batch: 6977 Loss: 0.43124979734420776\n",
      "Batch: 7041 Loss: 0.4210728406906128\n",
      "Batch: 7105 Loss: 0.35715287923812866\n",
      "Batch: 7169 Loss: 0.4162026047706604\n",
      "Batch: 7233 Loss: 0.36269164085388184\n",
      "Batch: 7297 Loss: 0.4171409606933594\n",
      "Batch: 7361 Loss: 0.39073893427848816\n",
      "Batch: 7425 Loss: 0.47656336426734924\n",
      "Batch: 7489 Loss: 0.5668138265609741\n",
      "Batch: 7553 Loss: 0.3686426877975464\n",
      "Batch: 7617 Loss: 0.36475104093551636\n",
      "Batch: 7681 Loss: 0.44383910298347473\n",
      "Batch: 7745 Loss: 0.457009494304657\n",
      "Batch: 7809 Loss: 0.42298951745033264\n",
      "Batch: 7873 Loss: 0.3609634041786194\n",
      "Batch: 7937 Loss: 0.5677513480186462\n",
      "Batch: 8001 Loss: 0.4220520257949829\n",
      "Batch: 8065 Loss: 0.5617934465408325\n",
      "Batch: 8129 Loss: 0.41940343379974365\n",
      "Batch: 8193 Loss: 0.46545249223709106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 8257 Loss: 0.4847620725631714\n",
      "Batch: 8321 Loss: 0.6423313021659851\n",
      "Batch: 8385 Loss: 0.3150349259376526\n",
      "Batch: 8449 Loss: 0.35055413842201233\n",
      "Batch: 8513 Loss: 0.6361332535743713\n",
      "Batch: 8577 Loss: 0.334458589553833\n",
      "Batch: 8641 Loss: 0.51080721616745\n",
      "Batch: 8705 Loss: 0.41616353392601013\n",
      "Batch: 8769 Loss: 0.4788452982902527\n",
      "Batch: 8833 Loss: 0.5323144793510437\n",
      "Batch: 8897 Loss: 0.8065770864486694\n",
      "Batch: 8961 Loss: 0.3958531320095062\n",
      "Batch: 9025 Loss: 0.3904282748699188\n",
      "Batch: 9089 Loss: 0.40100914239883423\n",
      "Batch: 9153 Loss: 0.47235482931137085\n",
      "Batch: 9217 Loss: 0.5119753479957581\n",
      "Batch: 9281 Loss: 0.47398674488067627\n",
      "Batch: 9345 Loss: 0.38508522510528564\n",
      "Batch: 9409 Loss: 0.5184704661369324\n",
      "Batch: 9473 Loss: 0.5704006552696228\n",
      "Batch: 9537 Loss: 0.48310649394989014\n",
      "Batch: 9601 Loss: 0.37510091066360474\n",
      "Batch: 9665 Loss: 0.3600061535835266\n",
      "Batch: 9729 Loss: 0.4610338509082794\n",
      "Batch: 9793 Loss: 0.38947412371635437\n",
      "Batch: 9857 Loss: 0.4302731454372406\n",
      "Batch: 9921 Loss: 0.4005964696407318\n",
      "Batch: 9985 Loss: 0.45512863993644714\n",
      "Batch: 10049 Loss: 0.525357186794281\n",
      "Batch: 10113 Loss: 0.41079404950141907\n",
      "Batch: 10177 Loss: 0.4920402765274048\n",
      "Batch: 10241 Loss: 0.36888453364372253\n",
      "Batch: 10305 Loss: 0.4427843987941742\n",
      "Batch: 10369 Loss: 0.4830065071582794\n",
      "Batch: 10433 Loss: 0.4005467891693115\n",
      "Batch: 10497 Loss: 0.3948681652545929\n",
      "Batch: 10561 Loss: 0.36886066198349\n",
      "Batch: 10625 Loss: 0.43324875831604004\n",
      "Batch: 10689 Loss: 0.43086421489715576\n",
      "Batch: 10753 Loss: 0.35646528005599976\n",
      "Batch: 10817 Loss: 0.3108360767364502\n",
      "Batch: 10881 Loss: 0.3673698902130127\n",
      "Batch: 10945 Loss: 0.3536105751991272\n",
      "Batch: 11009 Loss: 0.3947731554508209\n",
      "Batch: 11073 Loss: 0.4635476768016815\n",
      "Batch: 11137 Loss: 0.37886619567871094\n",
      "Batch: 11201 Loss: 0.3859560191631317\n",
      "Batch: 11265 Loss: 0.5307862758636475\n",
      "Batch: 11329 Loss: 0.6518693566322327\n",
      "Batch: 11393 Loss: 0.3044517934322357\n",
      "Batch: 11457 Loss: 0.37787479162216187\n",
      "Batch: 11521 Loss: 0.39168304204940796\n",
      "Batch: 11585 Loss: 0.49649059772491455\n",
      "Batch: 11649 Loss: 0.3259463608264923\n",
      "Batch: 11713 Loss: 0.43271422386169434\n",
      "Batch: 11777 Loss: 0.6129018664360046\n",
      "Batch: 11841 Loss: 0.5747256875038147\n",
      "Batch: 11905 Loss: 0.4581757187843323\n",
      "Batch: 11969 Loss: 0.4323403835296631\n",
      "Batch: 12033 Loss: 0.37495681643486023\n",
      "Batch: 12097 Loss: 0.9439350366592407\n",
      "Batch: 12161 Loss: 0.5134097337722778\n",
      "Batch: 12225 Loss: 0.3003721535205841\n",
      "Batch: 12289 Loss: 0.3275657594203949\n",
      "Batch: 12353 Loss: 0.44437724351882935\n",
      "Batch: 12417 Loss: 0.38297656178474426\n",
      "Batch: 12481 Loss: 0.40546607971191406\n",
      "Batch: 12545 Loss: 0.4815356433391571\n",
      "Batch: 12609 Loss: 0.5232688188552856\n",
      "Batch: 12673 Loss: 0.5473847985267639\n",
      "Batch: 12737 Loss: 0.4540626108646393\n",
      "Batch: 12801 Loss: 0.38278135657310486\n",
      "Batch: 12865 Loss: 0.3242364525794983\n",
      "Batch: 12929 Loss: 0.66356360912323\n",
      "Epoch: 23\n",
      "Batch: 1 Loss: 0.40584391355514526\n",
      "Batch: 65 Loss: 0.4666345715522766\n",
      "Batch: 129 Loss: 0.3990271985530853\n",
      "Batch: 193 Loss: 0.597267746925354\n",
      "Batch: 257 Loss: 0.42762282490730286\n",
      "Batch: 321 Loss: 0.4088902771472931\n",
      "Batch: 385 Loss: 0.41296419501304626\n",
      "Batch: 449 Loss: 0.3789168894290924\n",
      "Batch: 513 Loss: 0.3959047198295593\n",
      "Batch: 577 Loss: 0.39386942982673645\n",
      "Batch: 641 Loss: 0.4664522111415863\n",
      "Batch: 705 Loss: 0.4139758050441742\n",
      "Batch: 769 Loss: 0.46392807364463806\n",
      "Batch: 833 Loss: 0.3429274260997772\n",
      "Batch: 897 Loss: 0.5698207020759583\n",
      "Batch: 961 Loss: 0.3659328818321228\n",
      "Batch: 1025 Loss: 0.3989241123199463\n",
      "Batch: 1089 Loss: 0.3971193730831146\n",
      "Batch: 1153 Loss: 0.42998746037483215\n",
      "Batch: 1217 Loss: 0.38507387042045593\n",
      "Batch: 1281 Loss: 0.41448014974594116\n",
      "Batch: 1345 Loss: 0.4231323003768921\n",
      "Batch: 1409 Loss: 0.3586362302303314\n",
      "Batch: 1473 Loss: 0.4068145155906677\n",
      "Batch: 1537 Loss: 0.39770108461380005\n",
      "Batch: 1601 Loss: 0.330133318901062\n",
      "Batch: 1665 Loss: 0.3698960840702057\n",
      "Batch: 1729 Loss: 0.43551427125930786\n",
      "Batch: 1793 Loss: 0.3346222937107086\n",
      "Batch: 1857 Loss: 0.3932808041572571\n",
      "Batch: 1921 Loss: 0.4452747106552124\n",
      "Batch: 1985 Loss: 0.3644198179244995\n",
      "Batch: 2049 Loss: 0.34631526470184326\n",
      "Batch: 2113 Loss: 0.3911535143852234\n",
      "Batch: 2177 Loss: 0.4216344356536865\n",
      "Batch: 2241 Loss: 0.470270574092865\n",
      "Batch: 2305 Loss: 0.48220762610435486\n",
      "Batch: 2369 Loss: 0.492136687040329\n",
      "Batch: 2433 Loss: 0.4364292621612549\n",
      "Batch: 2497 Loss: 0.49209028482437134\n",
      "Batch: 2561 Loss: 0.422550767660141\n",
      "Batch: 2625 Loss: 0.42945289611816406\n",
      "Batch: 2689 Loss: 0.4416482448577881\n",
      "Batch: 2753 Loss: 0.3755964934825897\n",
      "Batch: 2817 Loss: 0.5432081818580627\n",
      "Batch: 2881 Loss: 0.4747713804244995\n",
      "Batch: 2945 Loss: 0.4060888886451721\n",
      "Batch: 3009 Loss: 0.5687050223350525\n",
      "Batch: 3073 Loss: 0.4496721923351288\n",
      "Batch: 3137 Loss: 0.4065113067626953\n",
      "Batch: 3201 Loss: 0.38318932056427\n",
      "Batch: 3265 Loss: 0.37077680230140686\n",
      "Batch: 3329 Loss: 0.3995899558067322\n",
      "Batch: 3393 Loss: 0.4413870573043823\n",
      "Batch: 3457 Loss: 0.4141197204589844\n",
      "Batch: 3521 Loss: 0.31234997510910034\n",
      "Batch: 3585 Loss: 0.3062039613723755\n",
      "Batch: 3649 Loss: 0.4881525933742523\n",
      "Batch: 3713 Loss: 0.4051697254180908\n",
      "Batch: 3777 Loss: 0.4310366213321686\n",
      "Batch: 3841 Loss: 0.4314863085746765\n",
      "Batch: 3905 Loss: 0.3852100670337677\n",
      "Batch: 3969 Loss: 0.5351391434669495\n",
      "Batch: 4033 Loss: 0.4052898585796356\n",
      "Batch: 4097 Loss: 0.3958125710487366\n",
      "Batch: 4161 Loss: 0.4595400393009186\n",
      "Batch: 4225 Loss: 0.33634132146835327\n",
      "Batch: 4289 Loss: 0.36084404587745667\n",
      "Batch: 4353 Loss: 0.49312660098075867\n",
      "Batch: 4417 Loss: 0.6373159885406494\n",
      "Batch: 4481 Loss: 0.6827278137207031\n",
      "Batch: 4545 Loss: 0.5556180477142334\n",
      "Batch: 4609 Loss: 0.3730612099170685\n",
      "Batch: 4673 Loss: 0.35282978415489197\n",
      "Batch: 4737 Loss: 0.45690757036209106\n",
      "Batch: 4801 Loss: 0.37794530391693115\n",
      "Batch: 4865 Loss: 0.3807899057865143\n",
      "Batch: 4929 Loss: 0.4218170940876007\n",
      "Batch: 4993 Loss: 0.5395734310150146\n",
      "Batch: 5057 Loss: 0.515888512134552\n",
      "Batch: 5121 Loss: 0.40241682529449463\n",
      "Batch: 5185 Loss: 0.8623502254486084\n",
      "Batch: 5249 Loss: 0.373006671667099\n",
      "Batch: 5313 Loss: 0.4408959448337555\n",
      "Batch: 5377 Loss: 0.42473989725112915\n",
      "Batch: 5441 Loss: 0.5304322838783264\n",
      "Batch: 5505 Loss: 0.48417332768440247\n",
      "Batch: 5569 Loss: 0.5246325135231018\n",
      "Batch: 5633 Loss: 0.39082109928131104\n",
      "Batch: 5697 Loss: 0.4540323317050934\n",
      "Batch: 5761 Loss: 0.5605273246765137\n",
      "Batch: 5825 Loss: 0.4285496771335602\n",
      "Batch: 5889 Loss: 0.38979530334472656\n",
      "Batch: 5953 Loss: 0.3861677348613739\n",
      "Batch: 6017 Loss: 0.32367533445358276\n",
      "Batch: 6081 Loss: 0.32272860407829285\n",
      "Batch: 6145 Loss: 0.43192344903945923\n",
      "Batch: 6209 Loss: 0.36355024576187134\n",
      "Batch: 6273 Loss: 0.46594688296318054\n",
      "Batch: 6337 Loss: 0.33822759985923767\n",
      "Batch: 6401 Loss: 0.3355529010295868\n",
      "Batch: 6465 Loss: 0.3792099356651306\n",
      "Batch: 6529 Loss: 0.3596394956111908\n",
      "Batch: 6593 Loss: 0.400287926197052\n",
      "Batch: 6657 Loss: 0.32458001375198364\n",
      "Batch: 6721 Loss: 0.4497119188308716\n",
      "Batch: 6785 Loss: 0.4571991264820099\n",
      "Batch: 6849 Loss: 0.43105265498161316\n",
      "Batch: 6913 Loss: 0.3982708156108856\n",
      "Batch: 6977 Loss: 0.42987194657325745\n",
      "Batch: 7041 Loss: 0.42028701305389404\n",
      "Batch: 7105 Loss: 0.35505256056785583\n",
      "Batch: 7169 Loss: 0.41344520449638367\n",
      "Batch: 7233 Loss: 0.3631311058998108\n",
      "Batch: 7297 Loss: 0.416694313287735\n",
      "Batch: 7361 Loss: 0.38796675205230713\n",
      "Batch: 7425 Loss: 0.4765896201133728\n",
      "Batch: 7489 Loss: 0.5655229091644287\n",
      "Batch: 7553 Loss: 0.36807548999786377\n",
      "Batch: 7617 Loss: 0.36527368426322937\n",
      "Batch: 7681 Loss: 0.4449683725833893\n",
      "Batch: 7745 Loss: 0.45782992243766785\n",
      "Batch: 7809 Loss: 0.42162761092185974\n",
      "Batch: 7873 Loss: 0.35593727231025696\n",
      "Batch: 7937 Loss: 0.5631262063980103\n",
      "Batch: 8001 Loss: 0.41906067728996277\n",
      "Batch: 8065 Loss: 0.5594785213470459\n",
      "Batch: 8129 Loss: 0.4174577593803406\n",
      "Batch: 8193 Loss: 0.4589167535305023\n",
      "Batch: 8257 Loss: 0.4870021343231201\n",
      "Batch: 8321 Loss: 0.639787495136261\n",
      "Batch: 8385 Loss: 0.3153550326824188\n",
      "Batch: 8449 Loss: 0.34982115030288696\n",
      "Batch: 8513 Loss: 0.6353774666786194\n",
      "Batch: 8577 Loss: 0.33306533098220825\n",
      "Batch: 8641 Loss: 0.5083783268928528\n",
      "Batch: 8705 Loss: 0.41566261649131775\n",
      "Batch: 8769 Loss: 0.4779665470123291\n",
      "Batch: 8833 Loss: 0.5353238582611084\n",
      "Batch: 8897 Loss: 0.8057595491409302\n",
      "Batch: 8961 Loss: 0.3969959020614624\n",
      "Batch: 9025 Loss: 0.38999420404434204\n",
      "Batch: 9089 Loss: 0.402040034532547\n",
      "Batch: 9153 Loss: 0.47222599387168884\n",
      "Batch: 9217 Loss: 0.5078173279762268\n",
      "Batch: 9281 Loss: 0.47231581807136536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 9345 Loss: 0.37976697087287903\n",
      "Batch: 9409 Loss: 0.5124317407608032\n",
      "Batch: 9473 Loss: 0.5692980289459229\n",
      "Batch: 9537 Loss: 0.4994431734085083\n",
      "Batch: 9601 Loss: 0.3719158172607422\n",
      "Batch: 9665 Loss: 0.35749638080596924\n",
      "Batch: 9729 Loss: 0.45298686623573303\n",
      "Batch: 9793 Loss: 0.3842572271823883\n",
      "Batch: 9857 Loss: 0.42869532108306885\n",
      "Batch: 9921 Loss: 0.3998258411884308\n",
      "Batch: 9985 Loss: 0.45104679465293884\n",
      "Batch: 10049 Loss: 0.5186878442764282\n",
      "Batch: 10113 Loss: 0.4102019667625427\n",
      "Batch: 10177 Loss: 0.48776939511299133\n",
      "Batch: 10241 Loss: 0.36838051676750183\n",
      "Batch: 10305 Loss: 0.441385954618454\n",
      "Batch: 10369 Loss: 0.48272740840911865\n",
      "Batch: 10433 Loss: 0.40113237500190735\n",
      "Batch: 10497 Loss: 0.3941689133644104\n",
      "Batch: 10561 Loss: 0.3687407672405243\n",
      "Batch: 10625 Loss: 0.4330076575279236\n",
      "Batch: 10689 Loss: 0.42809775471687317\n",
      "Batch: 10753 Loss: 0.3547617793083191\n",
      "Batch: 10817 Loss: 0.31080442667007446\n",
      "Batch: 10881 Loss: 0.36507096886634827\n",
      "Batch: 10945 Loss: 0.3523734211921692\n",
      "Batch: 11009 Loss: 0.3912166953086853\n",
      "Batch: 11073 Loss: 0.4532248079776764\n",
      "Batch: 11137 Loss: 0.3708377182483673\n",
      "Batch: 11201 Loss: 0.38726016879081726\n",
      "Batch: 11265 Loss: 0.5318798422813416\n",
      "Batch: 11329 Loss: 0.6492108106613159\n",
      "Batch: 11393 Loss: 0.2990013659000397\n",
      "Batch: 11457 Loss: 0.37019047141075134\n",
      "Batch: 11521 Loss: 0.38694560527801514\n",
      "Batch: 11585 Loss: 0.49330827593803406\n",
      "Batch: 11649 Loss: 0.32547324895858765\n",
      "Batch: 11713 Loss: 0.4306935667991638\n",
      "Batch: 11777 Loss: 0.6109572649002075\n",
      "Batch: 11841 Loss: 0.5727147459983826\n",
      "Batch: 11905 Loss: 0.4568675756454468\n",
      "Batch: 11969 Loss: 0.4227215349674225\n",
      "Batch: 12033 Loss: 0.3763440251350403\n",
      "Batch: 12097 Loss: 0.9427769780158997\n",
      "Batch: 12161 Loss: 0.5179686546325684\n",
      "Batch: 12225 Loss: 0.2999473810195923\n",
      "Batch: 12289 Loss: 0.31843167543411255\n",
      "Batch: 12353 Loss: 0.43545058369636536\n",
      "Batch: 12417 Loss: 0.3732566237449646\n",
      "Batch: 12481 Loss: 0.41220977902412415\n",
      "Batch: 12545 Loss: 0.4835740029811859\n",
      "Batch: 12609 Loss: 0.5231419801712036\n",
      "Batch: 12673 Loss: 0.54961097240448\n",
      "Batch: 12737 Loss: 0.45682623982429504\n",
      "Batch: 12801 Loss: 0.38159850239753723\n",
      "Batch: 12865 Loss: 0.3238939940929413\n",
      "Batch: 12929 Loss: 0.6593117713928223\n",
      "Epoch: 24\n",
      "Batch: 1 Loss: 0.4011934995651245\n",
      "Batch: 65 Loss: 0.465287446975708\n",
      "Batch: 129 Loss: 0.3977898359298706\n",
      "Batch: 193 Loss: 0.5955439805984497\n",
      "Batch: 257 Loss: 0.4296809732913971\n",
      "Batch: 321 Loss: 0.40641385316848755\n",
      "Batch: 385 Loss: 0.41226842999458313\n",
      "Batch: 449 Loss: 0.37637242674827576\n",
      "Batch: 513 Loss: 0.39493075013160706\n",
      "Batch: 577 Loss: 0.3920859098434448\n",
      "Batch: 641 Loss: 0.4667639434337616\n",
      "Batch: 705 Loss: 0.41437456011772156\n",
      "Batch: 769 Loss: 0.4643872082233429\n",
      "Batch: 833 Loss: 0.3424164652824402\n",
      "Batch: 897 Loss: 0.5691529512405396\n",
      "Batch: 961 Loss: 0.3641258478164673\n",
      "Batch: 1025 Loss: 0.3977082073688507\n",
      "Batch: 1089 Loss: 0.39644262194633484\n",
      "Batch: 1153 Loss: 0.4274369776248932\n",
      "Batch: 1217 Loss: 0.3840252757072449\n",
      "Batch: 1281 Loss: 0.4140125513076782\n",
      "Batch: 1345 Loss: 0.423223078250885\n",
      "Batch: 1409 Loss: 0.35866326093673706\n",
      "Batch: 1473 Loss: 0.41117894649505615\n",
      "Batch: 1537 Loss: 0.39145901799201965\n",
      "Batch: 1601 Loss: 0.33215081691741943\n",
      "Batch: 1665 Loss: 0.3706092834472656\n",
      "Batch: 1729 Loss: 0.43443211913108826\n",
      "Batch: 1793 Loss: 0.33775100111961365\n",
      "Batch: 1857 Loss: 0.393649697303772\n",
      "Batch: 1921 Loss: 0.4468197524547577\n",
      "Batch: 1985 Loss: 0.36700576543807983\n",
      "Batch: 2049 Loss: 0.34628719091415405\n",
      "Batch: 2113 Loss: 0.38647258281707764\n",
      "Batch: 2177 Loss: 0.42231300473213196\n",
      "Batch: 2241 Loss: 0.4797195792198181\n",
      "Batch: 2305 Loss: 0.4817541837692261\n",
      "Batch: 2369 Loss: 0.49325650930404663\n",
      "Batch: 2433 Loss: 0.43578776717185974\n",
      "Batch: 2497 Loss: 0.4921247959136963\n",
      "Batch: 2561 Loss: 0.4223456084728241\n",
      "Batch: 2625 Loss: 0.4265747666358948\n",
      "Batch: 2689 Loss: 0.4551309049129486\n",
      "Batch: 2753 Loss: 0.3698342740535736\n",
      "Batch: 2817 Loss: 0.5365515947341919\n",
      "Batch: 2881 Loss: 0.4902755916118622\n",
      "Batch: 2945 Loss: 0.4014087915420532\n",
      "Batch: 3009 Loss: 0.5744041800498962\n",
      "Batch: 3073 Loss: 0.45131567120552063\n",
      "Batch: 3137 Loss: 0.40633219480514526\n",
      "Batch: 3201 Loss: 0.3825814127922058\n",
      "Batch: 3265 Loss: 0.37013956904411316\n",
      "Batch: 3329 Loss: 0.399096816778183\n",
      "Batch: 3393 Loss: 0.44375500082969666\n",
      "Batch: 3457 Loss: 0.4078303873538971\n",
      "Batch: 3521 Loss: 0.3083950877189636\n",
      "Batch: 3585 Loss: 0.30520206689834595\n",
      "Batch: 3649 Loss: 0.4895700514316559\n",
      "Batch: 3713 Loss: 0.4063269793987274\n",
      "Batch: 3777 Loss: 0.43069568276405334\n",
      "Batch: 3841 Loss: 0.43515077233314514\n",
      "Batch: 3905 Loss: 0.38838115334510803\n",
      "Batch: 3969 Loss: 0.5310702323913574\n",
      "Batch: 4033 Loss: 0.40007665753364563\n",
      "Batch: 4097 Loss: 0.39551231265068054\n",
      "Batch: 4161 Loss: 0.45751190185546875\n",
      "Batch: 4225 Loss: 0.3342941999435425\n",
      "Batch: 4289 Loss: 0.3612102270126343\n",
      "Batch: 4353 Loss: 0.4917726516723633\n",
      "Batch: 4417 Loss: 0.6343013644218445\n",
      "Batch: 4481 Loss: 0.6896877288818359\n",
      "Batch: 4545 Loss: 0.5582402944564819\n",
      "Batch: 4609 Loss: 0.37294501066207886\n",
      "Batch: 4673 Loss: 0.3525693118572235\n",
      "Batch: 4737 Loss: 0.4550047218799591\n",
      "Batch: 4801 Loss: 0.37530750036239624\n",
      "Batch: 4865 Loss: 0.3782934844493866\n",
      "Batch: 4929 Loss: 0.43088510632514954\n",
      "Batch: 4993 Loss: 0.5326448082923889\n",
      "Batch: 5057 Loss: 0.5223047733306885\n",
      "Batch: 5121 Loss: 0.4059526026248932\n",
      "Batch: 5185 Loss: 0.8622731566429138\n",
      "Batch: 5249 Loss: 0.37425723671913147\n",
      "Batch: 5313 Loss: 0.43974778056144714\n",
      "Batch: 5377 Loss: 0.4241762161254883\n",
      "Batch: 5441 Loss: 0.5313093066215515\n",
      "Batch: 5505 Loss: 0.4823194742202759\n",
      "Batch: 5569 Loss: 0.525368332862854\n",
      "Batch: 5633 Loss: 0.38809412717819214\n",
      "Batch: 5697 Loss: 0.4452483355998993\n",
      "Batch: 5761 Loss: 0.5565574765205383\n",
      "Batch: 5825 Loss: 0.43024536967277527\n",
      "Batch: 5889 Loss: 0.38496139645576477\n",
      "Batch: 5953 Loss: 0.3862563669681549\n",
      "Batch: 6017 Loss: 0.3225705623626709\n",
      "Batch: 6081 Loss: 0.3216630816459656\n",
      "Batch: 6145 Loss: 0.42716652154922485\n",
      "Batch: 6209 Loss: 0.36097800731658936\n",
      "Batch: 6273 Loss: 0.46402081847190857\n",
      "Batch: 6337 Loss: 0.3376346826553345\n",
      "Batch: 6401 Loss: 0.33526676893234253\n",
      "Batch: 6465 Loss: 0.37834033370018005\n",
      "Batch: 6529 Loss: 0.358543336391449\n",
      "Batch: 6593 Loss: 0.40072792768478394\n",
      "Batch: 6657 Loss: 0.32138094305992126\n",
      "Batch: 6721 Loss: 0.44979897141456604\n",
      "Batch: 6785 Loss: 0.42830607295036316\n",
      "Batch: 6849 Loss: 0.42718401551246643\n",
      "Batch: 6913 Loss: 0.39980509877204895\n",
      "Batch: 6977 Loss: 0.43013283610343933\n",
      "Batch: 7041 Loss: 0.42033514380455017\n",
      "Batch: 7105 Loss: 0.35303255915641785\n",
      "Batch: 7169 Loss: 0.41166359186172485\n",
      "Batch: 7233 Loss: 0.3609587848186493\n",
      "Batch: 7297 Loss: 0.417121946811676\n",
      "Batch: 7361 Loss: 0.38781243562698364\n",
      "Batch: 7425 Loss: 0.4744333028793335\n",
      "Batch: 7489 Loss: 0.5654795169830322\n",
      "Batch: 7553 Loss: 0.36724135279655457\n",
      "Batch: 7617 Loss: 0.3647233843803406\n",
      "Batch: 7681 Loss: 0.4446428120136261\n",
      "Batch: 7745 Loss: 0.45737922191619873\n",
      "Batch: 7809 Loss: 0.4203261137008667\n",
      "Batch: 7873 Loss: 0.35313716530799866\n",
      "Batch: 7937 Loss: 0.5597397685050964\n",
      "Batch: 8001 Loss: 0.4183672070503235\n",
      "Batch: 8065 Loss: 0.5578774213790894\n",
      "Batch: 8129 Loss: 0.41696155071258545\n",
      "Batch: 8193 Loss: 0.4580986797809601\n",
      "Batch: 8257 Loss: 0.47821056842803955\n",
      "Batch: 8321 Loss: 0.6381445527076721\n",
      "Batch: 8385 Loss: 0.3149297833442688\n",
      "Batch: 8449 Loss: 0.3493814170360565\n",
      "Batch: 8513 Loss: 0.6348963379859924\n",
      "Batch: 8577 Loss: 0.3315581977367401\n",
      "Batch: 8641 Loss: 0.5079699158668518\n",
      "Batch: 8705 Loss: 0.41320857405662537\n",
      "Batch: 8769 Loss: 0.4768906831741333\n",
      "Batch: 8833 Loss: 0.5281293988227844\n",
      "Batch: 8897 Loss: 0.806479275226593\n",
      "Batch: 8961 Loss: 0.39330795407295227\n",
      "Batch: 9025 Loss: 0.3904476463794708\n",
      "Batch: 9089 Loss: 0.4002462327480316\n",
      "Batch: 9153 Loss: 0.4723871350288391\n",
      "Batch: 9217 Loss: 0.5049776434898376\n",
      "Batch: 9281 Loss: 0.4850335717201233\n",
      "Batch: 9345 Loss: 0.377531498670578\n",
      "Batch: 9409 Loss: 0.530193567276001\n",
      "Batch: 9473 Loss: 0.5657850503921509\n",
      "Batch: 9537 Loss: 0.4807484447956085\n",
      "Batch: 9601 Loss: 0.37048229575157166\n",
      "Batch: 9665 Loss: 0.35999318957328796\n",
      "Batch: 9729 Loss: 0.4595760405063629\n",
      "Batch: 9793 Loss: 0.3891209661960602\n",
      "Batch: 9857 Loss: 0.4285171329975128\n",
      "Batch: 9921 Loss: 0.3975207507610321\n",
      "Batch: 9985 Loss: 0.4539010524749756\n",
      "Batch: 10049 Loss: 0.524722695350647\n",
      "Batch: 10113 Loss: 0.4091561734676361\n",
      "Batch: 10177 Loss: 0.4929596185684204\n",
      "Batch: 10241 Loss: 0.3685930669307709\n",
      "Batch: 10305 Loss: 0.43933290243148804\n",
      "Batch: 10369 Loss: 0.4832358658313751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10433 Loss: 0.4004458785057068\n",
      "Batch: 10497 Loss: 0.39443889260292053\n",
      "Batch: 10561 Loss: 0.3667766749858856\n",
      "Batch: 10625 Loss: 0.43125489354133606\n",
      "Batch: 10689 Loss: 0.4278077781200409\n",
      "Batch: 10753 Loss: 0.3542953133583069\n",
      "Batch: 10817 Loss: 0.31052976846694946\n",
      "Batch: 10881 Loss: 0.36367374658584595\n",
      "Batch: 10945 Loss: 0.3495202362537384\n",
      "Batch: 11009 Loss: 0.38852888345718384\n",
      "Batch: 11073 Loss: 0.4671494960784912\n",
      "Batch: 11137 Loss: 0.37403666973114014\n",
      "Batch: 11201 Loss: 0.38342833518981934\n",
      "Batch: 11265 Loss: 0.5278884172439575\n",
      "Batch: 11329 Loss: 0.6512673497200012\n",
      "Batch: 11393 Loss: 0.2928091883659363\n",
      "Batch: 11457 Loss: 0.36711862683296204\n",
      "Batch: 11521 Loss: 0.38453158736228943\n",
      "Batch: 11585 Loss: 0.4908931851387024\n",
      "Batch: 11649 Loss: 0.3246779143810272\n",
      "Batch: 11713 Loss: 0.42836588621139526\n",
      "Batch: 11777 Loss: 0.6117091178894043\n",
      "Batch: 11841 Loss: 0.5747039318084717\n",
      "Batch: 11905 Loss: 0.45735281705856323\n",
      "Batch: 11969 Loss: 0.4361880421638489\n",
      "Batch: 12033 Loss: 0.3731536865234375\n",
      "Batch: 12097 Loss: 0.9420032501220703\n",
      "Batch: 12161 Loss: 0.5150548219680786\n",
      "Batch: 12225 Loss: 0.2991919219493866\n",
      "Batch: 12289 Loss: 0.31954726576805115\n",
      "Batch: 12353 Loss: 0.43526771664619446\n",
      "Batch: 12417 Loss: 0.3792143762111664\n",
      "Batch: 12481 Loss: 0.39904212951660156\n",
      "Batch: 12545 Loss: 0.48308107256889343\n",
      "Batch: 12609 Loss: 0.5241923332214355\n",
      "Batch: 12673 Loss: 0.5497646927833557\n",
      "Batch: 12737 Loss: 0.451717734336853\n",
      "Batch: 12801 Loss: 0.3766733407974243\n",
      "Batch: 12865 Loss: 0.32098451256752014\n",
      "Batch: 12929 Loss: 0.6562671661376953\n",
      "Epoch: 25\n",
      "Batch: 1 Loss: 0.403138667345047\n",
      "Batch: 65 Loss: 0.46471941471099854\n",
      "Batch: 129 Loss: 0.3981624245643616\n",
      "Batch: 193 Loss: 0.5981298685073853\n",
      "Batch: 257 Loss: 0.4298204481601715\n",
      "Batch: 321 Loss: 0.4103574752807617\n",
      "Batch: 385 Loss: 0.4129520058631897\n",
      "Batch: 449 Loss: 0.3798089921474457\n",
      "Batch: 513 Loss: 0.3948730230331421\n",
      "Batch: 577 Loss: 0.3915225565433502\n",
      "Batch: 641 Loss: 0.4677738845348358\n",
      "Batch: 705 Loss: 0.4145367741584778\n",
      "Batch: 769 Loss: 0.4642401337623596\n",
      "Batch: 833 Loss: 0.34175238013267517\n",
      "Batch: 897 Loss: 0.5690227150917053\n",
      "Batch: 961 Loss: 0.3621128797531128\n",
      "Batch: 1025 Loss: 0.39885884523391724\n",
      "Batch: 1089 Loss: 0.39573317766189575\n",
      "Batch: 1153 Loss: 0.42677390575408936\n",
      "Batch: 1217 Loss: 0.3834509551525116\n",
      "Batch: 1281 Loss: 0.41335564851760864\n",
      "Batch: 1345 Loss: 0.4223964512348175\n",
      "Batch: 1409 Loss: 0.35827693343162537\n",
      "Batch: 1473 Loss: 0.41208451986312866\n",
      "Batch: 1537 Loss: 0.38920876383781433\n",
      "Batch: 1601 Loss: 0.33422598242759705\n",
      "Batch: 1665 Loss: 0.36836087703704834\n",
      "Batch: 1729 Loss: 0.4341655373573303\n",
      "Batch: 1793 Loss: 0.3349093496799469\n",
      "Batch: 1857 Loss: 0.3925565183162689\n",
      "Batch: 1921 Loss: 0.4417122006416321\n",
      "Batch: 1985 Loss: 0.36501821875572205\n",
      "Batch: 2049 Loss: 0.3476537764072418\n",
      "Batch: 2113 Loss: 0.394946813583374\n",
      "Batch: 2177 Loss: 0.4250263571739197\n",
      "Batch: 2241 Loss: 0.46007469296455383\n",
      "Batch: 2305 Loss: 0.4832124710083008\n",
      "Batch: 2369 Loss: 0.5014769434928894\n",
      "Batch: 2433 Loss: 0.4364124536514282\n",
      "Batch: 2497 Loss: 0.49073442816734314\n",
      "Batch: 2561 Loss: 0.4202359616756439\n",
      "Batch: 2625 Loss: 0.42414194345474243\n",
      "Batch: 2689 Loss: 0.44541221857070923\n",
      "Batch: 2753 Loss: 0.36932575702667236\n",
      "Batch: 2817 Loss: 0.53606778383255\n",
      "Batch: 2881 Loss: 0.46748247742652893\n",
      "Batch: 2945 Loss: 0.40883001685142517\n",
      "Batch: 3009 Loss: 0.5705429911613464\n",
      "Batch: 3073 Loss: 0.4479377269744873\n",
      "Batch: 3137 Loss: 0.4042450189590454\n",
      "Batch: 3201 Loss: 0.38174566626548767\n",
      "Batch: 3265 Loss: 0.369090735912323\n",
      "Batch: 3329 Loss: 0.3980308175086975\n",
      "Batch: 3393 Loss: 0.4471701681613922\n",
      "Batch: 3457 Loss: 0.41331782937049866\n",
      "Batch: 3521 Loss: 0.30962294340133667\n",
      "Batch: 3585 Loss: 0.30555054545402527\n",
      "Batch: 3649 Loss: 0.490774929523468\n",
      "Batch: 3713 Loss: 0.4004768133163452\n",
      "Batch: 3777 Loss: 0.42783430218696594\n",
      "Batch: 3841 Loss: 0.4247405230998993\n",
      "Batch: 3905 Loss: 0.3858383297920227\n",
      "Batch: 3969 Loss: 0.5453662872314453\n",
      "Batch: 4033 Loss: 0.4077378511428833\n",
      "Batch: 4097 Loss: 0.40072956681251526\n",
      "Batch: 4161 Loss: 0.4595836400985718\n",
      "Batch: 4225 Loss: 0.33531486988067627\n",
      "Batch: 4289 Loss: 0.3596149682998657\n",
      "Batch: 4353 Loss: 0.4939856231212616\n",
      "Batch: 4417 Loss: 0.6359900832176208\n",
      "Batch: 4481 Loss: 0.6827423572540283\n",
      "Batch: 4545 Loss: 0.5544741153717041\n",
      "Batch: 4609 Loss: 0.3709903359413147\n",
      "Batch: 4673 Loss: 0.35209038853645325\n",
      "Batch: 4737 Loss: 0.4533868730068207\n",
      "Batch: 4801 Loss: 0.37122225761413574\n",
      "Batch: 4865 Loss: 0.37952977418899536\n",
      "Batch: 4929 Loss: 0.4215540587902069\n",
      "Batch: 4993 Loss: 0.535320520401001\n",
      "Batch: 5057 Loss: 0.5151983499526978\n",
      "Batch: 5121 Loss: 0.4071807861328125\n",
      "Batch: 5185 Loss: 0.8601721525192261\n",
      "Batch: 5249 Loss: 0.37040087580680847\n",
      "Batch: 5313 Loss: 0.43952813744544983\n",
      "Batch: 5377 Loss: 0.42226728796958923\n",
      "Batch: 5441 Loss: 0.5251827239990234\n",
      "Batch: 5505 Loss: 0.48115870356559753\n",
      "Batch: 5569 Loss: 0.5230048894882202\n",
      "Batch: 5633 Loss: 0.38907676935195923\n",
      "Batch: 5697 Loss: 0.4470416307449341\n",
      "Batch: 5761 Loss: 0.5568426847457886\n",
      "Batch: 5825 Loss: 0.43071362376213074\n",
      "Batch: 5889 Loss: 0.3822930157184601\n",
      "Batch: 5953 Loss: 0.3859982192516327\n",
      "Batch: 6017 Loss: 0.3355344831943512\n",
      "Batch: 6081 Loss: 0.31972071528434753\n",
      "Batch: 6145 Loss: 0.44326093792915344\n",
      "Batch: 6209 Loss: 0.3596496880054474\n",
      "Batch: 6273 Loss: 0.4623275697231293\n",
      "Batch: 6337 Loss: 0.3356872797012329\n",
      "Batch: 6401 Loss: 0.3344103991985321\n",
      "Batch: 6465 Loss: 0.3779985308647156\n",
      "Batch: 6529 Loss: 0.3579089939594269\n",
      "Batch: 6593 Loss: 0.40140119194984436\n",
      "Batch: 6657 Loss: 0.3199162185192108\n",
      "Batch: 6721 Loss: 0.4386054575443268\n",
      "Batch: 6785 Loss: 0.42610859870910645\n",
      "Batch: 6849 Loss: 0.4227616786956787\n",
      "Batch: 6913 Loss: 0.3955528736114502\n",
      "Batch: 6977 Loss: 0.42871516942977905\n",
      "Batch: 7041 Loss: 0.4193063974380493\n",
      "Batch: 7105 Loss: 0.35216906666755676\n",
      "Batch: 7169 Loss: 0.41068342328071594\n",
      "Batch: 7233 Loss: 0.35914814472198486\n",
      "Batch: 7297 Loss: 0.41575339436531067\n",
      "Batch: 7361 Loss: 0.386563241481781\n",
      "Batch: 7425 Loss: 0.47290587425231934\n",
      "Batch: 7489 Loss: 0.5652334690093994\n",
      "Batch: 7553 Loss: 0.3669780492782593\n",
      "Batch: 7617 Loss: 0.36518189311027527\n",
      "Batch: 7681 Loss: 0.44279977679252625\n",
      "Batch: 7745 Loss: 0.4553908705711365\n",
      "Batch: 7809 Loss: 0.4198896586894989\n",
      "Batch: 7873 Loss: 0.35336217284202576\n",
      "Batch: 7937 Loss: 0.5578247904777527\n",
      "Batch: 8001 Loss: 0.4152988791465759\n",
      "Batch: 8065 Loss: 0.555564284324646\n",
      "Batch: 8129 Loss: 0.4142136871814728\n",
      "Batch: 8193 Loss: 0.4502131938934326\n",
      "Batch: 8257 Loss: 0.4703567922115326\n",
      "Batch: 8321 Loss: 0.6382246613502502\n",
      "Batch: 8385 Loss: 0.31426915526390076\n",
      "Batch: 8449 Loss: 0.34872499108314514\n",
      "Batch: 8513 Loss: 0.6350586414337158\n",
      "Batch: 8577 Loss: 0.3320382535457611\n",
      "Batch: 8641 Loss: 0.5098955035209656\n",
      "Batch: 8705 Loss: 0.41057896614074707\n",
      "Batch: 8769 Loss: 0.4751626253128052\n",
      "Batch: 8833 Loss: 0.5305056571960449\n",
      "Batch: 8897 Loss: 0.8014190196990967\n",
      "Batch: 8961 Loss: 0.3964923918247223\n",
      "Batch: 9025 Loss: 0.38976025581359863\n",
      "Batch: 9089 Loss: 0.40123066306114197\n",
      "Batch: 9153 Loss: 0.46726617217063904\n",
      "Batch: 9217 Loss: 0.50162273645401\n",
      "Batch: 9281 Loss: 0.47095274925231934\n",
      "Batch: 9345 Loss: 0.37609967589378357\n",
      "Batch: 9409 Loss: 0.5079900622367859\n",
      "Batch: 9473 Loss: 0.5703384876251221\n",
      "Batch: 9537 Loss: 0.47560957074165344\n",
      "Batch: 9601 Loss: 0.36915460228919983\n",
      "Batch: 9665 Loss: 0.3609120547771454\n",
      "Batch: 9729 Loss: 0.4626004695892334\n",
      "Batch: 9793 Loss: 0.4006524980068207\n",
      "Batch: 9857 Loss: 0.4448455572128296\n",
      "Batch: 9921 Loss: 0.41277000308036804\n",
      "Batch: 9985 Loss: 0.4491128623485565\n",
      "Batch: 10049 Loss: 0.5199233293533325\n",
      "Batch: 10113 Loss: 0.4080891013145447\n",
      "Batch: 10177 Loss: 0.5012763142585754\n",
      "Batch: 10241 Loss: 0.3669110834598541\n",
      "Batch: 10305 Loss: 0.44151508808135986\n",
      "Batch: 10369 Loss: 0.48120343685150146\n",
      "Batch: 10433 Loss: 0.4009977877140045\n",
      "Batch: 10497 Loss: 0.3950275778770447\n",
      "Batch: 10561 Loss: 0.3664158284664154\n",
      "Batch: 10625 Loss: 0.43344321846961975\n",
      "Batch: 10689 Loss: 0.4208800494670868\n",
      "Batch: 10753 Loss: 0.362682044506073\n",
      "Batch: 10817 Loss: 0.3105739951133728\n",
      "Batch: 10881 Loss: 0.36289140582084656\n",
      "Batch: 10945 Loss: 0.3501838445663452\n",
      "Batch: 11009 Loss: 0.38841140270233154\n",
      "Batch: 11073 Loss: 0.4611436724662781\n",
      "Batch: 11137 Loss: 0.3726870119571686\n",
      "Batch: 11201 Loss: 0.3834940493106842\n",
      "Batch: 11265 Loss: 0.526417076587677\n",
      "Batch: 11329 Loss: 0.6570611596107483\n",
      "Batch: 11393 Loss: 0.287039190530777\n",
      "Batch: 11457 Loss: 0.36431342363357544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 11521 Loss: 0.39583152532577515\n",
      "Batch: 11585 Loss: 0.4905177652835846\n",
      "Batch: 11649 Loss: 0.3241545855998993\n",
      "Batch: 11713 Loss: 0.4287716746330261\n",
      "Batch: 11777 Loss: 0.6087096333503723\n",
      "Batch: 11841 Loss: 0.5711236596107483\n",
      "Batch: 11905 Loss: 0.4550849199295044\n",
      "Batch: 11969 Loss: 0.4272767901420593\n",
      "Batch: 12033 Loss: 0.3711700737476349\n",
      "Batch: 12097 Loss: 0.9426557421684265\n",
      "Batch: 12161 Loss: 0.5241923332214355\n",
      "Batch: 12225 Loss: 0.29709604382514954\n",
      "Batch: 12289 Loss: 0.3199096620082855\n",
      "Batch: 12353 Loss: 0.4312400817871094\n",
      "Batch: 12417 Loss: 0.36193451285362244\n",
      "Batch: 12481 Loss: 0.3948419988155365\n",
      "Batch: 12545 Loss: 0.48048076033592224\n",
      "Batch: 12609 Loss: 0.5200889110565186\n",
      "Batch: 12673 Loss: 0.5433202385902405\n",
      "Batch: 12737 Loss: 0.4504123330116272\n",
      "Batch: 12801 Loss: 0.37829068303108215\n",
      "Batch: 12865 Loss: 0.32300493121147156\n",
      "Batch: 12929 Loss: 0.6548396944999695\n",
      "Epoch: 26\n",
      "Batch: 1 Loss: 0.40367311239242554\n",
      "Batch: 65 Loss: 0.4645192623138428\n",
      "Batch: 129 Loss: 0.398113489151001\n",
      "Batch: 193 Loss: 0.5961952209472656\n",
      "Batch: 257 Loss: 0.4274061918258667\n",
      "Batch: 321 Loss: 0.40484288334846497\n",
      "Batch: 385 Loss: 0.40901318192481995\n",
      "Batch: 449 Loss: 0.37507954239845276\n",
      "Batch: 513 Loss: 0.3939797580242157\n",
      "Batch: 577 Loss: 0.39279672503471375\n",
      "Batch: 641 Loss: 0.467725932598114\n",
      "Batch: 705 Loss: 0.41758421063423157\n",
      "Batch: 769 Loss: 0.4656570851802826\n",
      "Batch: 833 Loss: 0.3427013158798218\n",
      "Batch: 897 Loss: 0.5694668889045715\n",
      "Batch: 961 Loss: 0.36500850319862366\n",
      "Batch: 1025 Loss: 0.398177832365036\n",
      "Batch: 1089 Loss: 0.39585861563682556\n",
      "Batch: 1153 Loss: 0.42794567346572876\n",
      "Batch: 1217 Loss: 0.3838522136211395\n",
      "Batch: 1281 Loss: 0.41316401958465576\n",
      "Batch: 1345 Loss: 0.4230877757072449\n",
      "Batch: 1409 Loss: 0.35882773995399475\n",
      "Batch: 1473 Loss: 0.41078945994377136\n",
      "Batch: 1537 Loss: 0.3882599472999573\n",
      "Batch: 1601 Loss: 0.3322363793849945\n",
      "Batch: 1665 Loss: 0.36723968386650085\n",
      "Batch: 1729 Loss: 0.43220284581184387\n",
      "Batch: 1793 Loss: 0.33556920289993286\n",
      "Batch: 1857 Loss: 0.39065492153167725\n",
      "Batch: 1921 Loss: 0.4480704963207245\n",
      "Batch: 1985 Loss: 0.3659488260746002\n",
      "Batch: 2049 Loss: 0.3386442959308624\n",
      "Batch: 2113 Loss: 0.3607926666736603\n",
      "Batch: 2177 Loss: 0.4125097393989563\n",
      "Batch: 2241 Loss: 0.4652009904384613\n",
      "Batch: 2305 Loss: 0.4932023882865906\n",
      "Batch: 2369 Loss: 0.4983183443546295\n",
      "Batch: 2433 Loss: 0.43606477975845337\n",
      "Batch: 2497 Loss: 0.49463117122650146\n",
      "Batch: 2561 Loss: 0.421371728181839\n",
      "Batch: 2625 Loss: 0.42300891876220703\n",
      "Batch: 2689 Loss: 0.4393407702445984\n",
      "Batch: 2753 Loss: 0.3680606186389923\n",
      "Batch: 2817 Loss: 0.5328541398048401\n",
      "Batch: 2881 Loss: 0.4651044011116028\n",
      "Batch: 2945 Loss: 0.4116978943347931\n",
      "Batch: 3009 Loss: 0.5645936727523804\n",
      "Batch: 3073 Loss: 0.4486389756202698\n",
      "Batch: 3137 Loss: 0.40197429060935974\n",
      "Batch: 3201 Loss: 0.3831842541694641\n",
      "Batch: 3265 Loss: 0.370639443397522\n",
      "Batch: 3329 Loss: 0.40140873193740845\n",
      "Batch: 3393 Loss: 0.4530511796474457\n",
      "Batch: 3457 Loss: 0.41670718789100647\n",
      "Batch: 3521 Loss: 0.32275429368019104\n",
      "Batch: 3585 Loss: 0.30673304200172424\n",
      "Batch: 3649 Loss: 0.48662644624710083\n",
      "Batch: 3713 Loss: 0.39877191185951233\n",
      "Batch: 3777 Loss: 0.4253188967704773\n",
      "Batch: 3841 Loss: 0.42573681473731995\n",
      "Batch: 3905 Loss: 0.39913952350616455\n",
      "Batch: 3969 Loss: 0.5499048829078674\n",
      "Batch: 4033 Loss: 0.4145267903804779\n",
      "Batch: 4097 Loss: 0.4126746952533722\n",
      "Batch: 4161 Loss: 0.4718424379825592\n",
      "Batch: 4225 Loss: 0.3446506857872009\n",
      "Batch: 4289 Loss: 0.36332276463508606\n",
      "Batch: 4353 Loss: 0.49462687969207764\n",
      "Batch: 4417 Loss: 0.6377792358398438\n",
      "Batch: 4481 Loss: 0.6820259094238281\n",
      "Batch: 4545 Loss: 0.5582916736602783\n",
      "Batch: 4609 Loss: 0.37879234552383423\n",
      "Batch: 4673 Loss: 0.35407358407974243\n",
      "Batch: 4737 Loss: 0.45201578736305237\n",
      "Batch: 4801 Loss: 0.37589114904403687\n",
      "Batch: 4865 Loss: 0.377391517162323\n",
      "Batch: 4929 Loss: 0.4189649522304535\n",
      "Batch: 4993 Loss: 0.5299263596534729\n",
      "Batch: 5057 Loss: 0.542169988155365\n",
      "Batch: 5121 Loss: 0.39085468649864197\n",
      "Batch: 5185 Loss: 0.8521195650100708\n",
      "Batch: 5249 Loss: 0.36919426918029785\n",
      "Batch: 5313 Loss: 0.44074198603630066\n",
      "Batch: 5377 Loss: 0.4221668839454651\n",
      "Batch: 5441 Loss: 0.5298777222633362\n",
      "Batch: 5505 Loss: 0.4810919463634491\n",
      "Batch: 5569 Loss: 0.5206184387207031\n",
      "Batch: 5633 Loss: 0.38823625445365906\n",
      "Batch: 5697 Loss: 0.446914941072464\n",
      "Batch: 5761 Loss: 0.5586390495300293\n",
      "Batch: 5825 Loss: 0.42823511362075806\n",
      "Batch: 5889 Loss: 0.3838300406932831\n",
      "Batch: 5953 Loss: 0.38441184163093567\n",
      "Batch: 6017 Loss: 0.32477203011512756\n",
      "Batch: 6081 Loss: 0.31860166788101196\n",
      "Batch: 6145 Loss: 0.4244454503059387\n",
      "Batch: 6209 Loss: 0.3564002811908722\n",
      "Batch: 6273 Loss: 0.4612285792827606\n",
      "Batch: 6337 Loss: 0.3346216678619385\n",
      "Batch: 6401 Loss: 0.3351612687110901\n",
      "Batch: 6465 Loss: 0.37784281373023987\n",
      "Batch: 6529 Loss: 0.3565399944782257\n",
      "Batch: 6593 Loss: 0.39865076541900635\n",
      "Batch: 6657 Loss: 0.32665038108825684\n",
      "Batch: 6721 Loss: 0.4537198841571808\n",
      "Batch: 6785 Loss: 0.4273892045021057\n",
      "Batch: 6849 Loss: 0.42129048705101013\n",
      "Batch: 6913 Loss: 0.39396679401397705\n",
      "Batch: 6977 Loss: 0.42845916748046875\n",
      "Batch: 7041 Loss: 0.4195009768009186\n",
      "Batch: 7105 Loss: 0.3504270911216736\n",
      "Batch: 7169 Loss: 0.4102137088775635\n",
      "Batch: 7233 Loss: 0.35695788264274597\n",
      "Batch: 7297 Loss: 0.41468268632888794\n",
      "Batch: 7361 Loss: 0.38516703248023987\n",
      "Batch: 7425 Loss: 0.47269076108932495\n",
      "Batch: 7489 Loss: 0.5633710026741028\n",
      "Batch: 7553 Loss: 0.3671696186065674\n",
      "Batch: 7617 Loss: 0.36571577191352844\n",
      "Batch: 7681 Loss: 0.4425896108150482\n",
      "Batch: 7745 Loss: 0.45579227805137634\n",
      "Batch: 7809 Loss: 0.4207005798816681\n",
      "Batch: 7873 Loss: 0.3504732847213745\n",
      "Batch: 7937 Loss: 0.5564817190170288\n",
      "Batch: 8001 Loss: 0.41562598943710327\n",
      "Batch: 8065 Loss: 0.5557421445846558\n",
      "Batch: 8129 Loss: 0.4151700437068939\n",
      "Batch: 8193 Loss: 0.4497102200984955\n",
      "Batch: 8257 Loss: 0.48020800948143005\n",
      "Batch: 8321 Loss: 0.6359382271766663\n",
      "Batch: 8385 Loss: 0.31397557258605957\n",
      "Batch: 8449 Loss: 0.34903690218925476\n",
      "Batch: 8513 Loss: 0.6334290504455566\n",
      "Batch: 8577 Loss: 0.3305210471153259\n",
      "Batch: 8641 Loss: 0.5036818981170654\n",
      "Batch: 8705 Loss: 0.4106886386871338\n",
      "Batch: 8769 Loss: 0.4738811254501343\n",
      "Batch: 8833 Loss: 0.5257152318954468\n",
      "Batch: 8897 Loss: 0.798822820186615\n",
      "Batch: 8961 Loss: 0.3932630717754364\n",
      "Batch: 9025 Loss: 0.3907575309276581\n",
      "Batch: 9089 Loss: 0.4004022181034088\n",
      "Batch: 9153 Loss: 0.46945497393608093\n",
      "Batch: 9217 Loss: 0.5010848641395569\n",
      "Batch: 9281 Loss: 0.47509726881980896\n",
      "Batch: 9345 Loss: 0.37192967534065247\n",
      "Batch: 9409 Loss: 0.5080487728118896\n",
      "Batch: 9473 Loss: 0.5636342167854309\n",
      "Batch: 9537 Loss: 0.4746353030204773\n",
      "Batch: 9601 Loss: 0.36838823556900024\n",
      "Batch: 9665 Loss: 0.3598928153514862\n",
      "Batch: 9729 Loss: 0.4601030647754669\n",
      "Batch: 9793 Loss: 0.3988230228424072\n",
      "Batch: 9857 Loss: 0.44333750009536743\n",
      "Batch: 9921 Loss: 0.41100338101387024\n",
      "Batch: 9985 Loss: 0.44810613989830017\n",
      "Batch: 10049 Loss: 0.5192158818244934\n",
      "Batch: 10113 Loss: 0.4075776934623718\n",
      "Batch: 10177 Loss: 0.4953445494174957\n",
      "Batch: 10241 Loss: 0.3666944205760956\n",
      "Batch: 10305 Loss: 0.4395369589328766\n",
      "Batch: 10369 Loss: 0.4812554121017456\n",
      "Batch: 10433 Loss: 0.40630534291267395\n",
      "Batch: 10497 Loss: 0.3977093994617462\n",
      "Batch: 10561 Loss: 0.3667512834072113\n",
      "Batch: 10625 Loss: 0.4331691563129425\n",
      "Batch: 10689 Loss: 0.41992810368537903\n",
      "Batch: 10753 Loss: 0.3666466176509857\n",
      "Batch: 10817 Loss: 0.3107222318649292\n",
      "Batch: 10881 Loss: 0.3617859482765198\n",
      "Batch: 10945 Loss: 0.3490757346153259\n",
      "Batch: 11009 Loss: 0.39124274253845215\n",
      "Batch: 11073 Loss: 0.45572301745414734\n",
      "Batch: 11137 Loss: 0.370958536863327\n",
      "Batch: 11201 Loss: 0.3811497986316681\n",
      "Batch: 11265 Loss: 0.5247365832328796\n",
      "Batch: 11329 Loss: 0.6456584930419922\n",
      "Batch: 11393 Loss: 0.28342899680137634\n",
      "Batch: 11457 Loss: 0.36114686727523804\n",
      "Batch: 11521 Loss: 0.378289133310318\n",
      "Batch: 11585 Loss: 0.49012482166290283\n",
      "Batch: 11649 Loss: 0.32723402976989746\n",
      "Batch: 11713 Loss: 0.4283241629600525\n",
      "Batch: 11777 Loss: 0.6084787845611572\n",
      "Batch: 11841 Loss: 0.5686808228492737\n",
      "Batch: 11905 Loss: 0.4531690776348114\n",
      "Batch: 11969 Loss: 0.42293956875801086\n",
      "Batch: 12033 Loss: 0.3703490197658539\n",
      "Batch: 12097 Loss: 0.9367250204086304\n",
      "Batch: 12161 Loss: 0.5165107250213623\n",
      "Batch: 12225 Loss: 0.2971581816673279\n",
      "Batch: 12289 Loss: 0.322053462266922\n",
      "Batch: 12353 Loss: 0.4346233904361725\n",
      "Batch: 12417 Loss: 0.36013323068618774\n",
      "Batch: 12481 Loss: 0.39346081018447876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 12545 Loss: 0.47955483198165894\n",
      "Batch: 12609 Loss: 0.5198544263839722\n",
      "Batch: 12673 Loss: 0.549808919429779\n",
      "Batch: 12737 Loss: 0.45784083008766174\n",
      "Batch: 12801 Loss: 0.3793071508407593\n",
      "Batch: 12865 Loss: 0.3224885165691376\n",
      "Batch: 12929 Loss: 0.6516490578651428\n",
      "Epoch: 27\n",
      "Batch: 1 Loss: 0.40053102374076843\n",
      "Batch: 65 Loss: 0.46389585733413696\n",
      "Batch: 129 Loss: 0.39715704321861267\n",
      "Batch: 193 Loss: 0.5944310426712036\n",
      "Batch: 257 Loss: 0.42590510845184326\n",
      "Batch: 321 Loss: 0.40863245725631714\n",
      "Batch: 385 Loss: 0.41087502241134644\n",
      "Batch: 449 Loss: 0.3772770166397095\n",
      "Batch: 513 Loss: 0.39387619495391846\n",
      "Batch: 577 Loss: 0.3919335901737213\n",
      "Batch: 641 Loss: 0.46638014912605286\n",
      "Batch: 705 Loss: 0.4140561819076538\n",
      "Batch: 769 Loss: 0.4645644724369049\n",
      "Batch: 833 Loss: 0.3410288393497467\n",
      "Batch: 897 Loss: 0.5681645274162292\n",
      "Batch: 961 Loss: 0.36116358637809753\n",
      "Batch: 1025 Loss: 0.39820733666419983\n",
      "Batch: 1089 Loss: 0.3961382806301117\n",
      "Batch: 1153 Loss: 0.42686307430267334\n",
      "Batch: 1217 Loss: 0.382706880569458\n",
      "Batch: 1281 Loss: 0.41375958919525146\n",
      "Batch: 1345 Loss: 0.42312297224998474\n",
      "Batch: 1409 Loss: 0.3597489893436432\n",
      "Batch: 1473 Loss: 0.41072604060173035\n",
      "Batch: 1537 Loss: 0.3880237340927124\n",
      "Batch: 1601 Loss: 0.3322332501411438\n",
      "Batch: 1665 Loss: 0.367131769657135\n",
      "Batch: 1729 Loss: 0.43243783712387085\n",
      "Batch: 1793 Loss: 0.3347587585449219\n",
      "Batch: 1857 Loss: 0.3914583921432495\n",
      "Batch: 1921 Loss: 0.44121241569519043\n",
      "Batch: 1985 Loss: 0.3653901219367981\n",
      "Batch: 2049 Loss: 0.33811327815055847\n",
      "Batch: 2113 Loss: 0.3587389886379242\n",
      "Batch: 2177 Loss: 0.40980425477027893\n",
      "Batch: 2241 Loss: 0.4630677103996277\n",
      "Batch: 2305 Loss: 0.4807513356208801\n",
      "Batch: 2369 Loss: 0.4969636797904968\n",
      "Batch: 2433 Loss: 0.4390755295753479\n",
      "Batch: 2497 Loss: 0.5029792785644531\n",
      "Batch: 2561 Loss: 0.4212352931499481\n",
      "Batch: 2625 Loss: 0.4246971905231476\n",
      "Batch: 2689 Loss: 0.43929025530815125\n",
      "Batch: 2753 Loss: 0.3732188642024994\n",
      "Batch: 2817 Loss: 0.532457709312439\n",
      "Batch: 2881 Loss: 0.46568986773490906\n",
      "Batch: 2945 Loss: 0.40348854660987854\n",
      "Batch: 3009 Loss: 0.5686859488487244\n",
      "Batch: 3073 Loss: 0.4492861330509186\n",
      "Batch: 3137 Loss: 0.4009212255477905\n",
      "Batch: 3201 Loss: 0.38263392448425293\n",
      "Batch: 3265 Loss: 0.3695243000984192\n",
      "Batch: 3329 Loss: 0.39976194500923157\n",
      "Batch: 3393 Loss: 0.44110509753227234\n",
      "Batch: 3457 Loss: 0.4168334901332855\n",
      "Batch: 3521 Loss: 0.3078954815864563\n",
      "Batch: 3585 Loss: 0.30225563049316406\n",
      "Batch: 3649 Loss: 0.4862368702888489\n",
      "Batch: 3713 Loss: 0.3980397880077362\n",
      "Batch: 3777 Loss: 0.42576131224632263\n",
      "Batch: 3841 Loss: 0.4142337441444397\n",
      "Batch: 3905 Loss: 0.3955615162849426\n",
      "Batch: 3969 Loss: 0.5463963150978088\n",
      "Batch: 4033 Loss: 0.4127940535545349\n",
      "Batch: 4097 Loss: 0.4102783799171448\n",
      "Batch: 4161 Loss: 0.4659596085548401\n",
      "Batch: 4225 Loss: 0.33323967456817627\n",
      "Batch: 4289 Loss: 0.3570738136768341\n",
      "Batch: 4353 Loss: 0.4873354434967041\n",
      "Batch: 4417 Loss: 0.6344093680381775\n",
      "Batch: 4481 Loss: 0.6819422245025635\n",
      "Batch: 4545 Loss: 0.5490307211875916\n",
      "Batch: 4609 Loss: 0.3694063723087311\n",
      "Batch: 4673 Loss: 0.35116004943847656\n",
      "Batch: 4737 Loss: 0.44956618547439575\n",
      "Batch: 4801 Loss: 0.37215563654899597\n",
      "Batch: 4865 Loss: 0.3692849576473236\n",
      "Batch: 4929 Loss: 0.420393705368042\n",
      "Batch: 4993 Loss: 0.5267823934555054\n",
      "Batch: 5057 Loss: 0.5031731128692627\n",
      "Batch: 5121 Loss: 0.3888978660106659\n",
      "Batch: 5185 Loss: 0.8527697920799255\n",
      "Batch: 5249 Loss: 0.37012675404548645\n",
      "Batch: 5313 Loss: 0.439704567193985\n",
      "Batch: 5377 Loss: 0.42181187868118286\n",
      "Batch: 5441 Loss: 0.522638738155365\n",
      "Batch: 5505 Loss: 0.4796868562698364\n",
      "Batch: 5569 Loss: 0.5202028751373291\n",
      "Batch: 5633 Loss: 0.38892117142677307\n",
      "Batch: 5697 Loss: 0.44674891233444214\n",
      "Batch: 5761 Loss: 0.5583500266075134\n",
      "Batch: 5825 Loss: 0.428143709897995\n",
      "Batch: 5889 Loss: 0.38235360383987427\n",
      "Batch: 5953 Loss: 0.3852980136871338\n",
      "Batch: 6017 Loss: 0.32353198528289795\n",
      "Batch: 6081 Loss: 0.31833264231681824\n",
      "Batch: 6145 Loss: 0.4235665202140808\n",
      "Batch: 6209 Loss: 0.35509395599365234\n",
      "Batch: 6273 Loss: 0.4595017731189728\n",
      "Batch: 6337 Loss: 0.33447879552841187\n",
      "Batch: 6401 Loss: 0.3349549472332001\n",
      "Batch: 6465 Loss: 0.3771475851535797\n",
      "Batch: 6529 Loss: 0.3559463322162628\n",
      "Batch: 6593 Loss: 0.3964824676513672\n",
      "Batch: 6657 Loss: 0.31867918372154236\n",
      "Batch: 6721 Loss: 0.43532875180244446\n",
      "Batch: 6785 Loss: 0.42694640159606934\n",
      "Batch: 6849 Loss: 0.4202815592288971\n",
      "Batch: 6913 Loss: 0.3929327130317688\n",
      "Batch: 6977 Loss: 0.42885497212409973\n",
      "Batch: 7041 Loss: 0.4190630614757538\n",
      "Batch: 7105 Loss: 0.3519122302532196\n",
      "Batch: 7169 Loss: 0.4084146320819855\n",
      "Batch: 7233 Loss: 0.35832393169403076\n",
      "Batch: 7297 Loss: 0.4140773415565491\n",
      "Batch: 7361 Loss: 0.3837432861328125\n",
      "Batch: 7425 Loss: 0.47068729996681213\n",
      "Batch: 7489 Loss: 0.5632911324501038\n",
      "Batch: 7553 Loss: 0.36678433418273926\n",
      "Batch: 7617 Loss: 0.36500784754753113\n",
      "Batch: 7681 Loss: 0.44232553243637085\n",
      "Batch: 7745 Loss: 0.45547786355018616\n",
      "Batch: 7809 Loss: 0.42075809836387634\n",
      "Batch: 7873 Loss: 0.3506225645542145\n",
      "Batch: 7937 Loss: 0.5550040602684021\n",
      "Batch: 8001 Loss: 0.413706511259079\n",
      "Batch: 8065 Loss: 0.5553650259971619\n",
      "Batch: 8129 Loss: 0.4158055782318115\n",
      "Batch: 8193 Loss: 0.4442228376865387\n",
      "Batch: 8257 Loss: 0.4663999080657959\n",
      "Batch: 8321 Loss: 0.6375888586044312\n",
      "Batch: 8385 Loss: 0.31351280212402344\n",
      "Batch: 8449 Loss: 0.34865137934684753\n",
      "Batch: 8513 Loss: 0.6334264278411865\n",
      "Batch: 8577 Loss: 0.3296131491661072\n",
      "Batch: 8641 Loss: 0.5003246068954468\n",
      "Batch: 8705 Loss: 0.4139261841773987\n",
      "Batch: 8769 Loss: 0.4739947021007538\n",
      "Batch: 8833 Loss: 0.5236185789108276\n",
      "Batch: 8897 Loss: 0.7992055416107178\n",
      "Batch: 8961 Loss: 0.39324501156806946\n",
      "Batch: 9025 Loss: 0.3894076943397522\n",
      "Batch: 9089 Loss: 0.3998645544052124\n",
      "Batch: 9153 Loss: 0.4708145558834076\n",
      "Batch: 9217 Loss: 0.5004594326019287\n",
      "Batch: 9281 Loss: 0.475945383310318\n",
      "Batch: 9345 Loss: 0.3709767758846283\n",
      "Batch: 9409 Loss: 0.49952641129493713\n",
      "Batch: 9473 Loss: 0.5565102100372314\n",
      "Batch: 9537 Loss: 0.4705333113670349\n",
      "Batch: 9601 Loss: 0.36897972226142883\n",
      "Batch: 9665 Loss: 0.3479956388473511\n",
      "Batch: 9729 Loss: 0.44177621603012085\n",
      "Batch: 9793 Loss: 0.38200843334198\n",
      "Batch: 9857 Loss: 0.42754361033439636\n",
      "Batch: 9921 Loss: 0.3966127634048462\n",
      "Batch: 9985 Loss: 0.446196585893631\n",
      "Batch: 10049 Loss: 0.5174316763877869\n",
      "Batch: 10113 Loss: 0.40524882078170776\n",
      "Batch: 10177 Loss: 0.4978838264942169\n",
      "Batch: 10241 Loss: 0.3661457300186157\n",
      "Batch: 10305 Loss: 0.43947532773017883\n",
      "Batch: 10369 Loss: 0.4803096055984497\n",
      "Batch: 10433 Loss: 0.4011741876602173\n",
      "Batch: 10497 Loss: 0.39435285329818726\n",
      "Batch: 10561 Loss: 0.36654356122016907\n",
      "Batch: 10625 Loss: 0.4304391145706177\n",
      "Batch: 10689 Loss: 0.42132556438446045\n",
      "Batch: 10753 Loss: 0.3531034290790558\n",
      "Batch: 10817 Loss: 0.31263941526412964\n",
      "Batch: 10881 Loss: 0.3625871241092682\n",
      "Batch: 10945 Loss: 0.35616546869277954\n",
      "Batch: 11009 Loss: 0.37307626008987427\n",
      "Batch: 11073 Loss: 0.4487798511981964\n",
      "Batch: 11137 Loss: 0.3655618131160736\n",
      "Batch: 11201 Loss: 0.3808997869491577\n",
      "Batch: 11265 Loss: 0.5257601737976074\n",
      "Batch: 11329 Loss: 0.638150155544281\n",
      "Batch: 11393 Loss: 0.28811246156692505\n",
      "Batch: 11457 Loss: 0.38014358282089233\n",
      "Batch: 11521 Loss: 0.3892187774181366\n",
      "Batch: 11585 Loss: 0.49047330021858215\n",
      "Batch: 11649 Loss: 0.32410672307014465\n",
      "Batch: 11713 Loss: 0.4286942780017853\n",
      "Batch: 11777 Loss: 0.6070061922073364\n",
      "Batch: 11841 Loss: 0.5658783316612244\n",
      "Batch: 11905 Loss: 0.45087510347366333\n",
      "Batch: 11969 Loss: 0.4207327365875244\n",
      "Batch: 12033 Loss: 0.3710745573043823\n",
      "Batch: 12097 Loss: 0.9362388253211975\n",
      "Batch: 12161 Loss: 0.5205038785934448\n",
      "Batch: 12225 Loss: 0.2960146367549896\n",
      "Batch: 12289 Loss: 0.3171405792236328\n",
      "Batch: 12353 Loss: 0.42643043398857117\n",
      "Batch: 12417 Loss: 0.3577236831188202\n",
      "Batch: 12481 Loss: 0.39230552315711975\n",
      "Batch: 12545 Loss: 0.48004165291786194\n",
      "Batch: 12609 Loss: 0.5182875990867615\n",
      "Batch: 12673 Loss: 0.5475685000419617\n",
      "Batch: 12737 Loss: 0.4508656859397888\n",
      "Batch: 12801 Loss: 0.3770914375782013\n",
      "Batch: 12865 Loss: 0.3194350004196167\n",
      "Batch: 12929 Loss: 0.6515936851501465\n",
      "Epoch: 28\n",
      "Batch: 1 Loss: 0.40050822496414185\n",
      "Batch: 65 Loss: 0.4634093642234802\n",
      "Batch: 129 Loss: 0.39605388045310974\n",
      "Batch: 193 Loss: 0.5917794108390808\n",
      "Batch: 257 Loss: 0.4244774878025055\n",
      "Batch: 321 Loss: 0.4087013006210327\n",
      "Batch: 385 Loss: 0.41003209352493286\n",
      "Batch: 449 Loss: 0.3768012821674347\n",
      "Batch: 513 Loss: 0.39272376894950867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 577 Loss: 0.39249187707901\n",
      "Batch: 641 Loss: 0.46743038296699524\n",
      "Batch: 705 Loss: 0.41286370158195496\n",
      "Batch: 769 Loss: 0.4617230296134949\n",
      "Batch: 833 Loss: 0.3396400809288025\n",
      "Batch: 897 Loss: 0.5676384568214417\n",
      "Batch: 961 Loss: 0.3627467453479767\n",
      "Batch: 1025 Loss: 0.3972192108631134\n",
      "Batch: 1089 Loss: 0.3958001434803009\n",
      "Batch: 1153 Loss: 0.42752572894096375\n",
      "Batch: 1217 Loss: 0.3836623728275299\n",
      "Batch: 1281 Loss: 0.4131864607334137\n",
      "Batch: 1345 Loss: 0.4234907627105713\n",
      "Batch: 1409 Loss: 0.35829710960388184\n",
      "Batch: 1473 Loss: 0.4104624092578888\n",
      "Batch: 1537 Loss: 0.38771942257881165\n",
      "Batch: 1601 Loss: 0.3330615162849426\n",
      "Batch: 1665 Loss: 0.36758267879486084\n",
      "Batch: 1729 Loss: 0.4332239627838135\n",
      "Batch: 1793 Loss: 0.33531680703163147\n",
      "Batch: 1857 Loss: 0.3875083327293396\n",
      "Batch: 1921 Loss: 0.43704667687416077\n",
      "Batch: 1985 Loss: 0.3774868845939636\n",
      "Batch: 2049 Loss: 0.33815592527389526\n",
      "Batch: 2113 Loss: 0.3577836751937866\n",
      "Batch: 2177 Loss: 0.40936729311943054\n",
      "Batch: 2241 Loss: 0.4636736810207367\n",
      "Batch: 2305 Loss: 0.47348475456237793\n",
      "Batch: 2369 Loss: 0.49348005652427673\n",
      "Batch: 2433 Loss: 0.4343321621417999\n",
      "Batch: 2497 Loss: 0.49464115500450134\n",
      "Batch: 2561 Loss: 0.414652019739151\n",
      "Batch: 2625 Loss: 0.4229935109615326\n",
      "Batch: 2689 Loss: 0.4412086606025696\n",
      "Batch: 2753 Loss: 0.365426629781723\n",
      "Batch: 2817 Loss: 0.5320850014686584\n",
      "Batch: 2881 Loss: 0.4620836675167084\n",
      "Batch: 2945 Loss: 0.4023306369781494\n",
      "Batch: 3009 Loss: 0.561974287033081\n",
      "Batch: 3073 Loss: 0.4466877281665802\n",
      "Batch: 3137 Loss: 0.3975171744823456\n",
      "Batch: 3201 Loss: 0.3826070725917816\n",
      "Batch: 3265 Loss: 0.3703228235244751\n",
      "Batch: 3329 Loss: 0.4009004533290863\n",
      "Batch: 3393 Loss: 0.4420303702354431\n",
      "Batch: 3457 Loss: 0.4177172780036926\n",
      "Batch: 3521 Loss: 0.3081461489200592\n",
      "Batch: 3585 Loss: 0.3102733790874481\n",
      "Batch: 3649 Loss: 0.5142510533332825\n",
      "Batch: 3713 Loss: 0.3994845747947693\n",
      "Batch: 3777 Loss: 0.42410093545913696\n",
      "Batch: 3841 Loss: 0.4123595952987671\n",
      "Batch: 3905 Loss: 0.39876827597618103\n",
      "Batch: 3969 Loss: 0.5469352602958679\n",
      "Batch: 4033 Loss: 0.4126132130622864\n",
      "Batch: 4097 Loss: 0.4125407934188843\n",
      "Batch: 4161 Loss: 0.47262606024742126\n",
      "Batch: 4225 Loss: 0.3454686403274536\n",
      "Batch: 4289 Loss: 0.35844311118125916\n",
      "Batch: 4353 Loss: 0.48809993267059326\n",
      "Batch: 4417 Loss: 0.634502112865448\n",
      "Batch: 4481 Loss: 0.6830959916114807\n",
      "Batch: 4545 Loss: 0.5471917390823364\n",
      "Batch: 4609 Loss: 0.37232062220573425\n",
      "Batch: 4673 Loss: 0.35023054480552673\n",
      "Batch: 4737 Loss: 0.45076170563697815\n",
      "Batch: 4801 Loss: 0.3682234287261963\n",
      "Batch: 4865 Loss: 0.3734590411186218\n",
      "Batch: 4929 Loss: 0.4153890609741211\n",
      "Batch: 4993 Loss: 0.5228014588356018\n",
      "Batch: 5057 Loss: 0.5001034736633301\n",
      "Batch: 5121 Loss: 0.38900813460350037\n",
      "Batch: 5185 Loss: 0.8532782793045044\n",
      "Batch: 5249 Loss: 0.37127575278282166\n",
      "Batch: 5313 Loss: 0.43934914469718933\n",
      "Batch: 5377 Loss: 0.4217536151409149\n",
      "Batch: 5441 Loss: 0.5294281840324402\n",
      "Batch: 5505 Loss: 0.480398565530777\n",
      "Batch: 5569 Loss: 0.5192521214485168\n",
      "Batch: 5633 Loss: 0.38866204023361206\n",
      "Batch: 5697 Loss: 0.45072418451309204\n",
      "Batch: 5761 Loss: 0.565868616104126\n",
      "Batch: 5825 Loss: 0.42929667234420776\n",
      "Batch: 5889 Loss: 0.38382235169410706\n",
      "Batch: 5953 Loss: 0.384162038564682\n",
      "Batch: 6017 Loss: 0.3238475024700165\n",
      "Batch: 6081 Loss: 0.3120206296443939\n",
      "Batch: 6145 Loss: 0.4208434820175171\n",
      "Batch: 6209 Loss: 0.3538757860660553\n",
      "Batch: 6273 Loss: 0.45917195081710815\n",
      "Batch: 6337 Loss: 0.3334462344646454\n",
      "Batch: 6401 Loss: 0.3348613381385803\n",
      "Batch: 6465 Loss: 0.3768790364265442\n",
      "Batch: 6529 Loss: 0.35635754466056824\n",
      "Batch: 6593 Loss: 0.3913634121417999\n",
      "Batch: 6657 Loss: 0.3328201472759247\n",
      "Batch: 6721 Loss: 0.43398383259773254\n",
      "Batch: 6785 Loss: 0.42544180154800415\n",
      "Batch: 6849 Loss: 0.41725414991378784\n",
      "Batch: 6913 Loss: 0.39274004101753235\n",
      "Batch: 6977 Loss: 0.4280083477497101\n",
      "Batch: 7041 Loss: 0.4182260036468506\n",
      "Batch: 7105 Loss: 0.3458755314350128\n",
      "Batch: 7169 Loss: 0.4083370864391327\n",
      "Batch: 7233 Loss: 0.35644277930259705\n",
      "Batch: 7297 Loss: 0.41457274556159973\n",
      "Batch: 7361 Loss: 0.3836161196231842\n",
      "Batch: 7425 Loss: 0.4704272747039795\n",
      "Batch: 7489 Loss: 0.5622027516365051\n",
      "Batch: 7553 Loss: 0.3663212060928345\n",
      "Batch: 7617 Loss: 0.3652246594429016\n",
      "Batch: 7681 Loss: 0.44109204411506653\n",
      "Batch: 7745 Loss: 0.45504382252693176\n",
      "Batch: 7809 Loss: 0.4208693206310272\n",
      "Batch: 7873 Loss: 0.34870854020118713\n",
      "Batch: 7937 Loss: 0.5502728223800659\n",
      "Batch: 8001 Loss: 0.411575049161911\n",
      "Batch: 8065 Loss: 0.552619457244873\n",
      "Batch: 8129 Loss: 0.4137025773525238\n",
      "Batch: 8193 Loss: 0.46712231636047363\n",
      "Batch: 8257 Loss: 0.469524085521698\n",
      "Batch: 8321 Loss: 0.6358975768089294\n",
      "Batch: 8385 Loss: 0.31305888295173645\n",
      "Batch: 8449 Loss: 0.34827351570129395\n",
      "Batch: 8513 Loss: 0.6334366798400879\n",
      "Batch: 8577 Loss: 0.32857048511505127\n",
      "Batch: 8641 Loss: 0.4977978765964508\n",
      "Batch: 8705 Loss: 0.4148804545402527\n",
      "Batch: 8769 Loss: 0.4729847013950348\n",
      "Batch: 8833 Loss: 0.5243052244186401\n",
      "Batch: 8897 Loss: 0.7984097599983215\n",
      "Batch: 8961 Loss: 0.3937571346759796\n",
      "Batch: 9025 Loss: 0.3888810873031616\n",
      "Batch: 9089 Loss: 0.40010544657707214\n",
      "Batch: 9153 Loss: 0.466139554977417\n",
      "Batch: 9217 Loss: 0.4968920648097992\n",
      "Batch: 9281 Loss: 0.46792498230934143\n",
      "Batch: 9345 Loss: 0.3737671673297882\n",
      "Batch: 9409 Loss: 0.5021259784698486\n",
      "Batch: 9473 Loss: 0.5588157176971436\n",
      "Batch: 9537 Loss: 0.47140267491340637\n",
      "Batch: 9601 Loss: 0.36450716853141785\n",
      "Batch: 9665 Loss: 0.3524916172027588\n",
      "Batch: 9729 Loss: 0.44223594665527344\n",
      "Batch: 9793 Loss: 0.38132327795028687\n",
      "Batch: 9857 Loss: 0.4278140962123871\n",
      "Batch: 9921 Loss: 0.3952151834964752\n",
      "Batch: 9985 Loss: 0.44708240032196045\n",
      "Batch: 10049 Loss: 0.5151406526565552\n",
      "Batch: 10113 Loss: 0.402743935585022\n",
      "Batch: 10177 Loss: 0.4976748824119568\n",
      "Batch: 10241 Loss: 0.36545711755752563\n",
      "Batch: 10305 Loss: 0.43947833776474\n",
      "Batch: 10369 Loss: 0.4806240499019623\n",
      "Batch: 10433 Loss: 0.40118008852005005\n",
      "Batch: 10497 Loss: 0.3945181369781494\n",
      "Batch: 10561 Loss: 0.3659864366054535\n",
      "Batch: 10625 Loss: 0.4336625933647156\n",
      "Batch: 10689 Loss: 0.41819074749946594\n",
      "Batch: 10753 Loss: 0.353051096200943\n",
      "Batch: 10817 Loss: 0.31018009781837463\n",
      "Batch: 10881 Loss: 0.3634485900402069\n",
      "Batch: 10945 Loss: 0.34882447123527527\n",
      "Batch: 11009 Loss: 0.3789702355861664\n",
      "Batch: 11073 Loss: 0.4600312113761902\n",
      "Batch: 11137 Loss: 0.3639625906944275\n",
      "Batch: 11201 Loss: 0.3772132098674774\n",
      "Batch: 11265 Loss: 0.5247589349746704\n",
      "Batch: 11329 Loss: 0.6483990550041199\n",
      "Batch: 11393 Loss: 0.29883986711502075\n",
      "Batch: 11457 Loss: 0.361000657081604\n",
      "Batch: 11521 Loss: 0.3740972578525543\n",
      "Batch: 11585 Loss: 0.490070104598999\n",
      "Batch: 11649 Loss: 0.3236849904060364\n",
      "Batch: 11713 Loss: 0.4242617189884186\n",
      "Batch: 11777 Loss: 0.6042277216911316\n",
      "Batch: 11841 Loss: 0.5656970739364624\n",
      "Batch: 11905 Loss: 0.4497182369232178\n",
      "Batch: 11969 Loss: 0.41766512393951416\n",
      "Batch: 12033 Loss: 0.3701482117176056\n",
      "Batch: 12097 Loss: 0.9317550659179688\n",
      "Batch: 12161 Loss: 0.5178705453872681\n",
      "Batch: 12225 Loss: 0.2983958423137665\n",
      "Batch: 12289 Loss: 0.3152799904346466\n",
      "Batch: 12353 Loss: 0.4228902757167816\n",
      "Batch: 12417 Loss: 0.35774460434913635\n",
      "Batch: 12481 Loss: 0.3926321864128113\n",
      "Batch: 12545 Loss: 0.4782240390777588\n",
      "Batch: 12609 Loss: 0.5173080563545227\n",
      "Batch: 12673 Loss: 0.5452301502227783\n",
      "Batch: 12737 Loss: 0.4497193992137909\n",
      "Batch: 12801 Loss: 0.376611590385437\n",
      "Batch: 12865 Loss: 0.3181019127368927\n",
      "Batch: 12929 Loss: 0.6491581201553345\n",
      "Epoch: 29\n",
      "Batch: 1 Loss: 0.4001425504684448\n",
      "Batch: 65 Loss: 0.46339887380599976\n",
      "Batch: 129 Loss: 0.3958996832370758\n",
      "Batch: 193 Loss: 0.592205286026001\n",
      "Batch: 257 Loss: 0.42490264773368835\n",
      "Batch: 321 Loss: 0.4084077775478363\n",
      "Batch: 385 Loss: 0.4096069931983948\n",
      "Batch: 449 Loss: 0.37607017159461975\n",
      "Batch: 513 Loss: 0.3926713764667511\n",
      "Batch: 577 Loss: 0.3918328881263733\n",
      "Batch: 641 Loss: 0.46438929438591003\n",
      "Batch: 705 Loss: 0.4128197729587555\n",
      "Batch: 769 Loss: 0.46366241574287415\n",
      "Batch: 833 Loss: 0.3409641683101654\n",
      "Batch: 897 Loss: 0.566040575504303\n",
      "Batch: 961 Loss: 0.3609658181667328\n",
      "Batch: 1025 Loss: 0.3993084728717804\n",
      "Batch: 1089 Loss: 0.3948429524898529\n",
      "Batch: 1153 Loss: 0.4257229268550873\n",
      "Batch: 1217 Loss: 0.3824251890182495\n",
      "Batch: 1281 Loss: 0.4140964448451996\n",
      "Batch: 1345 Loss: 0.4233764410018921\n",
      "Batch: 1409 Loss: 0.360324889421463\n",
      "Batch: 1473 Loss: 0.40923839807510376\n",
      "Batch: 1537 Loss: 0.38622039556503296\n",
      "Batch: 1601 Loss: 0.3311442732810974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1665 Loss: 0.36655962467193604\n",
      "Batch: 1729 Loss: 0.4319200813770294\n",
      "Batch: 1793 Loss: 0.3349827527999878\n",
      "Batch: 1857 Loss: 0.38621923327445984\n",
      "Batch: 1921 Loss: 0.43625321984291077\n",
      "Batch: 1985 Loss: 0.3664833903312683\n",
      "Batch: 2049 Loss: 0.33723294734954834\n",
      "Batch: 2113 Loss: 0.35586872696876526\n",
      "Batch: 2177 Loss: 0.40968820452690125\n",
      "Batch: 2241 Loss: 0.4639774560928345\n",
      "Batch: 2305 Loss: 0.47814780473709106\n",
      "Batch: 2369 Loss: 0.49495285749435425\n",
      "Batch: 2433 Loss: 0.4343029856681824\n",
      "Batch: 2497 Loss: 0.4945150911808014\n",
      "Batch: 2561 Loss: 0.41267091035842896\n",
      "Batch: 2625 Loss: 0.4224546253681183\n",
      "Batch: 2689 Loss: 0.43797141313552856\n",
      "Batch: 2753 Loss: 0.3624265193939209\n",
      "Batch: 2817 Loss: 0.5314574837684631\n",
      "Batch: 2881 Loss: 0.46477195620536804\n",
      "Batch: 2945 Loss: 0.4027292728424072\n",
      "Batch: 3009 Loss: 0.557274341583252\n",
      "Batch: 3073 Loss: 0.4443082809448242\n",
      "Batch: 3137 Loss: 0.3977023959159851\n",
      "Batch: 3201 Loss: 0.38259199261665344\n",
      "Batch: 3265 Loss: 0.36994147300720215\n",
      "Batch: 3329 Loss: 0.40021565556526184\n",
      "Batch: 3393 Loss: 0.43886440992355347\n",
      "Batch: 3457 Loss: 0.4083242118358612\n",
      "Batch: 3521 Loss: 0.30209270119667053\n",
      "Batch: 3585 Loss: 0.3004601299762726\n",
      "Batch: 3649 Loss: 0.48072898387908936\n",
      "Batch: 3713 Loss: 0.39362508058547974\n",
      "Batch: 3777 Loss: 0.42165830731391907\n",
      "Batch: 3841 Loss: 0.41057100892066956\n",
      "Batch: 3905 Loss: 0.39311882853507996\n",
      "Batch: 3969 Loss: 0.5410445332527161\n",
      "Batch: 4033 Loss: 0.4050539433956146\n",
      "Batch: 4097 Loss: 0.3960353434085846\n",
      "Batch: 4161 Loss: 0.4589271545410156\n",
      "Batch: 4225 Loss: 0.33228597044944763\n",
      "Batch: 4289 Loss: 0.355823278427124\n",
      "Batch: 4353 Loss: 0.4847579598426819\n",
      "Batch: 4417 Loss: 0.6308817267417908\n",
      "Batch: 4481 Loss: 0.6894093751907349\n",
      "Batch: 4545 Loss: 0.5514764189720154\n",
      "Batch: 4609 Loss: 0.36955076456069946\n",
      "Batch: 4673 Loss: 0.348840594291687\n",
      "Batch: 4737 Loss: 0.4475243389606476\n",
      "Batch: 4801 Loss: 0.3736525774002075\n",
      "Batch: 4865 Loss: 0.3657980263233185\n",
      "Batch: 4929 Loss: 0.4267160892486572\n",
      "Batch: 4993 Loss: 0.5218185782432556\n",
      "Batch: 5057 Loss: 0.500426709651947\n",
      "Batch: 5121 Loss: 0.39058804512023926\n",
      "Batch: 5185 Loss: 0.8505924344062805\n",
      "Batch: 5249 Loss: 0.3683077394962311\n",
      "Batch: 5313 Loss: 0.43897005915641785\n",
      "Batch: 5377 Loss: 0.42149919271469116\n",
      "Batch: 5441 Loss: 0.5252209305763245\n",
      "Batch: 5505 Loss: 0.47830814123153687\n",
      "Batch: 5569 Loss: 0.5170789957046509\n",
      "Batch: 5633 Loss: 0.38953810930252075\n",
      "Batch: 5697 Loss: 0.4543965756893158\n",
      "Batch: 5761 Loss: 0.5696095824241638\n",
      "Batch: 5825 Loss: 0.43091443181037903\n",
      "Batch: 5889 Loss: 0.38265737891197205\n",
      "Batch: 5953 Loss: 0.384952187538147\n",
      "Batch: 6017 Loss: 0.32313528656959534\n",
      "Batch: 6081 Loss: 0.3086584210395813\n",
      "Batch: 6145 Loss: 0.41803932189941406\n",
      "Batch: 6209 Loss: 0.35237452387809753\n",
      "Batch: 6273 Loss: 0.4597248136997223\n",
      "Batch: 6337 Loss: 0.3332090973854065\n",
      "Batch: 6401 Loss: 0.33488553762435913\n",
      "Batch: 6465 Loss: 0.3763428330421448\n",
      "Batch: 6529 Loss: 0.35610321164131165\n",
      "Batch: 6593 Loss: 0.38938164710998535\n",
      "Batch: 6657 Loss: 0.3205166757106781\n",
      "Batch: 6721 Loss: 0.42989835143089294\n",
      "Batch: 6785 Loss: 0.42334288358688354\n",
      "Batch: 6849 Loss: 0.42001983523368835\n",
      "Batch: 6913 Loss: 0.3932708501815796\n",
      "Batch: 6977 Loss: 0.4279363751411438\n",
      "Batch: 7041 Loss: 0.4183656573295593\n",
      "Batch: 7105 Loss: 0.3434179425239563\n",
      "Batch: 7169 Loss: 0.411828875541687\n",
      "Batch: 7233 Loss: 0.3549397885799408\n",
      "Batch: 7297 Loss: 0.41235271096229553\n",
      "Batch: 7361 Loss: 0.38319703936576843\n",
      "Batch: 7425 Loss: 0.470121294260025\n",
      "Batch: 7489 Loss: 0.5619317889213562\n",
      "Batch: 7553 Loss: 0.3659878969192505\n",
      "Batch: 7617 Loss: 0.3651045560836792\n",
      "Batch: 7681 Loss: 0.4406677484512329\n",
      "Batch: 7745 Loss: 0.4543549418449402\n",
      "Batch: 7809 Loss: 0.4210737645626068\n",
      "Batch: 7873 Loss: 0.34242069721221924\n",
      "Batch: 7937 Loss: 0.5569788813591003\n",
      "Batch: 8001 Loss: 0.41065481305122375\n",
      "Batch: 8065 Loss: 0.5523306131362915\n",
      "Batch: 8129 Loss: 0.41040894389152527\n",
      "Batch: 8193 Loss: 0.44381633400917053\n",
      "Batch: 8257 Loss: 0.46954479813575745\n",
      "Batch: 8321 Loss: 0.632771372795105\n",
      "Batch: 8385 Loss: 0.3128097355365753\n",
      "Batch: 8449 Loss: 0.34782674908638\n",
      "Batch: 8513 Loss: 0.6336124539375305\n",
      "Batch: 8577 Loss: 0.3283178210258484\n",
      "Batch: 8641 Loss: 0.5005380511283875\n",
      "Batch: 8705 Loss: 0.4096136689186096\n",
      "Batch: 8769 Loss: 0.47060656547546387\n",
      "Batch: 8833 Loss: 0.5239100456237793\n",
      "Batch: 8897 Loss: 0.8027610778808594\n",
      "Batch: 8961 Loss: 0.3937126696109772\n",
      "Batch: 9025 Loss: 0.3887843191623688\n",
      "Batch: 9089 Loss: 0.4004345238208771\n",
      "Batch: 9153 Loss: 0.4648325443267822\n",
      "Batch: 9217 Loss: 0.4963342249393463\n",
      "Batch: 9281 Loss: 0.46343284845352173\n",
      "Batch: 9345 Loss: 0.3678741753101349\n",
      "Batch: 9409 Loss: 0.48985007405281067\n",
      "Batch: 9473 Loss: 0.5543872714042664\n",
      "Batch: 9537 Loss: 0.47340455651283264\n",
      "Batch: 9601 Loss: 0.3576991856098175\n",
      "Batch: 9665 Loss: 0.350378155708313\n",
      "Batch: 9729 Loss: 0.44309061765670776\n",
      "Batch: 9793 Loss: 0.380911260843277\n",
      "Batch: 9857 Loss: 0.4280290901660919\n",
      "Batch: 9921 Loss: 0.39425382018089294\n",
      "Batch: 9985 Loss: 0.44458258152008057\n",
      "Batch: 10049 Loss: 0.5116153955459595\n",
      "Batch: 10113 Loss: 0.4004833400249481\n",
      "Batch: 10177 Loss: 0.49978160858154297\n",
      "Batch: 10241 Loss: 0.36504796147346497\n",
      "Batch: 10305 Loss: 0.4397251605987549\n",
      "Batch: 10369 Loss: 0.4810716509819031\n",
      "Batch: 10433 Loss: 0.4018075466156006\n",
      "Batch: 10497 Loss: 0.3946818709373474\n",
      "Batch: 10561 Loss: 0.36581796407699585\n",
      "Batch: 10625 Loss: 0.4338172972202301\n",
      "Batch: 10689 Loss: 0.4133022129535675\n",
      "Batch: 10753 Loss: 0.3522159159183502\n",
      "Batch: 10817 Loss: 0.31060418486595154\n",
      "Batch: 10881 Loss: 0.3589770495891571\n",
      "Batch: 10945 Loss: 0.346752792596817\n",
      "Batch: 11009 Loss: 0.37003251910209656\n",
      "Batch: 11073 Loss: 0.4588859975337982\n",
      "Batch: 11137 Loss: 0.36348557472229004\n",
      "Batch: 11201 Loss: 0.3735158443450928\n",
      "Batch: 11265 Loss: 0.5240216851234436\n",
      "Batch: 11329 Loss: 0.6502982974052429\n",
      "Batch: 11393 Loss: 0.30187666416168213\n",
      "Batch: 11457 Loss: 0.36058613657951355\n",
      "Batch: 11521 Loss: 0.37383535504341125\n",
      "Batch: 11585 Loss: 0.4900248646736145\n",
      "Batch: 11649 Loss: 0.3236517608165741\n",
      "Batch: 11713 Loss: 0.42260855436325073\n",
      "Batch: 11777 Loss: 0.6028278470039368\n",
      "Batch: 11841 Loss: 0.5650427937507629\n",
      "Batch: 11905 Loss: 0.44682466983795166\n",
      "Batch: 11969 Loss: 0.41824498772621155\n",
      "Batch: 12033 Loss: 0.37037768959999084\n",
      "Batch: 12097 Loss: 0.9259536266326904\n",
      "Batch: 12161 Loss: 0.5125862956047058\n",
      "Batch: 12225 Loss: 0.2971283197402954\n",
      "Batch: 12289 Loss: 0.31538814306259155\n",
      "Batch: 12353 Loss: 0.4212018847465515\n",
      "Batch: 12417 Loss: 0.3568594753742218\n",
      "Batch: 12481 Loss: 0.3917835056781769\n",
      "Batch: 12545 Loss: 0.477426677942276\n",
      "Batch: 12609 Loss: 0.5182061791419983\n",
      "Batch: 12673 Loss: 0.5454788208007812\n",
      "Batch: 12737 Loss: 0.4503066837787628\n",
      "Batch: 12801 Loss: 0.3755462169647217\n",
      "Batch: 12865 Loss: 0.3176502287387848\n",
      "Batch: 12929 Loss: 0.6482902765274048\n",
      "Epoch: 30\n",
      "Batch: 1 Loss: 0.3996865153312683\n",
      "Batch: 65 Loss: 0.4629773795604706\n",
      "Batch: 129 Loss: 0.39462602138519287\n",
      "Batch: 193 Loss: 0.5899386405944824\n",
      "Batch: 257 Loss: 0.4234543740749359\n",
      "Batch: 321 Loss: 0.4078231453895569\n",
      "Batch: 385 Loss: 0.40804266929626465\n",
      "Batch: 449 Loss: 0.37534424662590027\n",
      "Batch: 513 Loss: 0.3917672634124756\n",
      "Batch: 577 Loss: 0.3916876018047333\n",
      "Batch: 641 Loss: 0.46448686718940735\n",
      "Batch: 705 Loss: 0.4124668538570404\n",
      "Batch: 769 Loss: 0.46268901228904724\n",
      "Batch: 833 Loss: 0.33922362327575684\n",
      "Batch: 897 Loss: 0.5678240656852722\n",
      "Batch: 961 Loss: 0.36490753293037415\n",
      "Batch: 1025 Loss: 0.3982889652252197\n",
      "Batch: 1089 Loss: 0.3930507004261017\n",
      "Batch: 1153 Loss: 0.42414018511772156\n",
      "Batch: 1217 Loss: 0.3824300467967987\n",
      "Batch: 1281 Loss: 0.4125401973724365\n",
      "Batch: 1345 Loss: 0.4222775399684906\n",
      "Batch: 1409 Loss: 0.3586999773979187\n",
      "Batch: 1473 Loss: 0.4109969437122345\n",
      "Batch: 1537 Loss: 0.3871828019618988\n",
      "Batch: 1601 Loss: 0.3327927887439728\n",
      "Batch: 1665 Loss: 0.36704179644584656\n",
      "Batch: 1729 Loss: 0.4309841990470886\n",
      "Batch: 1793 Loss: 0.33634474873542786\n",
      "Batch: 1857 Loss: 0.3843507766723633\n",
      "Batch: 1921 Loss: 0.4324530363082886\n",
      "Batch: 1985 Loss: 0.36361774802207947\n",
      "Batch: 2049 Loss: 0.3374289870262146\n",
      "Batch: 2113 Loss: 0.36569514870643616\n",
      "Batch: 2177 Loss: 0.41139280796051025\n",
      "Batch: 2241 Loss: 0.45390400290489197\n",
      "Batch: 2305 Loss: 0.48055750131607056\n",
      "Batch: 2369 Loss: 0.48134559392929077\n",
      "Batch: 2433 Loss: 0.43317359685897827\n",
      "Batch: 2497 Loss: 0.4900999069213867\n",
      "Batch: 2561 Loss: 0.4119921028614044\n",
      "Batch: 2625 Loss: 0.42217394709587097\n",
      "Batch: 2689 Loss: 0.43765032291412354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2753 Loss: 0.36442461609840393\n",
      "Batch: 2817 Loss: 0.5373056530952454\n",
      "Batch: 2881 Loss: 0.4592335522174835\n",
      "Batch: 2945 Loss: 0.3902661204338074\n",
      "Batch: 3009 Loss: 0.5538510084152222\n",
      "Batch: 3073 Loss: 0.4413963854312897\n",
      "Batch: 3137 Loss: 0.39679646492004395\n",
      "Batch: 3201 Loss: 0.3810917139053345\n",
      "Batch: 3265 Loss: 0.36864495277404785\n",
      "Batch: 3329 Loss: 0.40022310614585876\n",
      "Batch: 3393 Loss: 0.4346955716609955\n",
      "Batch: 3457 Loss: 0.40556129813194275\n",
      "Batch: 3521 Loss: 0.30181941390037537\n",
      "Batch: 3585 Loss: 0.2898843586444855\n",
      "Batch: 3649 Loss: 0.4791608154773712\n",
      "Batch: 3713 Loss: 0.3926176428794861\n",
      "Batch: 3777 Loss: 0.41866448521614075\n",
      "Batch: 3841 Loss: 0.40874776244163513\n",
      "Batch: 3905 Loss: 0.39084509015083313\n",
      "Batch: 3969 Loss: 0.5390642881393433\n",
      "Batch: 4033 Loss: 0.40217357873916626\n",
      "Batch: 4097 Loss: 0.39412108063697815\n",
      "Batch: 4161 Loss: 0.45917633175849915\n",
      "Batch: 4225 Loss: 0.33140915632247925\n",
      "Batch: 4289 Loss: 0.3552853465080261\n",
      "Batch: 4353 Loss: 0.48320671916007996\n",
      "Batch: 4417 Loss: 0.6278738975524902\n",
      "Batch: 4481 Loss: 0.6804320812225342\n",
      "Batch: 4545 Loss: 0.545815646648407\n",
      "Batch: 4609 Loss: 0.3696790039539337\n",
      "Batch: 4673 Loss: 0.34847888350486755\n",
      "Batch: 4737 Loss: 0.4489670395851135\n",
      "Batch: 4801 Loss: 0.3683258593082428\n",
      "Batch: 4865 Loss: 0.3668534755706787\n",
      "Batch: 4929 Loss: 0.4319536089897156\n",
      "Batch: 4993 Loss: 0.535559892654419\n",
      "Batch: 5057 Loss: 0.5000050067901611\n",
      "Batch: 5121 Loss: 0.3895106017589569\n",
      "Batch: 5185 Loss: 0.8563729524612427\n",
      "Batch: 5249 Loss: 0.36708351969718933\n",
      "Batch: 5313 Loss: 0.4385681450366974\n",
      "Batch: 5377 Loss: 0.42164790630340576\n",
      "Batch: 5441 Loss: 0.5299170613288879\n",
      "Batch: 5505 Loss: 0.47859251499176025\n",
      "Batch: 5569 Loss: 0.5145106911659241\n",
      "Batch: 5633 Loss: 0.38830214738845825\n",
      "Batch: 5697 Loss: 0.45345428586006165\n",
      "Batch: 5761 Loss: 0.5686123967170715\n",
      "Batch: 5825 Loss: 0.4294423758983612\n",
      "Batch: 5889 Loss: 0.3836241364479065\n",
      "Batch: 5953 Loss: 0.38506266474723816\n",
      "Batch: 6017 Loss: 0.3228377401828766\n",
      "Batch: 6081 Loss: 0.3075106739997864\n",
      "Batch: 6145 Loss: 0.41918784379959106\n",
      "Batch: 6209 Loss: 0.3520200252532959\n",
      "Batch: 6273 Loss: 0.45856013894081116\n",
      "Batch: 6337 Loss: 0.33274951577186584\n",
      "Batch: 6401 Loss: 0.3348485231399536\n",
      "Batch: 6465 Loss: 0.37638261914253235\n",
      "Batch: 6529 Loss: 0.3555286228656769\n",
      "Batch: 6593 Loss: 0.38595619797706604\n",
      "Batch: 6657 Loss: 0.3262092173099518\n",
      "Batch: 6721 Loss: 0.4272056818008423\n",
      "Batch: 6785 Loss: 0.42093193531036377\n",
      "Batch: 6849 Loss: 0.41784194111824036\n",
      "Batch: 6913 Loss: 0.39287784695625305\n",
      "Batch: 6977 Loss: 0.4274379312992096\n",
      "Batch: 7041 Loss: 0.4175802767276764\n",
      "Batch: 7105 Loss: 0.34189513325691223\n",
      "Batch: 7169 Loss: 0.4058685302734375\n",
      "Batch: 7233 Loss: 0.35240471363067627\n",
      "Batch: 7297 Loss: 0.4123215973377228\n",
      "Batch: 7361 Loss: 0.3830031156539917\n",
      "Batch: 7425 Loss: 0.46874114871025085\n",
      "Batch: 7489 Loss: 0.5624085664749146\n",
      "Batch: 7553 Loss: 0.36600083112716675\n",
      "Batch: 7617 Loss: 0.36463525891304016\n",
      "Batch: 7681 Loss: 0.44118350744247437\n",
      "Batch: 7745 Loss: 0.4546297788619995\n",
      "Batch: 7809 Loss: 0.41836634278297424\n",
      "Batch: 7873 Loss: 0.3431496024131775\n",
      "Batch: 7937 Loss: 0.5537054538726807\n",
      "Batch: 8001 Loss: 0.4090867340564728\n",
      "Batch: 8065 Loss: 0.5474979281425476\n",
      "Batch: 8129 Loss: 0.4086800515651703\n",
      "Batch: 8193 Loss: 0.4441400468349457\n",
      "Batch: 8257 Loss: 0.4753294885158539\n",
      "Batch: 8321 Loss: 0.6330721378326416\n",
      "Batch: 8385 Loss: 0.31370121240615845\n",
      "Batch: 8449 Loss: 0.34775203466415405\n",
      "Batch: 8513 Loss: 0.6333797574043274\n",
      "Batch: 8577 Loss: 0.3280543386936188\n",
      "Batch: 8641 Loss: 0.4986184537410736\n",
      "Batch: 8705 Loss: 0.40875044465065\n",
      "Batch: 8769 Loss: 0.4686432182788849\n",
      "Batch: 8833 Loss: 0.5223585367202759\n",
      "Batch: 8897 Loss: 0.7997277975082397\n",
      "Batch: 8961 Loss: 0.3934635519981384\n",
      "Batch: 9025 Loss: 0.3887689709663391\n",
      "Batch: 9089 Loss: 0.3999224603176117\n",
      "Batch: 9153 Loss: 0.46463075280189514\n",
      "Batch: 9217 Loss: 0.4957924783229828\n",
      "Batch: 9281 Loss: 0.4601524770259857\n",
      "Batch: 9345 Loss: 0.3673970103263855\n",
      "Batch: 9409 Loss: 0.48942580819129944\n",
      "Batch: 9473 Loss: 0.5489032864570618\n",
      "Batch: 9537 Loss: 0.46771812438964844\n",
      "Batch: 9601 Loss: 0.35752803087234497\n",
      "Batch: 9665 Loss: 0.3399679660797119\n",
      "Batch: 9729 Loss: 0.4389169216156006\n",
      "Batch: 9793 Loss: 0.3806699812412262\n",
      "Batch: 9857 Loss: 0.4279176592826843\n",
      "Batch: 9921 Loss: 0.3937455415725708\n",
      "Batch: 9985 Loss: 0.44449540972709656\n",
      "Batch: 10049 Loss: 0.5081973075866699\n",
      "Batch: 10113 Loss: 0.39736422896385193\n",
      "Batch: 10177 Loss: 0.4966541826725006\n",
      "Batch: 10241 Loss: 0.3646322190761566\n",
      "Batch: 10305 Loss: 0.43889981508255005\n",
      "Batch: 10369 Loss: 0.4808746576309204\n",
      "Batch: 10433 Loss: 0.4014977216720581\n",
      "Batch: 10497 Loss: 0.39432114362716675\n",
      "Batch: 10561 Loss: 0.36595553159713745\n",
      "Batch: 10625 Loss: 0.4292798936367035\n",
      "Batch: 10689 Loss: 0.4207879304885864\n",
      "Batch: 10753 Loss: 0.35178548097610474\n",
      "Batch: 10817 Loss: 0.3108176589012146\n",
      "Batch: 10881 Loss: 0.36000359058380127\n",
      "Batch: 10945 Loss: 0.342852920293808\n",
      "Batch: 11009 Loss: 0.3984077274799347\n",
      "Batch: 11073 Loss: 0.4453948736190796\n",
      "Batch: 11137 Loss: 0.3620259165763855\n",
      "Batch: 11201 Loss: 0.37038424611091614\n",
      "Batch: 11265 Loss: 0.522283673286438\n",
      "Batch: 11329 Loss: 0.6387646794319153\n",
      "Batch: 11393 Loss: 0.3027280271053314\n",
      "Batch: 11457 Loss: 0.35936787724494934\n",
      "Batch: 11521 Loss: 0.3717806339263916\n",
      "Batch: 11585 Loss: 0.4900891184806824\n",
      "Batch: 11649 Loss: 0.3240378499031067\n",
      "Batch: 11713 Loss: 0.42108720541000366\n",
      "Batch: 11777 Loss: 0.6034390330314636\n",
      "Batch: 11841 Loss: 0.5637140870094299\n",
      "Batch: 11905 Loss: 0.44487297534942627\n",
      "Batch: 11969 Loss: 0.41625797748565674\n",
      "Batch: 12033 Loss: 0.3719019293785095\n",
      "Batch: 12097 Loss: 0.922622561454773\n",
      "Batch: 12161 Loss: 0.5146645307540894\n",
      "Batch: 12225 Loss: 0.29564303159713745\n",
      "Batch: 12289 Loss: 0.31231626868247986\n",
      "Batch: 12353 Loss: 0.4205748736858368\n",
      "Batch: 12417 Loss: 0.355815052986145\n",
      "Batch: 12481 Loss: 0.3883001208305359\n",
      "Batch: 12545 Loss: 0.4771654009819031\n",
      "Batch: 12609 Loss: 0.5139680504798889\n",
      "Batch: 12673 Loss: 0.5428871512413025\n",
      "Batch: 12737 Loss: 0.4505518078804016\n",
      "Batch: 12801 Loss: 0.3737350106239319\n",
      "Batch: 12865 Loss: 0.3166329860687256\n",
      "Batch: 12929 Loss: 0.6466578245162964\n",
      "Epoch: 31\n",
      "Batch: 1 Loss: 0.39918702840805054\n",
      "Batch: 65 Loss: 0.46258798241615295\n",
      "Batch: 129 Loss: 0.39408770203590393\n",
      "Batch: 193 Loss: 0.5881729125976562\n",
      "Batch: 257 Loss: 0.4223657548427582\n",
      "Batch: 321 Loss: 0.4066191017627716\n",
      "Batch: 385 Loss: 0.4097287356853485\n",
      "Batch: 449 Loss: 0.3756497800350189\n",
      "Batch: 513 Loss: 0.3918676972389221\n",
      "Batch: 577 Loss: 0.3909102976322174\n",
      "Batch: 641 Loss: 0.4646274447441101\n",
      "Batch: 705 Loss: 0.4116719365119934\n",
      "Batch: 769 Loss: 0.46145421266555786\n",
      "Batch: 833 Loss: 0.33999738097190857\n",
      "Batch: 897 Loss: 0.5669944882392883\n",
      "Batch: 961 Loss: 0.36316341161727905\n",
      "Batch: 1025 Loss: 0.39810484647750854\n",
      "Batch: 1089 Loss: 0.3934561312198639\n",
      "Batch: 1153 Loss: 0.4253113567829132\n",
      "Batch: 1217 Loss: 0.38251668214797974\n",
      "Batch: 1281 Loss: 0.4138055741786957\n",
      "Batch: 1345 Loss: 0.42299818992614746\n",
      "Batch: 1409 Loss: 0.3590070307254791\n",
      "Batch: 1473 Loss: 0.409523069858551\n",
      "Batch: 1537 Loss: 0.3850986957550049\n",
      "Batch: 1601 Loss: 0.33557063341140747\n",
      "Batch: 1665 Loss: 0.36693623661994934\n",
      "Batch: 1729 Loss: 0.43234166502952576\n",
      "Batch: 1793 Loss: 0.33508312702178955\n",
      "Batch: 1857 Loss: 0.38767242431640625\n",
      "Batch: 1921 Loss: 0.4308479130268097\n",
      "Batch: 1985 Loss: 0.36563143134117126\n",
      "Batch: 2049 Loss: 0.3376534879207611\n",
      "Batch: 2113 Loss: 0.35376888513565063\n",
      "Batch: 2177 Loss: 0.4042495787143707\n",
      "Batch: 2241 Loss: 0.45191702246665955\n",
      "Batch: 2305 Loss: 0.4658738672733307\n",
      "Batch: 2369 Loss: 0.4780707061290741\n",
      "Batch: 2433 Loss: 0.4331246614456177\n",
      "Batch: 2497 Loss: 0.49376919865608215\n",
      "Batch: 2561 Loss: 0.4149296283721924\n",
      "Batch: 2625 Loss: 0.42204850912094116\n",
      "Batch: 2689 Loss: 0.43787068128585815\n",
      "Batch: 2753 Loss: 0.36904558539390564\n",
      "Batch: 2817 Loss: 0.5271238088607788\n",
      "Batch: 2881 Loss: 0.4564874768257141\n",
      "Batch: 2945 Loss: 0.3978232443332672\n",
      "Batch: 3009 Loss: 0.551773190498352\n",
      "Batch: 3073 Loss: 0.4391373097896576\n",
      "Batch: 3137 Loss: 0.3971713185310364\n",
      "Batch: 3201 Loss: 0.381975382566452\n",
      "Batch: 3265 Loss: 0.370051771402359\n",
      "Batch: 3329 Loss: 0.40106889605522156\n",
      "Batch: 3393 Loss: 0.43187081813812256\n",
      "Batch: 3457 Loss: 0.40248316526412964\n",
      "Batch: 3521 Loss: 0.30129149556159973\n",
      "Batch: 3585 Loss: 0.28949597477912903\n",
      "Batch: 3649 Loss: 0.4762744903564453\n",
      "Batch: 3713 Loss: 0.3882812261581421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 3777 Loss: 0.415711909532547\n",
      "Batch: 3841 Loss: 0.40806254744529724\n",
      "Batch: 3905 Loss: 0.3932640254497528\n",
      "Batch: 3969 Loss: 0.5443743467330933\n",
      "Batch: 4033 Loss: 0.4077359139919281\n",
      "Batch: 4097 Loss: 0.39455997943878174\n",
      "Batch: 4161 Loss: 0.45436903834342957\n",
      "Batch: 4225 Loss: 0.33139070868492126\n",
      "Batch: 4289 Loss: 0.359533429145813\n",
      "Batch: 4353 Loss: 0.4930765628814697\n",
      "Batch: 4417 Loss: 0.6505596041679382\n",
      "Batch: 4481 Loss: 0.6872755885124207\n",
      "Batch: 4545 Loss: 0.5555233955383301\n",
      "Batch: 4609 Loss: 0.36861228942871094\n",
      "Batch: 4673 Loss: 0.3481886386871338\n",
      "Batch: 4737 Loss: 0.447762668132782\n",
      "Batch: 4801 Loss: 0.3649146854877472\n",
      "Batch: 4865 Loss: 0.3606012463569641\n",
      "Batch: 4929 Loss: 0.4091077744960785\n",
      "Batch: 4993 Loss: 0.518517017364502\n",
      "Batch: 5057 Loss: 0.5059213042259216\n",
      "Batch: 5121 Loss: 0.3908759653568268\n",
      "Batch: 5185 Loss: 0.8488770127296448\n",
      "Batch: 5249 Loss: 0.36632323265075684\n",
      "Batch: 5313 Loss: 0.4380626082420349\n",
      "Batch: 5377 Loss: 0.4217556118965149\n",
      "Batch: 5441 Loss: 0.5364406704902649\n",
      "Batch: 5505 Loss: 0.47989559173583984\n",
      "Batch: 5569 Loss: 0.5210630297660828\n",
      "Batch: 5633 Loss: 0.38624534010887146\n",
      "Batch: 5697 Loss: 0.45050594210624695\n",
      "Batch: 5761 Loss: 0.5645135641098022\n",
      "Batch: 5825 Loss: 0.4280218482017517\n",
      "Batch: 5889 Loss: 0.38242557644844055\n",
      "Batch: 5953 Loss: 0.3849855959415436\n",
      "Batch: 6017 Loss: 0.32301560044288635\n",
      "Batch: 6081 Loss: 0.3089677393436432\n",
      "Batch: 6145 Loss: 0.4145061671733856\n",
      "Batch: 6209 Loss: 0.3490649461746216\n",
      "Batch: 6273 Loss: 0.45745259523391724\n",
      "Batch: 6337 Loss: 0.3324611485004425\n",
      "Batch: 6401 Loss: 0.3345453441143036\n",
      "Batch: 6465 Loss: 0.37582939863204956\n",
      "Batch: 6529 Loss: 0.35444366931915283\n",
      "Batch: 6593 Loss: 0.39127349853515625\n",
      "Batch: 6657 Loss: 0.31735363602638245\n",
      "Batch: 6721 Loss: 0.43080952763557434\n",
      "Batch: 6785 Loss: 0.41940295696258545\n",
      "Batch: 6849 Loss: 0.4206954836845398\n",
      "Batch: 6913 Loss: 0.39256760478019714\n",
      "Batch: 6977 Loss: 0.42767074704170227\n",
      "Batch: 7041 Loss: 0.41742101311683655\n",
      "Batch: 7105 Loss: 0.3434363901615143\n",
      "Batch: 7169 Loss: 0.40256568789482117\n",
      "Batch: 7233 Loss: 0.3507196307182312\n",
      "Batch: 7297 Loss: 0.41211265325546265\n",
      "Batch: 7361 Loss: 0.3823747932910919\n",
      "Batch: 7425 Loss: 0.46884214878082275\n",
      "Batch: 7489 Loss: 0.5614548921585083\n",
      "Batch: 7553 Loss: 0.36595645546913147\n",
      "Batch: 7617 Loss: 0.36480823159217834\n",
      "Batch: 7681 Loss: 0.44005486369132996\n",
      "Batch: 7745 Loss: 0.4540163576602936\n",
      "Batch: 7809 Loss: 0.4189717769622803\n",
      "Batch: 7873 Loss: 0.33992424607276917\n",
      "Batch: 7937 Loss: 0.551888108253479\n",
      "Batch: 8001 Loss: 0.4064176082611084\n",
      "Batch: 8065 Loss: 0.5478643774986267\n",
      "Batch: 8129 Loss: 0.41884854435920715\n",
      "Batch: 8193 Loss: 0.44222331047058105\n",
      "Batch: 8257 Loss: 0.4695177376270294\n",
      "Batch: 8321 Loss: 0.6356407999992371\n",
      "Batch: 8385 Loss: 0.3126983046531677\n",
      "Batch: 8449 Loss: 0.34731611609458923\n",
      "Batch: 8513 Loss: 0.6331825256347656\n",
      "Batch: 8577 Loss: 0.3283770978450775\n",
      "Batch: 8641 Loss: 0.5001733303070068\n",
      "Batch: 8705 Loss: 0.4047435522079468\n",
      "Batch: 8769 Loss: 0.4674946069717407\n",
      "Batch: 8833 Loss: 0.5206298232078552\n",
      "Batch: 8897 Loss: 0.7933318018913269\n",
      "Batch: 8961 Loss: 0.39260706305503845\n",
      "Batch: 9025 Loss: 0.38840508460998535\n",
      "Batch: 9089 Loss: 0.399295449256897\n",
      "Batch: 9153 Loss: 0.4651901423931122\n",
      "Batch: 9217 Loss: 0.49521464109420776\n",
      "Batch: 9281 Loss: 0.4630279541015625\n",
      "Batch: 9345 Loss: 0.3642474412918091\n",
      "Batch: 9409 Loss: 0.48819777369499207\n",
      "Batch: 9473 Loss: 0.5541408658027649\n",
      "Batch: 9537 Loss: 0.4667186439037323\n",
      "Batch: 9601 Loss: 0.3605883717536926\n",
      "Batch: 9665 Loss: 0.3362075388431549\n",
      "Batch: 9729 Loss: 0.44001296162605286\n",
      "Batch: 9793 Loss: 0.37993693351745605\n",
      "Batch: 9857 Loss: 0.42756524682044983\n",
      "Batch: 9921 Loss: 0.3933047652244568\n",
      "Batch: 9985 Loss: 0.44177377223968506\n",
      "Batch: 10049 Loss: 0.5096514225006104\n",
      "Batch: 10113 Loss: 0.41482219099998474\n",
      "Batch: 10177 Loss: 0.4942722022533417\n",
      "Batch: 10241 Loss: 0.36440417170524597\n",
      "Batch: 10305 Loss: 0.4388054311275482\n",
      "Batch: 10369 Loss: 0.4807737171649933\n",
      "Batch: 10433 Loss: 0.40068304538726807\n",
      "Batch: 10497 Loss: 0.39393049478530884\n",
      "Batch: 10561 Loss: 0.36547189950942993\n",
      "Batch: 10625 Loss: 0.43185514211654663\n",
      "Batch: 10689 Loss: 0.4163656234741211\n",
      "Batch: 10753 Loss: 0.35139915347099304\n",
      "Batch: 10817 Loss: 0.31021344661712646\n",
      "Batch: 10881 Loss: 0.35963279008865356\n",
      "Batch: 10945 Loss: 0.3373301029205322\n",
      "Batch: 11009 Loss: 0.39618372917175293\n",
      "Batch: 11073 Loss: 0.4417736530303955\n",
      "Batch: 11137 Loss: 0.36171653866767883\n",
      "Batch: 11201 Loss: 0.3688882887363434\n",
      "Batch: 11265 Loss: 0.5175893306732178\n",
      "Batch: 11329 Loss: 0.644201934337616\n",
      "Batch: 11393 Loss: 0.29073581099510193\n",
      "Batch: 11457 Loss: 0.3660648465156555\n",
      "Batch: 11521 Loss: 0.3730528950691223\n",
      "Batch: 11585 Loss: 0.4908001124858856\n",
      "Batch: 11649 Loss: 0.3233887553215027\n",
      "Batch: 11713 Loss: 0.4212561249732971\n",
      "Batch: 11777 Loss: 0.6018944382667542\n",
      "Batch: 11841 Loss: 0.5644431114196777\n",
      "Batch: 11905 Loss: 0.4429832696914673\n",
      "Batch: 11969 Loss: 0.4116547405719757\n",
      "Batch: 12033 Loss: 0.37078723311424255\n",
      "Batch: 12097 Loss: 0.9232931733131409\n",
      "Batch: 12161 Loss: 0.5062945485115051\n",
      "Batch: 12225 Loss: 0.29482853412628174\n",
      "Batch: 12289 Loss: 0.3121887445449829\n",
      "Batch: 12353 Loss: 0.41808995604515076\n",
      "Batch: 12417 Loss: 0.35324394702911377\n",
      "Batch: 12481 Loss: 0.38592517375946045\n",
      "Batch: 12545 Loss: 0.47656476497650146\n",
      "Batch: 12609 Loss: 0.5135659575462341\n",
      "Batch: 12673 Loss: 0.5467327833175659\n",
      "Batch: 12737 Loss: 0.451881468296051\n",
      "Batch: 12801 Loss: 0.37116190791130066\n",
      "Batch: 12865 Loss: 0.31518182158470154\n",
      "Batch: 12929 Loss: 0.6472049355506897\n",
      "Epoch: 32\n",
      "Batch: 1 Loss: 0.39933326840400696\n",
      "Batch: 65 Loss: 0.462477445602417\n",
      "Batch: 129 Loss: 0.3939758837223053\n",
      "Batch: 193 Loss: 0.5874577760696411\n",
      "Batch: 257 Loss: 0.42170995473861694\n",
      "Batch: 321 Loss: 0.40672075748443604\n",
      "Batch: 385 Loss: 0.4070018529891968\n",
      "Batch: 449 Loss: 0.3755453824996948\n",
      "Batch: 513 Loss: 0.3909769058227539\n",
      "Batch: 577 Loss: 0.3910672068595886\n",
      "Batch: 641 Loss: 0.46419093012809753\n",
      "Batch: 705 Loss: 0.4107748568058014\n",
      "Batch: 769 Loss: 0.4603467881679535\n",
      "Batch: 833 Loss: 0.33764755725860596\n",
      "Batch: 897 Loss: 0.566818356513977\n",
      "Batch: 961 Loss: 0.3634856641292572\n",
      "Batch: 1025 Loss: 0.3966107666492462\n",
      "Batch: 1089 Loss: 0.392005980014801\n",
      "Batch: 1153 Loss: 0.42362433671951294\n",
      "Batch: 1217 Loss: 0.382821261882782\n",
      "Batch: 1281 Loss: 0.4140247702598572\n",
      "Batch: 1345 Loss: 0.4228355288505554\n",
      "Batch: 1409 Loss: 0.35879582166671753\n",
      "Batch: 1473 Loss: 0.41142064332962036\n",
      "Batch: 1537 Loss: 0.38656383752822876\n",
      "Batch: 1601 Loss: 0.3315442204475403\n",
      "Batch: 1665 Loss: 0.3667561411857605\n",
      "Batch: 1729 Loss: 0.4306655526161194\n",
      "Batch: 1793 Loss: 0.33760401606559753\n",
      "Batch: 1857 Loss: 0.3817872405052185\n",
      "Batch: 1921 Loss: 0.43699929118156433\n",
      "Batch: 1985 Loss: 0.36342817544937134\n",
      "Batch: 2049 Loss: 0.33618059754371643\n",
      "Batch: 2113 Loss: 0.3585197627544403\n",
      "Batch: 2177 Loss: 0.4024992883205414\n",
      "Batch: 2241 Loss: 0.4465447664260864\n",
      "Batch: 2305 Loss: 0.46883872151374817\n",
      "Batch: 2369 Loss: 0.4793841242790222\n",
      "Batch: 2433 Loss: 0.4329114854335785\n",
      "Batch: 2497 Loss: 0.48963236808776855\n",
      "Batch: 2561 Loss: 0.40860119462013245\n",
      "Batch: 2625 Loss: 0.4218701720237732\n",
      "Batch: 2689 Loss: 0.43727874755859375\n",
      "Batch: 2753 Loss: 0.3602774143218994\n",
      "Batch: 2817 Loss: 0.5256385803222656\n",
      "Batch: 2881 Loss: 0.4620557129383087\n",
      "Batch: 2945 Loss: 0.39427945017814636\n",
      "Batch: 3009 Loss: 0.5490831136703491\n",
      "Batch: 3073 Loss: 0.4361155331134796\n",
      "Batch: 3137 Loss: 0.3959786295890808\n",
      "Batch: 3201 Loss: 0.38099783658981323\n",
      "Batch: 3265 Loss: 0.36862969398498535\n",
      "Batch: 3329 Loss: 0.40008631348609924\n",
      "Batch: 3393 Loss: 0.430871844291687\n",
      "Batch: 3457 Loss: 0.39713773131370544\n",
      "Batch: 3521 Loss: 0.3033740222454071\n",
      "Batch: 3585 Loss: 0.2897894084453583\n",
      "Batch: 3649 Loss: 0.4758162200450897\n",
      "Batch: 3713 Loss: 0.3914455771446228\n",
      "Batch: 3777 Loss: 0.4139772653579712\n",
      "Batch: 3841 Loss: 0.40914860367774963\n",
      "Batch: 3905 Loss: 0.3758440315723419\n",
      "Batch: 3969 Loss: 0.5262971520423889\n",
      "Batch: 4033 Loss: 0.3964347243309021\n",
      "Batch: 4097 Loss: 0.3917935788631439\n",
      "Batch: 4161 Loss: 0.4533374011516571\n",
      "Batch: 4225 Loss: 0.3318091928958893\n",
      "Batch: 4289 Loss: 0.35481077432632446\n",
      "Batch: 4353 Loss: 0.4817340075969696\n",
      "Batch: 4417 Loss: 0.6500333547592163\n",
      "Batch: 4481 Loss: 0.6862569451332092\n",
      "Batch: 4545 Loss: 0.5405604243278503\n",
      "Batch: 4609 Loss: 0.3685239851474762\n",
      "Batch: 4673 Loss: 0.3481843173503876\n",
      "Batch: 4737 Loss: 0.4460853040218353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 4801 Loss: 0.3664037883281708\n",
      "Batch: 4865 Loss: 0.3579966723918915\n",
      "Batch: 4929 Loss: 0.40967804193496704\n",
      "Batch: 4993 Loss: 0.5202022790908813\n",
      "Batch: 5057 Loss: 0.5012045502662659\n",
      "Batch: 5121 Loss: 0.39385345578193665\n",
      "Batch: 5185 Loss: 0.8502097725868225\n",
      "Batch: 5249 Loss: 0.36711347103118896\n",
      "Batch: 5313 Loss: 0.4384572207927704\n",
      "Batch: 5377 Loss: 0.4218645989894867\n",
      "Batch: 5441 Loss: 0.5344014167785645\n",
      "Batch: 5505 Loss: 0.4785369038581848\n",
      "Batch: 5569 Loss: 0.5165733098983765\n",
      "Batch: 5633 Loss: 0.38785454630851746\n",
      "Batch: 5697 Loss: 0.45477449893951416\n",
      "Batch: 5761 Loss: 0.5695741772651672\n",
      "Batch: 5825 Loss: 0.4301680326461792\n",
      "Batch: 5889 Loss: 0.3827480673789978\n",
      "Batch: 5953 Loss: 0.3847922086715698\n",
      "Batch: 6017 Loss: 0.3224499523639679\n",
      "Batch: 6081 Loss: 0.3055860102176666\n",
      "Batch: 6145 Loss: 0.41287416219711304\n",
      "Batch: 6209 Loss: 0.34692734479904175\n",
      "Batch: 6273 Loss: 0.4583757519721985\n",
      "Batch: 6337 Loss: 0.3318023979663849\n",
      "Batch: 6401 Loss: 0.3345397710800171\n",
      "Batch: 6465 Loss: 0.37614378333091736\n",
      "Batch: 6529 Loss: 0.3552197217941284\n",
      "Batch: 6593 Loss: 0.3857077956199646\n",
      "Batch: 6657 Loss: 0.3196409046649933\n",
      "Batch: 6721 Loss: 0.42463549971580505\n",
      "Batch: 6785 Loss: 0.4171288311481476\n",
      "Batch: 6849 Loss: 0.41771742701530457\n",
      "Batch: 6913 Loss: 0.3921647369861603\n",
      "Batch: 6977 Loss: 0.42698970437049866\n",
      "Batch: 7041 Loss: 0.4169803857803345\n",
      "Batch: 7105 Loss: 0.33949095010757446\n",
      "Batch: 7169 Loss: 0.40532973408699036\n",
      "Batch: 7233 Loss: 0.3505074977874756\n",
      "Batch: 7297 Loss: 0.4119857847690582\n",
      "Batch: 7361 Loss: 0.38280075788497925\n",
      "Batch: 7425 Loss: 0.4681360721588135\n",
      "Batch: 7489 Loss: 0.5611478686332703\n",
      "Batch: 7553 Loss: 0.3656872808933258\n",
      "Batch: 7617 Loss: 0.36496058106422424\n",
      "Batch: 7681 Loss: 0.4401048719882965\n",
      "Batch: 7745 Loss: 0.45384666323661804\n",
      "Batch: 7809 Loss: 0.4177956283092499\n",
      "Batch: 7873 Loss: 0.3395288288593292\n",
      "Batch: 7937 Loss: 0.5545470714569092\n",
      "Batch: 8001 Loss: 0.41795170307159424\n",
      "Batch: 8065 Loss: 0.546954870223999\n",
      "Batch: 8129 Loss: 0.40317055583000183\n",
      "Batch: 8193 Loss: 0.44031473994255066\n",
      "Batch: 8257 Loss: 0.4629838168621063\n",
      "Batch: 8321 Loss: 0.6323253512382507\n",
      "Batch: 8385 Loss: 0.31541553139686584\n",
      "Batch: 8449 Loss: 0.34732240438461304\n",
      "Batch: 8513 Loss: 0.6326411962509155\n",
      "Batch: 8577 Loss: 0.3268187940120697\n",
      "Batch: 8641 Loss: 0.49687594175338745\n",
      "Batch: 8705 Loss: 0.4041121006011963\n",
      "Batch: 8769 Loss: 0.4676869809627533\n",
      "Batch: 8833 Loss: 0.5209671854972839\n",
      "Batch: 8897 Loss: 0.7922834753990173\n",
      "Batch: 8961 Loss: 0.3925850987434387\n",
      "Batch: 9025 Loss: 0.38824495673179626\n",
      "Batch: 9089 Loss: 0.3993249833583832\n",
      "Batch: 9153 Loss: 0.46339350938796997\n",
      "Batch: 9217 Loss: 0.4958479404449463\n",
      "Batch: 9281 Loss: 0.45954933762550354\n",
      "Batch: 9345 Loss: 0.36219578981399536\n",
      "Batch: 9409 Loss: 0.48527827858924866\n",
      "Batch: 9473 Loss: 0.5466914772987366\n",
      "Batch: 9537 Loss: 0.46730726957321167\n",
      "Batch: 9601 Loss: 0.35948291420936584\n",
      "Batch: 9665 Loss: 0.33589327335357666\n",
      "Batch: 9729 Loss: 0.43763357400894165\n",
      "Batch: 9793 Loss: 0.37961238622665405\n",
      "Batch: 9857 Loss: 0.42751607298851013\n",
      "Batch: 9921 Loss: 0.3928120732307434\n",
      "Batch: 9985 Loss: 0.4398270845413208\n",
      "Batch: 10049 Loss: 0.5061583518981934\n",
      "Batch: 10113 Loss: 0.40767744183540344\n",
      "Batch: 10177 Loss: 0.49584972858428955\n",
      "Batch: 10241 Loss: 0.3642262816429138\n",
      "Batch: 10305 Loss: 0.43843933939933777\n",
      "Batch: 10369 Loss: 0.48037150502204895\n",
      "Batch: 10433 Loss: 0.4006328582763672\n",
      "Batch: 10497 Loss: 0.393741250038147\n",
      "Batch: 10561 Loss: 0.3654734194278717\n",
      "Batch: 10625 Loss: 0.4288574457168579\n",
      "Batch: 10689 Loss: 0.4202408194541931\n",
      "Batch: 10753 Loss: 0.3510994613170624\n",
      "Batch: 10817 Loss: 0.3101482391357422\n",
      "Batch: 10881 Loss: 0.3576801121234894\n",
      "Batch: 10945 Loss: 0.34185028076171875\n",
      "Batch: 11009 Loss: 0.38208118081092834\n",
      "Batch: 11073 Loss: 0.4431896209716797\n",
      "Batch: 11137 Loss: 0.35823753476142883\n",
      "Batch: 11201 Loss: 0.3673391342163086\n",
      "Batch: 11265 Loss: 0.5131049752235413\n",
      "Batch: 11329 Loss: 0.6406413912773132\n",
      "Batch: 11393 Loss: 0.29287007451057434\n",
      "Batch: 11457 Loss: 0.3590119779109955\n",
      "Batch: 11521 Loss: 0.3722669184207916\n",
      "Batch: 11585 Loss: 0.4901256561279297\n",
      "Batch: 11649 Loss: 0.32333293557167053\n",
      "Batch: 11713 Loss: 0.4204561114311218\n",
      "Batch: 11777 Loss: 0.6017887592315674\n",
      "Batch: 11841 Loss: 0.5602636933326721\n",
      "Batch: 11905 Loss: 0.4418478310108185\n",
      "Batch: 11969 Loss: 0.40779024362564087\n",
      "Batch: 12033 Loss: 0.37197548151016235\n",
      "Batch: 12097 Loss: 0.9213271737098694\n",
      "Batch: 12161 Loss: 0.5107074975967407\n",
      "Batch: 12225 Loss: 0.29536929726600647\n",
      "Batch: 12289 Loss: 0.31231603026390076\n",
      "Batch: 12353 Loss: 0.4174223244190216\n",
      "Batch: 12417 Loss: 0.3524954915046692\n",
      "Batch: 12481 Loss: 0.3858089745044708\n",
      "Batch: 12545 Loss: 0.4759713411331177\n",
      "Batch: 12609 Loss: 0.5115829706192017\n",
      "Batch: 12673 Loss: 0.5411654114723206\n",
      "Batch: 12737 Loss: 0.45078277587890625\n",
      "Batch: 12801 Loss: 0.36747628450393677\n",
      "Batch: 12865 Loss: 0.3158699870109558\n",
      "Batch: 12929 Loss: 0.6499649286270142\n",
      "Epoch: 33\n",
      "Batch: 1 Loss: 0.39908283948898315\n",
      "Batch: 65 Loss: 0.4623454809188843\n",
      "Batch: 129 Loss: 0.3942646384239197\n",
      "Batch: 193 Loss: 0.5882813334465027\n",
      "Batch: 257 Loss: 0.4216524064540863\n",
      "Batch: 321 Loss: 0.40577763319015503\n",
      "Batch: 385 Loss: 0.40679967403411865\n",
      "Batch: 449 Loss: 0.3759658634662628\n",
      "Batch: 513 Loss: 0.39139145612716675\n",
      "Batch: 577 Loss: 0.390072762966156\n",
      "Batch: 641 Loss: 0.4638303816318512\n",
      "Batch: 705 Loss: 0.4097709655761719\n",
      "Batch: 769 Loss: 0.4596027433872223\n",
      "Batch: 833 Loss: 0.33862951397895813\n",
      "Batch: 897 Loss: 0.5667770504951477\n",
      "Batch: 961 Loss: 0.36341968178749084\n",
      "Batch: 1025 Loss: 0.3962508738040924\n",
      "Batch: 1089 Loss: 0.39119410514831543\n",
      "Batch: 1153 Loss: 0.4225844442844391\n",
      "Batch: 1217 Loss: 0.3825809955596924\n",
      "Batch: 1281 Loss: 0.41371211409568787\n",
      "Batch: 1345 Loss: 0.42288821935653687\n",
      "Batch: 1409 Loss: 0.3584287464618683\n",
      "Batch: 1473 Loss: 0.41182228922843933\n",
      "Batch: 1537 Loss: 0.38642600178718567\n",
      "Batch: 1601 Loss: 0.33060222864151\n",
      "Batch: 1665 Loss: 0.3664599359035492\n",
      "Batch: 1729 Loss: 0.4301007091999054\n",
      "Batch: 1793 Loss: 0.33492112159729004\n",
      "Batch: 1857 Loss: 0.3836568593978882\n",
      "Batch: 1921 Loss: 0.43116679787635803\n",
      "Batch: 1985 Loss: 0.3621680438518524\n",
      "Batch: 2049 Loss: 0.3375002443790436\n",
      "Batch: 2113 Loss: 0.35388433933258057\n",
      "Batch: 2177 Loss: 0.4020763635635376\n",
      "Batch: 2241 Loss: 0.4454927444458008\n",
      "Batch: 2305 Loss: 0.46573758125305176\n",
      "Batch: 2369 Loss: 0.48470771312713623\n",
      "Batch: 2433 Loss: 0.4342513978481293\n",
      "Batch: 2497 Loss: 0.49097147583961487\n",
      "Batch: 2561 Loss: 0.41720882058143616\n",
      "Batch: 2625 Loss: 0.42130008339881897\n",
      "Batch: 2689 Loss: 0.437128484249115\n",
      "Batch: 2753 Loss: 0.35918697714805603\n",
      "Batch: 2817 Loss: 0.5253630876541138\n",
      "Batch: 2881 Loss: 0.4522281885147095\n",
      "Batch: 2945 Loss: 0.38802599906921387\n",
      "Batch: 3009 Loss: 0.5551960468292236\n",
      "Batch: 3073 Loss: 0.4350685477256775\n",
      "Batch: 3137 Loss: 0.39583322405815125\n",
      "Batch: 3201 Loss: 0.380571186542511\n",
      "Batch: 3265 Loss: 0.36806192994117737\n",
      "Batch: 3329 Loss: 0.39947694540023804\n",
      "Batch: 3393 Loss: 0.4286123216152191\n",
      "Batch: 3457 Loss: 0.39718157052993774\n",
      "Batch: 3521 Loss: 0.30592814087867737\n",
      "Batch: 3585 Loss: 0.29184991121292114\n",
      "Batch: 3649 Loss: 0.4729838967323303\n",
      "Batch: 3713 Loss: 0.3872278928756714\n",
      "Batch: 3777 Loss: 0.41217416524887085\n",
      "Batch: 3841 Loss: 0.4078790545463562\n",
      "Batch: 3905 Loss: 0.3950858414173126\n",
      "Batch: 3969 Loss: 0.5465703010559082\n",
      "Batch: 4033 Loss: 0.4159923195838928\n",
      "Batch: 4097 Loss: 0.40224432945251465\n",
      "Batch: 4161 Loss: 0.4609808623790741\n",
      "Batch: 4225 Loss: 0.33088332414627075\n",
      "Batch: 4289 Loss: 0.35583236813545227\n",
      "Batch: 4353 Loss: 0.48210930824279785\n",
      "Batch: 4417 Loss: 0.6221511363983154\n",
      "Batch: 4481 Loss: 0.6822296977043152\n",
      "Batch: 4545 Loss: 0.5460744500160217\n",
      "Batch: 4609 Loss: 0.3682898283004761\n",
      "Batch: 4673 Loss: 0.3472665250301361\n",
      "Batch: 4737 Loss: 0.44573095440864563\n",
      "Batch: 4801 Loss: 0.36411261558532715\n",
      "Batch: 4865 Loss: 0.3668164312839508\n",
      "Batch: 4929 Loss: 0.4152020514011383\n",
      "Batch: 4993 Loss: 0.5206843018531799\n",
      "Batch: 5057 Loss: 0.4986163079738617\n",
      "Batch: 5121 Loss: 0.39097684621810913\n",
      "Batch: 5185 Loss: 0.8472386598587036\n",
      "Batch: 5249 Loss: 0.3660615086555481\n",
      "Batch: 5313 Loss: 0.43777287006378174\n",
      "Batch: 5377 Loss: 0.42171356081962585\n",
      "Batch: 5441 Loss: 0.5342733263969421\n",
      "Batch: 5505 Loss: 0.4797169268131256\n",
      "Batch: 5569 Loss: 0.5165514349937439\n",
      "Batch: 5633 Loss: 0.38598084449768066\n",
      "Batch: 5697 Loss: 0.45085328817367554\n",
      "Batch: 5761 Loss: 0.5638807415962219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 5825 Loss: 0.42916274070739746\n",
      "Batch: 5889 Loss: 0.38220298290252686\n",
      "Batch: 5953 Loss: 0.3846217691898346\n",
      "Batch: 6017 Loss: 0.32329097390174866\n",
      "Batch: 6081 Loss: 0.3087473213672638\n",
      "Batch: 6145 Loss: 0.41144153475761414\n",
      "Batch: 6209 Loss: 0.34622782468795776\n",
      "Batch: 6273 Loss: 0.4564521312713623\n",
      "Batch: 6337 Loss: 0.3319513201713562\n",
      "Batch: 6401 Loss: 0.33416247367858887\n",
      "Batch: 6465 Loss: 0.37584078311920166\n",
      "Batch: 6529 Loss: 0.3542473018169403\n",
      "Batch: 6593 Loss: 0.38053372502326965\n",
      "Batch: 6657 Loss: 0.3145613968372345\n",
      "Batch: 6721 Loss: 0.42292845249176025\n",
      "Batch: 6785 Loss: 0.41767004132270813\n",
      "Batch: 6849 Loss: 0.4159452021121979\n",
      "Batch: 6913 Loss: 0.3918667137622833\n",
      "Batch: 6977 Loss: 0.4271831512451172\n",
      "Batch: 7041 Loss: 0.41669341921806335\n",
      "Batch: 7105 Loss: 0.33780086040496826\n",
      "Batch: 7169 Loss: 0.39834657311439514\n",
      "Batch: 7233 Loss: 0.35158371925354004\n",
      "Batch: 7297 Loss: 0.41199997067451477\n",
      "Batch: 7361 Loss: 0.3826523423194885\n",
      "Batch: 7425 Loss: 0.467239111661911\n",
      "Batch: 7489 Loss: 0.5616862177848816\n",
      "Batch: 7553 Loss: 0.3655199408531189\n",
      "Batch: 7617 Loss: 0.36432555317878723\n",
      "Batch: 7681 Loss: 0.4404476583003998\n",
      "Batch: 7745 Loss: 0.4540758728981018\n",
      "Batch: 7809 Loss: 0.4178808331489563\n",
      "Batch: 7873 Loss: 0.3398691415786743\n",
      "Batch: 7937 Loss: 0.5554062724113464\n",
      "Batch: 8001 Loss: 0.40024885535240173\n",
      "Batch: 8065 Loss: 0.5417473316192627\n",
      "Batch: 8129 Loss: 0.4025939702987671\n",
      "Batch: 8193 Loss: 0.4443715512752533\n",
      "Batch: 8257 Loss: 0.46682316064834595\n",
      "Batch: 8321 Loss: 0.6339601278305054\n",
      "Batch: 8385 Loss: 0.31228259205818176\n",
      "Batch: 8449 Loss: 0.3472746014595032\n",
      "Batch: 8513 Loss: 0.6329841613769531\n",
      "Batch: 8577 Loss: 0.3266230523586273\n",
      "Batch: 8641 Loss: 0.49563339352607727\n",
      "Batch: 8705 Loss: 0.40304842591285706\n",
      "Batch: 8769 Loss: 0.466259628534317\n",
      "Batch: 8833 Loss: 0.5207632780075073\n",
      "Batch: 8897 Loss: 0.7924686670303345\n",
      "Batch: 8961 Loss: 0.3956117331981659\n",
      "Batch: 9025 Loss: 0.38787853717803955\n",
      "Batch: 9089 Loss: 0.3990384340286255\n",
      "Batch: 9153 Loss: 0.46194931864738464\n",
      "Batch: 9217 Loss: 0.49955517053604126\n",
      "Batch: 9281 Loss: 0.4524464011192322\n",
      "Batch: 9345 Loss: 0.36066168546676636\n",
      "Batch: 9409 Loss: 0.48640817403793335\n",
      "Batch: 9473 Loss: 0.5457686185836792\n",
      "Batch: 9537 Loss: 0.46801134943962097\n",
      "Batch: 9601 Loss: 0.36117681860923767\n",
      "Batch: 9665 Loss: 0.3361594080924988\n",
      "Batch: 9729 Loss: 0.44069904088974\n",
      "Batch: 9793 Loss: 0.40576979517936707\n",
      "Batch: 9857 Loss: 0.4515097141265869\n",
      "Batch: 9921 Loss: 0.393303245306015\n",
      "Batch: 9985 Loss: 0.4385150969028473\n",
      "Batch: 10049 Loss: 0.5029797554016113\n",
      "Batch: 10113 Loss: 0.39362606406211853\n",
      "Batch: 10177 Loss: 0.4954988360404968\n",
      "Batch: 10241 Loss: 0.363745778799057\n",
      "Batch: 10305 Loss: 0.4383564591407776\n",
      "Batch: 10369 Loss: 0.4805348813533783\n",
      "Batch: 10433 Loss: 0.400320827960968\n",
      "Batch: 10497 Loss: 0.3938887417316437\n",
      "Batch: 10561 Loss: 0.3651844561100006\n",
      "Batch: 10625 Loss: 0.42786943912506104\n",
      "Batch: 10689 Loss: 0.4084637463092804\n",
      "Batch: 10753 Loss: 0.3510162830352783\n",
      "Batch: 10817 Loss: 0.3099035620689392\n",
      "Batch: 10881 Loss: 0.3570079207420349\n",
      "Batch: 10945 Loss: 0.3446609079837799\n",
      "Batch: 11009 Loss: 0.3857679069042206\n",
      "Batch: 11073 Loss: 0.4433920085430145\n",
      "Batch: 11137 Loss: 0.3663472533226013\n",
      "Batch: 11201 Loss: 0.3669469952583313\n",
      "Batch: 11265 Loss: 0.5128138661384583\n",
      "Batch: 11329 Loss: 0.6371725797653198\n",
      "Batch: 11393 Loss: 0.28856509923934937\n",
      "Batch: 11457 Loss: 0.36107420921325684\n",
      "Batch: 11521 Loss: 0.37219321727752686\n",
      "Batch: 11585 Loss: 0.4906284511089325\n",
      "Batch: 11649 Loss: 0.3228393495082855\n",
      "Batch: 11713 Loss: 0.41945478320121765\n",
      "Batch: 11777 Loss: 0.6009796261787415\n",
      "Batch: 11841 Loss: 0.5602956414222717\n",
      "Batch: 11905 Loss: 0.4407525360584259\n",
      "Batch: 11969 Loss: 0.40855368971824646\n",
      "Batch: 12033 Loss: 0.3718109130859375\n",
      "Batch: 12097 Loss: 0.9191616177558899\n",
      "Batch: 12161 Loss: 0.5071927905082703\n",
      "Batch: 12225 Loss: 0.29468056559562683\n",
      "Batch: 12289 Loss: 0.30875298380851746\n",
      "Batch: 12353 Loss: 0.4156988263130188\n",
      "Batch: 12417 Loss: 0.35580602288246155\n",
      "Batch: 12481 Loss: 0.3910388946533203\n",
      "Batch: 12545 Loss: 0.476037859916687\n",
      "Batch: 12609 Loss: 0.5132492780685425\n",
      "Batch: 12673 Loss: 0.5398175120353699\n",
      "Batch: 12737 Loss: 0.45021501183509827\n",
      "Batch: 12801 Loss: 0.36874905228614807\n",
      "Batch: 12865 Loss: 0.31436944007873535\n",
      "Batch: 12929 Loss: 0.6456727385520935\n",
      "Epoch: 34\n",
      "Batch: 1 Loss: 0.39909204840660095\n",
      "Batch: 65 Loss: 0.46207037568092346\n",
      "Batch: 129 Loss: 0.3937661945819855\n",
      "Batch: 193 Loss: 0.5878612399101257\n",
      "Batch: 257 Loss: 0.4210556149482727\n",
      "Batch: 321 Loss: 0.40540656447410583\n",
      "Batch: 385 Loss: 0.40630677342414856\n",
      "Batch: 449 Loss: 0.37597915530204773\n",
      "Batch: 513 Loss: 0.39127078652381897\n",
      "Batch: 577 Loss: 0.3898874819278717\n",
      "Batch: 641 Loss: 0.46391522884368896\n",
      "Batch: 705 Loss: 0.41031426191329956\n",
      "Batch: 769 Loss: 0.4598986804485321\n",
      "Batch: 833 Loss: 0.33854129910469055\n",
      "Batch: 897 Loss: 0.5666214823722839\n",
      "Batch: 961 Loss: 0.36316001415252686\n",
      "Batch: 1025 Loss: 0.3958686590194702\n",
      "Batch: 1089 Loss: 0.3914797008037567\n",
      "Batch: 1153 Loss: 0.42290231585502625\n",
      "Batch: 1217 Loss: 0.38261622190475464\n",
      "Batch: 1281 Loss: 0.4135147035121918\n",
      "Batch: 1345 Loss: 0.4225688874721527\n",
      "Batch: 1409 Loss: 0.3580077886581421\n",
      "Batch: 1473 Loss: 0.41207560896873474\n",
      "Batch: 1537 Loss: 0.38590964674949646\n",
      "Batch: 1601 Loss: 0.33187970519065857\n",
      "Batch: 1665 Loss: 0.3750201463699341\n",
      "Batch: 1729 Loss: 0.43191415071487427\n",
      "Batch: 1793 Loss: 0.3349527418613434\n",
      "Batch: 1857 Loss: 0.3797904849052429\n",
      "Batch: 1921 Loss: 0.4258372485637665\n",
      "Batch: 1985 Loss: 0.3670703172683716\n",
      "Batch: 2049 Loss: 0.3348458707332611\n",
      "Batch: 2113 Loss: 0.3573252558708191\n",
      "Batch: 2177 Loss: 0.39976316690444946\n",
      "Batch: 2241 Loss: 0.44521018862724304\n",
      "Batch: 2305 Loss: 0.4577438533306122\n",
      "Batch: 2369 Loss: 0.4812236428260803\n",
      "Batch: 2433 Loss: 0.4331182539463043\n",
      "Batch: 2497 Loss: 0.4902454614639282\n",
      "Batch: 2561 Loss: 0.40900900959968567\n",
      "Batch: 2625 Loss: 0.42116275429725647\n",
      "Batch: 2689 Loss: 0.4365687072277069\n",
      "Batch: 2753 Loss: 0.37750622630119324\n",
      "Batch: 2817 Loss: 0.5366759896278381\n",
      "Batch: 2881 Loss: 0.46147987246513367\n",
      "Batch: 2945 Loss: 0.40250661969184875\n",
      "Batch: 3009 Loss: 0.5472404360771179\n",
      "Batch: 3073 Loss: 0.4342121481895447\n",
      "Batch: 3137 Loss: 0.3995468318462372\n",
      "Batch: 3201 Loss: 0.38095715641975403\n",
      "Batch: 3265 Loss: 0.3681073486804962\n",
      "Batch: 3329 Loss: 0.3998229205608368\n",
      "Batch: 3393 Loss: 0.4317391514778137\n",
      "Batch: 3457 Loss: 0.39253368973731995\n",
      "Batch: 3521 Loss: 0.3007427752017975\n",
      "Batch: 3585 Loss: 0.2897270619869232\n",
      "Batch: 3649 Loss: 0.4721842110157013\n",
      "Batch: 3713 Loss: 0.3874048590660095\n",
      "Batch: 3777 Loss: 0.41129031777381897\n",
      "Batch: 3841 Loss: 0.4084111154079437\n",
      "Batch: 3905 Loss: 0.3759833872318268\n",
      "Batch: 3969 Loss: 0.5271874666213989\n",
      "Batch: 4033 Loss: 0.3957820534706116\n",
      "Batch: 4097 Loss: 0.38873112201690674\n",
      "Batch: 4161 Loss: 0.4537767171859741\n",
      "Batch: 4225 Loss: 0.33114147186279297\n",
      "Batch: 4289 Loss: 0.35445311665534973\n",
      "Batch: 4353 Loss: 0.48031821846961975\n",
      "Batch: 4417 Loss: 0.6205283403396606\n",
      "Batch: 4481 Loss: 0.6876993775367737\n",
      "Batch: 4545 Loss: 0.5411054491996765\n",
      "Batch: 4609 Loss: 0.3690189719200134\n",
      "Batch: 4673 Loss: 0.34742072224617004\n",
      "Batch: 4737 Loss: 0.44522032141685486\n",
      "Batch: 4801 Loss: 0.36307719349861145\n",
      "Batch: 4865 Loss: 0.35568544268608093\n",
      "Batch: 4929 Loss: 0.40664637088775635\n",
      "Batch: 4993 Loss: 0.5180324912071228\n",
      "Batch: 5057 Loss: 0.4986242353916168\n",
      "Batch: 5121 Loss: 0.39449089765548706\n",
      "Batch: 5185 Loss: 0.8507471680641174\n",
      "Batch: 5249 Loss: 0.365762859582901\n",
      "Batch: 5313 Loss: 0.4370776414871216\n",
      "Batch: 5377 Loss: 0.4225122034549713\n",
      "Batch: 5441 Loss: 0.5336219072341919\n",
      "Batch: 5505 Loss: 0.4784586727619171\n",
      "Batch: 5569 Loss: 0.5143574476242065\n",
      "Batch: 5633 Loss: 0.3908773362636566\n",
      "Batch: 5697 Loss: 0.45502910017967224\n",
      "Batch: 5761 Loss: 0.5693653225898743\n",
      "Batch: 5825 Loss: 0.42702165246009827\n",
      "Batch: 5889 Loss: 0.3826484978199005\n",
      "Batch: 5953 Loss: 0.38449257612228394\n",
      "Batch: 6017 Loss: 0.3226109743118286\n",
      "Batch: 6081 Loss: 0.3070143163204193\n",
      "Batch: 6145 Loss: 0.41763564944267273\n",
      "Batch: 6209 Loss: 0.3472242057323456\n",
      "Batch: 6273 Loss: 0.45773181319236755\n",
      "Batch: 6337 Loss: 0.33189651370048523\n",
      "Batch: 6401 Loss: 0.3341982066631317\n",
      "Batch: 6465 Loss: 0.37542885541915894\n",
      "Batch: 6529 Loss: 0.35359862446784973\n",
      "Batch: 6593 Loss: 0.38037052750587463\n",
      "Batch: 6657 Loss: 0.3157775402069092\n",
      "Batch: 6721 Loss: 0.42157837748527527\n",
      "Batch: 6785 Loss: 0.41724395751953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 6849 Loss: 0.4161311089992523\n",
      "Batch: 6913 Loss: 0.39207613468170166\n",
      "Batch: 6977 Loss: 0.426819771528244\n",
      "Batch: 7041 Loss: 0.41669386625289917\n",
      "Batch: 7105 Loss: 0.3382164239883423\n",
      "Batch: 7169 Loss: 0.40407660603523254\n",
      "Batch: 7233 Loss: 0.35384804010391235\n",
      "Batch: 7297 Loss: 0.41195887327194214\n",
      "Batch: 7361 Loss: 0.3826940059661865\n",
      "Batch: 7425 Loss: 0.4679228961467743\n",
      "Batch: 7489 Loss: 0.5608019828796387\n",
      "Batch: 7553 Loss: 0.36535021662712097\n",
      "Batch: 7617 Loss: 0.3644610345363617\n",
      "Batch: 7681 Loss: 0.4397272765636444\n",
      "Batch: 7745 Loss: 0.4537450075149536\n",
      "Batch: 7809 Loss: 0.416034460067749\n",
      "Batch: 7873 Loss: 0.3348258137702942\n",
      "Batch: 7937 Loss: 0.5439749360084534\n",
      "Batch: 8001 Loss: 0.3995628356933594\n",
      "Batch: 8065 Loss: 0.5415658354759216\n",
      "Batch: 8129 Loss: 0.40008023381233215\n",
      "Batch: 8193 Loss: 0.43907085061073303\n",
      "Batch: 8257 Loss: 0.46381059288978577\n",
      "Batch: 8321 Loss: 0.631066083908081\n",
      "Batch: 8385 Loss: 0.3124450147151947\n",
      "Batch: 8449 Loss: 0.3467821776866913\n",
      "Batch: 8513 Loss: 0.6328287720680237\n",
      "Batch: 8577 Loss: 0.3272522985935211\n",
      "Batch: 8641 Loss: 0.49411147832870483\n",
      "Batch: 8705 Loss: 0.40308600664138794\n",
      "Batch: 8769 Loss: 0.4666978120803833\n",
      "Batch: 8833 Loss: 0.5280663967132568\n",
      "Batch: 8897 Loss: 0.7998884916305542\n",
      "Batch: 8961 Loss: 0.3920621871948242\n",
      "Batch: 9025 Loss: 0.38781946897506714\n",
      "Batch: 9089 Loss: 0.39878976345062256\n",
      "Batch: 9153 Loss: 0.4652545154094696\n",
      "Batch: 9217 Loss: 0.4927237331867218\n",
      "Batch: 9281 Loss: 0.45777907967567444\n",
      "Batch: 9345 Loss: 0.36438918113708496\n",
      "Batch: 9409 Loss: 0.4880831241607666\n",
      "Batch: 9473 Loss: 0.5472608208656311\n",
      "Batch: 9537 Loss: 0.46581631898880005\n",
      "Batch: 9601 Loss: 0.35943910479545593\n",
      "Batch: 9665 Loss: 0.33583691716194153\n",
      "Batch: 9729 Loss: 0.43621164560317993\n",
      "Batch: 9793 Loss: 0.3785582482814789\n",
      "Batch: 9857 Loss: 0.4275449216365814\n",
      "Batch: 9921 Loss: 0.3927915394306183\n",
      "Batch: 9985 Loss: 0.4383336901664734\n",
      "Batch: 10049 Loss: 0.5016096234321594\n",
      "Batch: 10113 Loss: 0.392735093832016\n",
      "Batch: 10177 Loss: 0.4951576888561249\n",
      "Batch: 10241 Loss: 0.3633791208267212\n",
      "Batch: 10305 Loss: 0.43817630410194397\n",
      "Batch: 10369 Loss: 0.4802071750164032\n",
      "Batch: 10433 Loss: 0.40008312463760376\n",
      "Batch: 10497 Loss: 0.39326977729797363\n",
      "Batch: 10561 Loss: 0.36517027020454407\n",
      "Batch: 10625 Loss: 0.427291601896286\n",
      "Batch: 10689 Loss: 0.41145631670951843\n",
      "Batch: 10753 Loss: 0.3507160544395447\n",
      "Batch: 10817 Loss: 0.30976277589797974\n",
      "Batch: 10881 Loss: 0.3625309467315674\n",
      "Batch: 10945 Loss: 0.3329015374183655\n",
      "Batch: 11009 Loss: 0.3819340467453003\n",
      "Batch: 11073 Loss: 0.4374697804450989\n",
      "Batch: 11137 Loss: 0.35437077283859253\n",
      "Batch: 11201 Loss: 0.3749474287033081\n",
      "Batch: 11265 Loss: 0.5172152519226074\n",
      "Batch: 11329 Loss: 0.6377833485603333\n",
      "Batch: 11393 Loss: 0.28149837255477905\n",
      "Batch: 11457 Loss: 0.3596545159816742\n",
      "Batch: 11521 Loss: 0.3713604807853699\n",
      "Batch: 11585 Loss: 0.4909133315086365\n",
      "Batch: 11649 Loss: 0.3227185904979706\n",
      "Batch: 11713 Loss: 0.4174756109714508\n",
      "Batch: 11777 Loss: 0.6006971597671509\n",
      "Batch: 11841 Loss: 0.5598687529563904\n",
      "Batch: 11905 Loss: 0.4398212730884552\n",
      "Batch: 11969 Loss: 0.40424397587776184\n",
      "Batch: 12033 Loss: 0.3710620701313019\n",
      "Batch: 12097 Loss: 0.9189188480377197\n",
      "Batch: 12161 Loss: 0.5078625082969666\n",
      "Batch: 12225 Loss: 0.2950429618358612\n",
      "Batch: 12289 Loss: 0.3090986907482147\n",
      "Batch: 12353 Loss: 0.41873469948768616\n",
      "Batch: 12417 Loss: 0.34925419092178345\n",
      "Batch: 12481 Loss: 0.3833596408367157\n",
      "Batch: 12545 Loss: 0.4765123724937439\n",
      "Batch: 12609 Loss: 0.5130299925804138\n",
      "Batch: 12673 Loss: 0.5456163287162781\n",
      "Batch: 12737 Loss: 0.45039674639701843\n",
      "Batch: 12801 Loss: 0.3688141703605652\n",
      "Batch: 12865 Loss: 0.3138548731803894\n",
      "Batch: 12929 Loss: 0.6446607112884521\n",
      "Epoch: 35\n",
      "Batch: 1 Loss: 0.39870861172676086\n",
      "Batch: 65 Loss: 0.46118679642677307\n",
      "Batch: 129 Loss: 0.3923906981945038\n",
      "Batch: 193 Loss: 0.5854710340499878\n",
      "Batch: 257 Loss: 0.41945624351501465\n",
      "Batch: 321 Loss: 0.404645174741745\n",
      "Batch: 385 Loss: 0.4057256877422333\n",
      "Batch: 449 Loss: 0.3759462833404541\n",
      "Batch: 513 Loss: 0.39087358117103577\n",
      "Batch: 577 Loss: 0.3891395926475525\n",
      "Batch: 641 Loss: 0.464459091424942\n",
      "Batch: 705 Loss: 0.4100872576236725\n",
      "Batch: 769 Loss: 0.4593912661075592\n",
      "Batch: 833 Loss: 0.3379562795162201\n",
      "Batch: 897 Loss: 0.5661207437515259\n",
      "Batch: 961 Loss: 0.3604517877101898\n",
      "Batch: 1025 Loss: 0.3972526490688324\n",
      "Batch: 1089 Loss: 0.39086097478866577\n",
      "Batch: 1153 Loss: 0.4219790995121002\n",
      "Batch: 1217 Loss: 0.3822174072265625\n",
      "Batch: 1281 Loss: 0.41405048966407776\n",
      "Batch: 1345 Loss: 0.42276468873023987\n",
      "Batch: 1409 Loss: 0.3576773703098297\n",
      "Batch: 1473 Loss: 0.4118703007698059\n",
      "Batch: 1537 Loss: 0.38572195172309875\n",
      "Batch: 1601 Loss: 0.33063238859176636\n",
      "Batch: 1665 Loss: 0.3663792312145233\n",
      "Batch: 1729 Loss: 0.43144530057907104\n",
      "Batch: 1793 Loss: 0.33498790860176086\n",
      "Batch: 1857 Loss: 0.3829338848590851\n",
      "Batch: 1921 Loss: 0.4333825409412384\n",
      "Batch: 1985 Loss: 0.36667823791503906\n",
      "Batch: 2049 Loss: 0.3541085422039032\n",
      "Batch: 2113 Loss: 0.3643628656864166\n",
      "Batch: 2177 Loss: 0.4009329378604889\n",
      "Batch: 2241 Loss: 0.442158043384552\n",
      "Batch: 2305 Loss: 0.48405706882476807\n",
      "Batch: 2369 Loss: 0.4742879867553711\n",
      "Batch: 2433 Loss: 0.43035101890563965\n",
      "Batch: 2497 Loss: 0.4886740446090698\n",
      "Batch: 2561 Loss: 0.4071204364299774\n",
      "Batch: 2625 Loss: 0.42086488008499146\n",
      "Batch: 2689 Loss: 0.4364979565143585\n",
      "Batch: 2753 Loss: 0.3613757789134979\n",
      "Batch: 2817 Loss: 0.526343584060669\n",
      "Batch: 2881 Loss: 0.4506065547466278\n",
      "Batch: 2945 Loss: 0.3906109035015106\n",
      "Batch: 3009 Loss: 0.5467110276222229\n",
      "Batch: 3073 Loss: 0.43269163370132446\n",
      "Batch: 3137 Loss: 0.39588505029678345\n",
      "Batch: 3201 Loss: 0.38007086515426636\n",
      "Batch: 3265 Loss: 0.3676542341709137\n",
      "Batch: 3329 Loss: 0.39954832196235657\n",
      "Batch: 3393 Loss: 0.4272565543651581\n",
      "Batch: 3457 Loss: 0.39243343472480774\n",
      "Batch: 3521 Loss: 0.30040860176086426\n",
      "Batch: 3585 Loss: 0.29245802760124207\n",
      "Batch: 3649 Loss: 0.46989914774894714\n",
      "Batch: 3713 Loss: 0.38538146018981934\n",
      "Batch: 3777 Loss: 0.41171470284461975\n",
      "Batch: 3841 Loss: 0.4107491374015808\n",
      "Batch: 3905 Loss: 0.3744523227214813\n",
      "Batch: 3969 Loss: 0.5237810611724854\n",
      "Batch: 4033 Loss: 0.3924368619918823\n",
      "Batch: 4097 Loss: 0.3921237587928772\n",
      "Batch: 4161 Loss: 0.45234939455986023\n",
      "Batch: 4225 Loss: 0.33134546875953674\n",
      "Batch: 4289 Loss: 0.35590726137161255\n",
      "Batch: 4353 Loss: 0.48091819882392883\n",
      "Batch: 4417 Loss: 0.6179810762405396\n",
      "Batch: 4481 Loss: 0.6655025482177734\n",
      "Batch: 4545 Loss: 0.5391862988471985\n",
      "Batch: 4609 Loss: 0.3684779703617096\n",
      "Batch: 4673 Loss: 0.3474356532096863\n",
      "Batch: 4737 Loss: 0.4494980275630951\n",
      "Batch: 4801 Loss: 0.36607858538627625\n",
      "Batch: 4865 Loss: 0.35460391640663147\n",
      "Batch: 4929 Loss: 0.4043182134628296\n",
      "Batch: 4993 Loss: 0.5135313868522644\n",
      "Batch: 5057 Loss: 0.49572163820266724\n",
      "Batch: 5121 Loss: 0.3881811797618866\n",
      "Batch: 5185 Loss: 0.8452475666999817\n",
      "Batch: 5249 Loss: 0.3654085695743561\n",
      "Batch: 5313 Loss: 0.4373416304588318\n",
      "Batch: 5377 Loss: 0.42214885354042053\n",
      "Batch: 5441 Loss: 0.5351752042770386\n",
      "Batch: 5505 Loss: 0.48266535997390747\n",
      "Batch: 5569 Loss: 0.5170520544052124\n",
      "Batch: 5633 Loss: 0.3871228098869324\n",
      "Batch: 5697 Loss: 0.44871705770492554\n",
      "Batch: 5761 Loss: 0.5518990755081177\n",
      "Batch: 5825 Loss: 0.42772945761680603\n",
      "Batch: 5889 Loss: 0.3812374472618103\n",
      "Batch: 5953 Loss: 0.3846590518951416\n",
      "Batch: 6017 Loss: 0.321633517742157\n",
      "Batch: 6081 Loss: 0.3025178015232086\n",
      "Batch: 6145 Loss: 0.4103441834449768\n",
      "Batch: 6209 Loss: 0.34315118193626404\n",
      "Batch: 6273 Loss: 0.45645830035209656\n",
      "Batch: 6337 Loss: 0.33136820793151855\n",
      "Batch: 6401 Loss: 0.33384695649147034\n",
      "Batch: 6465 Loss: 0.375321626663208\n",
      "Batch: 6529 Loss: 0.3539429306983948\n",
      "Batch: 6593 Loss: 0.38709786534309387\n",
      "Batch: 6657 Loss: 0.3140082061290741\n",
      "Batch: 6721 Loss: 0.424367755651474\n",
      "Batch: 6785 Loss: 0.41348081827163696\n",
      "Batch: 6849 Loss: 0.4127783477306366\n",
      "Batch: 6913 Loss: 0.39139464497566223\n",
      "Batch: 6977 Loss: 0.42606469988822937\n",
      "Batch: 7041 Loss: 0.417906790971756\n",
      "Batch: 7105 Loss: 0.3389904797077179\n",
      "Batch: 7169 Loss: 0.3970060646533966\n",
      "Batch: 7233 Loss: 0.3512532711029053\n",
      "Batch: 7297 Loss: 0.41131728887557983\n",
      "Batch: 7361 Loss: 0.38258159160614014\n",
      "Batch: 7425 Loss: 0.4670535922050476\n",
      "Batch: 7489 Loss: 0.563452422618866\n",
      "Batch: 7553 Loss: 0.36528465151786804\n",
      "Batch: 7617 Loss: 0.36475926637649536\n",
      "Batch: 7681 Loss: 0.4392438232898712\n",
      "Batch: 7745 Loss: 0.45340976119041443\n",
      "Batch: 7809 Loss: 0.41570284962654114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 7873 Loss: 0.3338116705417633\n",
      "Batch: 7937 Loss: 0.5416067838668823\n",
      "Batch: 8001 Loss: 0.39670655131340027\n",
      "Batch: 8065 Loss: 0.5390485525131226\n",
      "Batch: 8129 Loss: 0.3988547921180725\n",
      "Batch: 8193 Loss: 0.4386262595653534\n",
      "Batch: 8257 Loss: 0.4619419276714325\n",
      "Batch: 8321 Loss: 0.6302546858787537\n",
      "Batch: 8385 Loss: 0.3117509186267853\n",
      "Batch: 8449 Loss: 0.3466438055038452\n",
      "Batch: 8513 Loss: 0.6329302191734314\n",
      "Batch: 8577 Loss: 0.32691481709480286\n",
      "Batch: 8641 Loss: 0.4937458038330078\n",
      "Batch: 8705 Loss: 0.397802472114563\n",
      "Batch: 8769 Loss: 0.46339380741119385\n",
      "Batch: 8833 Loss: 0.5237935185432434\n",
      "Batch: 8897 Loss: 0.7976656556129456\n",
      "Batch: 8961 Loss: 0.39358964562416077\n",
      "Batch: 9025 Loss: 0.38794419169425964\n",
      "Batch: 9089 Loss: 0.3985653817653656\n",
      "Batch: 9153 Loss: 0.46241915225982666\n",
      "Batch: 9217 Loss: 0.49713006615638733\n",
      "Batch: 9281 Loss: 0.4572293162345886\n",
      "Batch: 9345 Loss: 0.3576703369617462\n",
      "Batch: 9409 Loss: 0.484185129404068\n",
      "Batch: 9473 Loss: 0.5442337393760681\n",
      "Batch: 9537 Loss: 0.46482688188552856\n",
      "Batch: 9601 Loss: 0.35908687114715576\n",
      "Batch: 9665 Loss: 0.33526328206062317\n",
      "Batch: 9729 Loss: 0.43591955304145813\n",
      "Batch: 9793 Loss: 0.37813088297843933\n",
      "Batch: 9857 Loss: 0.4274390935897827\n",
      "Batch: 9921 Loss: 0.39263540506362915\n",
      "Batch: 9985 Loss: 0.43680059909820557\n",
      "Batch: 10049 Loss: 0.5016354322433472\n",
      "Batch: 10113 Loss: 0.40906059741973877\n",
      "Batch: 10177 Loss: 0.4970664381980896\n",
      "Batch: 10241 Loss: 0.36362820863723755\n",
      "Batch: 10305 Loss: 0.437801718711853\n",
      "Batch: 10369 Loss: 0.4801676273345947\n",
      "Batch: 10433 Loss: 0.40004459023475647\n",
      "Batch: 10497 Loss: 0.39289915561676025\n",
      "Batch: 10561 Loss: 0.365158349275589\n",
      "Batch: 10625 Loss: 0.4280923902988434\n",
      "Batch: 10689 Loss: 0.4079722762107849\n",
      "Batch: 10753 Loss: 0.3505423665046692\n",
      "Batch: 10817 Loss: 0.3095875084400177\n",
      "Batch: 10881 Loss: 0.35608363151550293\n",
      "Batch: 10945 Loss: 0.3411804735660553\n",
      "Batch: 11009 Loss: 0.3920065462589264\n",
      "Batch: 11073 Loss: 0.44464823603630066\n",
      "Batch: 11137 Loss: 0.3617718517780304\n",
      "Batch: 11201 Loss: 0.3652566373348236\n",
      "Batch: 11265 Loss: 0.5155675411224365\n",
      "Batch: 11329 Loss: 0.6344727277755737\n",
      "Batch: 11393 Loss: 0.2816501557826996\n",
      "Batch: 11457 Loss: 0.36152273416519165\n",
      "Batch: 11521 Loss: 0.3709835410118103\n",
      "Batch: 11585 Loss: 0.4896661043167114\n",
      "Batch: 11649 Loss: 0.3227721154689789\n",
      "Batch: 11713 Loss: 0.41852930188179016\n",
      "Batch: 11777 Loss: 0.5991576313972473\n",
      "Batch: 11841 Loss: 0.5574874877929688\n",
      "Batch: 11905 Loss: 0.4382059872150421\n",
      "Batch: 11969 Loss: 0.4062651991844177\n",
      "Batch: 12033 Loss: 0.3697117865085602\n",
      "Batch: 12097 Loss: 0.9159061908721924\n",
      "Batch: 12161 Loss: 0.503983736038208\n",
      "Batch: 12225 Loss: 0.2952447235584259\n",
      "Batch: 12289 Loss: 0.3083401322364807\n",
      "Batch: 12353 Loss: 0.4126940965652466\n",
      "Batch: 12417 Loss: 0.3462122678756714\n",
      "Batch: 12481 Loss: 0.3812951445579529\n",
      "Batch: 12545 Loss: 0.47667908668518066\n",
      "Batch: 12609 Loss: 0.5134943723678589\n",
      "Batch: 12673 Loss: 0.543497622013092\n",
      "Batch: 12737 Loss: 0.44938012957572937\n",
      "Batch: 12801 Loss: 0.36860334873199463\n",
      "Batch: 12865 Loss: 0.31405338644981384\n",
      "Batch: 12929 Loss: 0.6435600519180298\n",
      "Epoch: 36\n",
      "Batch: 1 Loss: 0.3988039195537567\n",
      "Batch: 65 Loss: 0.4605678915977478\n",
      "Batch: 129 Loss: 0.3918165862560272\n",
      "Batch: 193 Loss: 0.5848087072372437\n",
      "Batch: 257 Loss: 0.4196392893791199\n",
      "Batch: 321 Loss: 0.4048035442829132\n",
      "Batch: 385 Loss: 0.40497705340385437\n",
      "Batch: 449 Loss: 0.37501445412635803\n",
      "Batch: 513 Loss: 0.39041659235954285\n",
      "Batch: 577 Loss: 0.3885095715522766\n",
      "Batch: 641 Loss: 0.4638057351112366\n",
      "Batch: 705 Loss: 0.4096924662590027\n",
      "Batch: 769 Loss: 0.45903512835502625\n",
      "Batch: 833 Loss: 0.3370727598667145\n",
      "Batch: 897 Loss: 0.5650232434272766\n",
      "Batch: 961 Loss: 0.3611346185207367\n",
      "Batch: 1025 Loss: 0.3981975317001343\n",
      "Batch: 1089 Loss: 0.3908015191555023\n",
      "Batch: 1153 Loss: 0.42382869124412537\n",
      "Batch: 1217 Loss: 0.3833584189414978\n",
      "Batch: 1281 Loss: 0.4135286211967468\n",
      "Batch: 1345 Loss: 0.42295941710472107\n",
      "Batch: 1409 Loss: 0.35689932107925415\n",
      "Batch: 1473 Loss: 0.4083816409111023\n",
      "Batch: 1537 Loss: 0.38455748558044434\n",
      "Batch: 1601 Loss: 0.32958337664604187\n",
      "Batch: 1665 Loss: 0.36648687720298767\n",
      "Batch: 1729 Loss: 0.4298829734325409\n",
      "Batch: 1793 Loss: 0.33373820781707764\n",
      "Batch: 1857 Loss: 0.38771507143974304\n",
      "Batch: 1921 Loss: 0.4286276698112488\n",
      "Batch: 1985 Loss: 0.36117205023765564\n",
      "Batch: 2049 Loss: 0.3356782793998718\n",
      "Batch: 2113 Loss: 0.35618260502815247\n",
      "Batch: 2177 Loss: 0.39622578024864197\n",
      "Batch: 2241 Loss: 0.4407041072845459\n",
      "Batch: 2305 Loss: 0.45767828822135925\n",
      "Batch: 2369 Loss: 0.47993436455726624\n",
      "Batch: 2433 Loss: 0.43478813767433167\n",
      "Batch: 2497 Loss: 0.49019548296928406\n",
      "Batch: 2561 Loss: 0.40566518902778625\n",
      "Batch: 2625 Loss: 0.4208194315433502\n",
      "Batch: 2689 Loss: 0.43641796708106995\n",
      "Batch: 2753 Loss: 0.3740808963775635\n",
      "Batch: 2817 Loss: 0.5207085013389587\n",
      "Batch: 2881 Loss: 0.4487881064414978\n",
      "Batch: 2945 Loss: 0.38434672355651855\n",
      "Batch: 3009 Loss: 0.5452065467834473\n",
      "Batch: 3073 Loss: 0.4310489296913147\n",
      "Batch: 3137 Loss: 0.39522337913513184\n",
      "Batch: 3201 Loss: 0.38075414299964905\n",
      "Batch: 3265 Loss: 0.3681752681732178\n",
      "Batch: 3329 Loss: 0.3996584415435791\n",
      "Batch: 3393 Loss: 0.4253121614456177\n",
      "Batch: 3457 Loss: 0.3899082541465759\n",
      "Batch: 3521 Loss: 0.3004436492919922\n",
      "Batch: 3585 Loss: 0.28603261709213257\n",
      "Batch: 3649 Loss: 0.47153595089912415\n",
      "Batch: 3713 Loss: 0.3902897238731384\n",
      "Batch: 3777 Loss: 0.40895676612854004\n",
      "Batch: 3841 Loss: 0.40650153160095215\n",
      "Batch: 3905 Loss: 0.37560856342315674\n",
      "Batch: 3969 Loss: 0.5217464566230774\n",
      "Batch: 4033 Loss: 0.391388863325119\n",
      "Batch: 4097 Loss: 0.392203688621521\n",
      "Batch: 4161 Loss: 0.45028573274612427\n",
      "Batch: 4225 Loss: 0.33100077509880066\n",
      "Batch: 4289 Loss: 0.35349440574645996\n",
      "Batch: 4353 Loss: 0.4782702624797821\n",
      "Batch: 4417 Loss: 0.6480300426483154\n",
      "Batch: 4481 Loss: 0.6901139616966248\n",
      "Batch: 4545 Loss: 0.5401767492294312\n",
      "Batch: 4609 Loss: 0.3684040606021881\n",
      "Batch: 4673 Loss: 0.3476211428642273\n",
      "Batch: 4737 Loss: 0.4452994167804718\n",
      "Batch: 4801 Loss: 0.3643782138824463\n",
      "Batch: 4865 Loss: 0.3524288535118103\n",
      "Batch: 4929 Loss: 0.4031597971916199\n",
      "Batch: 4993 Loss: 0.5120833516120911\n",
      "Batch: 5057 Loss: 0.49777141213417053\n",
      "Batch: 5121 Loss: 0.39130234718322754\n",
      "Batch: 5185 Loss: 0.847515344619751\n",
      "Batch: 5249 Loss: 0.3652544915676117\n",
      "Batch: 5313 Loss: 0.4376918375492096\n",
      "Batch: 5377 Loss: 0.4216987192630768\n",
      "Batch: 5441 Loss: 0.5359357595443726\n",
      "Batch: 5505 Loss: 0.4838298559188843\n",
      "Batch: 5569 Loss: 0.5250598192214966\n",
      "Batch: 5633 Loss: 0.38977187871932983\n",
      "Batch: 5697 Loss: 0.45481792092323303\n",
      "Batch: 5761 Loss: 0.5714991092681885\n",
      "Batch: 5825 Loss: 0.4314679801464081\n",
      "Batch: 5889 Loss: 0.3824189603328705\n",
      "Batch: 5953 Loss: 0.38373565673828125\n",
      "Batch: 6017 Loss: 0.32077234983444214\n",
      "Batch: 6081 Loss: 0.2987103760242462\n",
      "Batch: 6145 Loss: 0.40503421425819397\n",
      "Batch: 6209 Loss: 0.34393826127052307\n",
      "Batch: 6273 Loss: 0.4573022425174713\n",
      "Batch: 6337 Loss: 0.3313317894935608\n",
      "Batch: 6401 Loss: 0.3341415226459503\n",
      "Batch: 6465 Loss: 0.3750038146972656\n",
      "Batch: 6529 Loss: 0.3542403280735016\n",
      "Batch: 6593 Loss: 0.393515408039093\n",
      "Batch: 6657 Loss: 0.3109489679336548\n",
      "Batch: 6721 Loss: 0.41726016998291016\n",
      "Batch: 6785 Loss: 0.41229742765426636\n",
      "Batch: 6849 Loss: 0.4118614196777344\n",
      "Batch: 6913 Loss: 0.39311641454696655\n",
      "Batch: 6977 Loss: 0.43931370973587036\n",
      "Batch: 7041 Loss: 0.4164920747280121\n",
      "Batch: 7105 Loss: 0.33452925086021423\n",
      "Batch: 7169 Loss: 0.3968026638031006\n",
      "Batch: 7233 Loss: 0.3533100485801697\n",
      "Batch: 7297 Loss: 0.4106399714946747\n",
      "Batch: 7361 Loss: 0.3837810754776001\n",
      "Batch: 7425 Loss: 0.46762779355049133\n",
      "Batch: 7489 Loss: 0.5617967247962952\n",
      "Batch: 7553 Loss: 0.36509501934051514\n",
      "Batch: 7617 Loss: 0.3642105162143707\n",
      "Batch: 7681 Loss: 0.4409116804599762\n",
      "Batch: 7745 Loss: 0.45378679037094116\n",
      "Batch: 7809 Loss: 0.41996124386787415\n",
      "Batch: 7873 Loss: 0.333912193775177\n",
      "Batch: 7937 Loss: 0.5467774868011475\n",
      "Batch: 8001 Loss: 0.39588165283203125\n",
      "Batch: 8065 Loss: 0.5381192564964294\n",
      "Batch: 8129 Loss: 0.3978787064552307\n",
      "Batch: 8193 Loss: 0.44045859575271606\n",
      "Batch: 8257 Loss: 0.46190494298934937\n",
      "Batch: 8321 Loss: 0.6331049799919128\n",
      "Batch: 8385 Loss: 0.3114128112792969\n",
      "Batch: 8449 Loss: 0.3466835618019104\n",
      "Batch: 8513 Loss: 0.6327551603317261\n",
      "Batch: 8577 Loss: 0.32522329688072205\n",
      "Batch: 8641 Loss: 0.49212202429771423\n",
      "Batch: 8705 Loss: 0.4093548059463501\n",
      "Batch: 8769 Loss: 0.4625568687915802\n",
      "Batch: 8833 Loss: 0.5178797245025635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 8897 Loss: 0.7923858165740967\n",
      "Batch: 8961 Loss: 0.39248842000961304\n",
      "Batch: 9025 Loss: 0.38761237263679504\n",
      "Batch: 9089 Loss: 0.39853209257125854\n",
      "Batch: 9153 Loss: 0.4631000757217407\n",
      "Batch: 9217 Loss: 0.49173152446746826\n",
      "Batch: 9281 Loss: 0.45379576086997986\n",
      "Batch: 9345 Loss: 0.3564915060997009\n",
      "Batch: 9409 Loss: 0.4847423732280731\n",
      "Batch: 9473 Loss: 0.5508460998535156\n",
      "Batch: 9537 Loss: 0.46659666299819946\n",
      "Batch: 9601 Loss: 0.35809677839279175\n",
      "Batch: 9665 Loss: 0.33473101258277893\n",
      "Batch: 9729 Loss: 0.4349382519721985\n",
      "Batch: 9793 Loss: 0.37778109312057495\n",
      "Batch: 9857 Loss: 0.42755669355392456\n",
      "Batch: 9921 Loss: 0.393099844455719\n",
      "Batch: 9985 Loss: 0.4404572546482086\n",
      "Batch: 10049 Loss: 0.4994695484638214\n",
      "Batch: 10113 Loss: 0.39044326543807983\n",
      "Batch: 10177 Loss: 0.4923637807369232\n",
      "Batch: 10241 Loss: 0.3640037775039673\n",
      "Batch: 10305 Loss: 0.4382104277610779\n",
      "Batch: 10369 Loss: 0.48036476969718933\n",
      "Batch: 10433 Loss: 0.39911729097366333\n",
      "Batch: 10497 Loss: 0.3933255970478058\n",
      "Batch: 10561 Loss: 0.3654157221317291\n",
      "Batch: 10625 Loss: 0.42874208092689514\n",
      "Batch: 10689 Loss: 0.4078635573387146\n",
      "Batch: 10753 Loss: 0.35025373101234436\n",
      "Batch: 10817 Loss: 0.30962470173835754\n",
      "Batch: 10881 Loss: 0.36833328008651733\n",
      "Batch: 10945 Loss: 0.32811200618743896\n",
      "Batch: 11009 Loss: 0.3748002350330353\n",
      "Batch: 11073 Loss: 0.43253645300865173\n",
      "Batch: 11137 Loss: 0.3517037034034729\n",
      "Batch: 11201 Loss: 0.36590999364852905\n",
      "Batch: 11265 Loss: 0.5156897902488708\n",
      "Batch: 11329 Loss: 0.6429401636123657\n",
      "Batch: 11393 Loss: 0.27980250120162964\n",
      "Batch: 11457 Loss: 0.35804951190948486\n",
      "Batch: 11521 Loss: 0.3716922998428345\n",
      "Batch: 11585 Loss: 0.4913822412490845\n",
      "Batch: 11649 Loss: 0.32255133986473083\n",
      "Batch: 11713 Loss: 0.4194048345088959\n",
      "Batch: 11777 Loss: 0.6017406582832336\n",
      "Batch: 11841 Loss: 0.5564842224121094\n",
      "Batch: 11905 Loss: 0.4380877614021301\n",
      "Batch: 11969 Loss: 0.40744468569755554\n",
      "Batch: 12033 Loss: 0.3719489872455597\n",
      "Batch: 12097 Loss: 0.9221128821372986\n",
      "Batch: 12161 Loss: 0.5036324262619019\n",
      "Batch: 12225 Loss: 0.29484814405441284\n",
      "Batch: 12289 Loss: 0.3109482228755951\n",
      "Batch: 12353 Loss: 0.4107809066772461\n",
      "Batch: 12417 Loss: 0.3448324203491211\n",
      "Batch: 12481 Loss: 0.3803611397743225\n",
      "Batch: 12545 Loss: 0.48230621218681335\n",
      "Batch: 12609 Loss: 0.512372612953186\n",
      "Batch: 12673 Loss: 0.5323602557182312\n",
      "Batch: 12737 Loss: 0.44732666015625\n",
      "Batch: 12801 Loss: 0.37391558289527893\n",
      "Batch: 12865 Loss: 0.3136276602745056\n",
      "Batch: 12929 Loss: 0.6431133151054382\n",
      "Epoch: 37\n",
      "Batch: 1 Loss: 0.3981962203979492\n",
      "Batch: 65 Loss: 0.46038559079170227\n",
      "Batch: 129 Loss: 0.3915241062641144\n",
      "Batch: 193 Loss: 0.5836283564567566\n",
      "Batch: 257 Loss: 0.4179208278656006\n",
      "Batch: 321 Loss: 0.4040655195713043\n",
      "Batch: 385 Loss: 0.4044826924800873\n",
      "Batch: 449 Loss: 0.37559759616851807\n",
      "Batch: 513 Loss: 0.38983824849128723\n",
      "Batch: 577 Loss: 0.38871991634368896\n",
      "Batch: 641 Loss: 0.4644412398338318\n",
      "Batch: 705 Loss: 0.4092961847782135\n",
      "Batch: 769 Loss: 0.457500696182251\n",
      "Batch: 833 Loss: 0.33454570174217224\n",
      "Batch: 897 Loss: 0.5671538710594177\n",
      "Batch: 961 Loss: 0.36433926224708557\n",
      "Batch: 1025 Loss: 0.39729979634284973\n",
      "Batch: 1089 Loss: 0.39215075969696045\n",
      "Batch: 1153 Loss: 0.42439135909080505\n",
      "Batch: 1217 Loss: 0.38377195596694946\n",
      "Batch: 1281 Loss: 0.41395124793052673\n",
      "Batch: 1345 Loss: 0.42309048771858215\n",
      "Batch: 1409 Loss: 0.35747379064559937\n",
      "Batch: 1473 Loss: 0.4091508984565735\n",
      "Batch: 1537 Loss: 0.3849245607852936\n",
      "Batch: 1601 Loss: 0.3301914632320404\n",
      "Batch: 1665 Loss: 0.3661371171474457\n",
      "Batch: 1729 Loss: 0.42935463786125183\n",
      "Batch: 1793 Loss: 0.3350098133087158\n",
      "Batch: 1857 Loss: 0.3774987757205963\n",
      "Batch: 1921 Loss: 0.4216366410255432\n",
      "Batch: 1985 Loss: 0.3614572584629059\n",
      "Batch: 2049 Loss: 0.3333622217178345\n",
      "Batch: 2113 Loss: 0.34990251064300537\n",
      "Batch: 2177 Loss: 0.3948669731616974\n",
      "Batch: 2241 Loss: 0.43784385919570923\n",
      "Batch: 2305 Loss: 0.45376500487327576\n",
      "Batch: 2369 Loss: 0.47304460406303406\n",
      "Batch: 2433 Loss: 0.4308335781097412\n",
      "Batch: 2497 Loss: 0.4890890121459961\n",
      "Batch: 2561 Loss: 0.4040922522544861\n",
      "Batch: 2625 Loss: 0.4204515516757965\n",
      "Batch: 2689 Loss: 0.43566271662712097\n",
      "Batch: 2753 Loss: 0.35922467708587646\n",
      "Batch: 2817 Loss: 0.5234372615814209\n",
      "Batch: 2881 Loss: 0.4523119628429413\n",
      "Batch: 2945 Loss: 0.3887694478034973\n",
      "Batch: 3009 Loss: 0.5499897003173828\n",
      "Batch: 3073 Loss: 0.4302294850349426\n",
      "Batch: 3137 Loss: 0.39439621567726135\n",
      "Batch: 3201 Loss: 0.38003402948379517\n",
      "Batch: 3265 Loss: 0.3676079213619232\n",
      "Batch: 3329 Loss: 0.399461954832077\n",
      "Batch: 3393 Loss: 0.4306926727294922\n",
      "Batch: 3457 Loss: 0.39061278104782104\n",
      "Batch: 3521 Loss: 0.2990648150444031\n",
      "Batch: 3585 Loss: 0.28604888916015625\n",
      "Batch: 3649 Loss: 0.4668334126472473\n",
      "Batch: 3713 Loss: 0.38464587926864624\n",
      "Batch: 3777 Loss: 0.4075204133987427\n",
      "Batch: 3841 Loss: 0.4066368639469147\n",
      "Batch: 3905 Loss: 0.374210387468338\n",
      "Batch: 3969 Loss: 0.5228378772735596\n",
      "Batch: 4033 Loss: 0.39246293902397156\n",
      "Batch: 4097 Loss: 0.39031389355659485\n",
      "Batch: 4161 Loss: 0.4507211744785309\n",
      "Batch: 4225 Loss: 0.3301568329334259\n",
      "Batch: 4289 Loss: 0.35261625051498413\n",
      "Batch: 4353 Loss: 0.4788223206996918\n",
      "Batch: 4417 Loss: 0.6122975945472717\n",
      "Batch: 4481 Loss: 0.6614786982536316\n",
      "Batch: 4545 Loss: 0.5371657609939575\n",
      "Batch: 4609 Loss: 0.3680783212184906\n",
      "Batch: 4673 Loss: 0.3469756543636322\n",
      "Batch: 4737 Loss: 0.443895548582077\n",
      "Batch: 4801 Loss: 0.3614664375782013\n",
      "Batch: 4865 Loss: 0.3521433472633362\n",
      "Batch: 4929 Loss: 0.401829332113266\n",
      "Batch: 4993 Loss: 0.5116860270500183\n",
      "Batch: 5057 Loss: 0.4952411651611328\n",
      "Batch: 5121 Loss: 0.38810503482818604\n",
      "Batch: 5185 Loss: 0.8408412337303162\n",
      "Batch: 5249 Loss: 0.36543625593185425\n",
      "Batch: 5313 Loss: 0.43706685304641724\n",
      "Batch: 5377 Loss: 0.42266520857810974\n",
      "Batch: 5441 Loss: 0.5378279089927673\n",
      "Batch: 5505 Loss: 0.4781511723995209\n",
      "Batch: 5569 Loss: 0.5112429261207581\n",
      "Batch: 5633 Loss: 0.38396894931793213\n",
      "Batch: 5697 Loss: 0.43103867769241333\n",
      "Batch: 5761 Loss: 0.5494774580001831\n",
      "Batch: 5825 Loss: 0.4265369176864624\n",
      "Batch: 5889 Loss: 0.3818654716014862\n",
      "Batch: 5953 Loss: 0.383792519569397\n",
      "Batch: 6017 Loss: 0.32090145349502563\n",
      "Batch: 6081 Loss: 0.29691675305366516\n",
      "Batch: 6145 Loss: 0.4148609936237335\n",
      "Batch: 6209 Loss: 0.3417981266975403\n",
      "Batch: 6273 Loss: 0.45667439699172974\n",
      "Batch: 6337 Loss: 0.33131298422813416\n",
      "Batch: 6401 Loss: 0.33360591530799866\n",
      "Batch: 6465 Loss: 0.37495723366737366\n",
      "Batch: 6529 Loss: 0.3530593514442444\n",
      "Batch: 6593 Loss: 0.37424594163894653\n",
      "Batch: 6657 Loss: 0.31538891792297363\n",
      "Batch: 6721 Loss: 0.4189909100532532\n",
      "Batch: 6785 Loss: 0.41115090250968933\n",
      "Batch: 6849 Loss: 0.411839097738266\n",
      "Batch: 6913 Loss: 0.3916793167591095\n",
      "Batch: 6977 Loss: 0.42622917890548706\n",
      "Batch: 7041 Loss: 0.4161197245121002\n",
      "Batch: 7105 Loss: 0.33975499868392944\n",
      "Batch: 7169 Loss: 0.40594056248664856\n",
      "Batch: 7233 Loss: 0.3515256345272064\n",
      "Batch: 7297 Loss: 0.4118042588233948\n",
      "Batch: 7361 Loss: 0.38347384333610535\n",
      "Batch: 7425 Loss: 0.4675435721874237\n",
      "Batch: 7489 Loss: 0.5607564449310303\n",
      "Batch: 7553 Loss: 0.3647167980670929\n",
      "Batch: 7617 Loss: 0.3629886209964752\n",
      "Batch: 7681 Loss: 0.4406961500644684\n",
      "Batch: 7745 Loss: 0.45396119356155396\n",
      "Batch: 7809 Loss: 0.41503679752349854\n",
      "Batch: 7873 Loss: 0.3299398720264435\n",
      "Batch: 7937 Loss: 0.543156087398529\n",
      "Batch: 8001 Loss: 0.3958077132701874\n",
      "Batch: 8065 Loss: 0.540778636932373\n",
      "Batch: 8129 Loss: 0.4077848196029663\n",
      "Batch: 8193 Loss: 0.437234103679657\n",
      "Batch: 8257 Loss: 0.46264371275901794\n",
      "Batch: 8321 Loss: 0.6325067281723022\n",
      "Batch: 8385 Loss: 0.3113720118999481\n",
      "Batch: 8449 Loss: 0.3463563323020935\n",
      "Batch: 8513 Loss: 0.6324191689491272\n",
      "Batch: 8577 Loss: 0.32451125979423523\n",
      "Batch: 8641 Loss: 0.4912319481372833\n",
      "Batch: 8705 Loss: 0.3932700455188751\n",
      "Batch: 8769 Loss: 0.4638196527957916\n",
      "Batch: 8833 Loss: 0.5170673131942749\n",
      "Batch: 8897 Loss: 0.7910938858985901\n",
      "Batch: 8961 Loss: 0.39285144209861755\n",
      "Batch: 9025 Loss: 0.3874362111091614\n",
      "Batch: 9089 Loss: 0.3984372615814209\n",
      "Batch: 9153 Loss: 0.4596926271915436\n",
      "Batch: 9217 Loss: 0.49059420824050903\n",
      "Batch: 9281 Loss: 0.4508661925792694\n",
      "Batch: 9345 Loss: 0.3554195165634155\n",
      "Batch: 9409 Loss: 0.4907912015914917\n",
      "Batch: 9473 Loss: 0.550922155380249\n",
      "Batch: 9537 Loss: 0.4642702043056488\n",
      "Batch: 9601 Loss: 0.358386754989624\n",
      "Batch: 9665 Loss: 0.3346470594406128\n",
      "Batch: 9729 Loss: 0.4351099133491516\n",
      "Batch: 9793 Loss: 0.3779391348361969\n",
      "Batch: 9857 Loss: 0.42702895402908325\n",
      "Batch: 9921 Loss: 0.3975706398487091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 9985 Loss: 0.4350258409976959\n",
      "Batch: 10049 Loss: 0.5016336441040039\n",
      "Batch: 10113 Loss: 0.39658281207084656\n",
      "Batch: 10177 Loss: 0.4934888780117035\n",
      "Batch: 10241 Loss: 0.363955557346344\n",
      "Batch: 10305 Loss: 0.43732866644859314\n",
      "Batch: 10369 Loss: 0.480281263589859\n",
      "Batch: 10433 Loss: 0.3993197977542877\n",
      "Batch: 10497 Loss: 0.3923027813434601\n",
      "Batch: 10561 Loss: 0.3650343716144562\n",
      "Batch: 10625 Loss: 0.4266238510608673\n",
      "Batch: 10689 Loss: 0.4029671549797058\n",
      "Batch: 10753 Loss: 0.3504024147987366\n",
      "Batch: 10817 Loss: 0.30929142236709595\n",
      "Batch: 10881 Loss: 0.3554495573043823\n",
      "Batch: 10945 Loss: 0.3507150113582611\n",
      "Batch: 11009 Loss: 0.3627522885799408\n",
      "Batch: 11073 Loss: 0.4460451304912567\n",
      "Batch: 11137 Loss: 0.35189196467399597\n",
      "Batch: 11201 Loss: 0.36582690477371216\n",
      "Batch: 11265 Loss: 0.5145952701568604\n",
      "Batch: 11329 Loss: 0.6357959508895874\n",
      "Batch: 11393 Loss: 0.2808850109577179\n",
      "Batch: 11457 Loss: 0.3583100736141205\n",
      "Batch: 11521 Loss: 0.37066060304641724\n",
      "Batch: 11585 Loss: 0.4906955361366272\n",
      "Batch: 11649 Loss: 0.3224828243255615\n",
      "Batch: 11713 Loss: 0.4165746569633484\n",
      "Batch: 11777 Loss: 0.6004177331924438\n",
      "Batch: 11841 Loss: 0.5557613372802734\n",
      "Batch: 11905 Loss: 0.43618303537368774\n",
      "Batch: 11969 Loss: 0.40420225262641907\n",
      "Batch: 12033 Loss: 0.37225982546806335\n",
      "Batch: 12097 Loss: 0.9156412482261658\n",
      "Batch: 12161 Loss: 0.5078299045562744\n",
      "Batch: 12225 Loss: 0.2944764792919159\n",
      "Batch: 12289 Loss: 0.30715250968933105\n",
      "Batch: 12353 Loss: 0.4114495515823364\n",
      "Batch: 12417 Loss: 0.3441143333911896\n",
      "Batch: 12481 Loss: 0.37967804074287415\n",
      "Batch: 12545 Loss: 0.4759587347507477\n",
      "Batch: 12609 Loss: 0.5146111845970154\n",
      "Batch: 12673 Loss: 0.5291413068771362\n",
      "Batch: 12737 Loss: 0.4483628571033478\n",
      "Batch: 12801 Loss: 0.3692862391471863\n",
      "Batch: 12865 Loss: 0.3133636713027954\n",
      "Batch: 12929 Loss: 0.6434355974197388\n",
      "Epoch: 38\n",
      "Batch: 1 Loss: 0.3983525037765503\n",
      "Batch: 65 Loss: 0.4601520001888275\n",
      "Batch: 129 Loss: 0.39151597023010254\n",
      "Batch: 193 Loss: 0.5835756063461304\n",
      "Batch: 257 Loss: 0.41848164796829224\n",
      "Batch: 321 Loss: 0.40433377027511597\n",
      "Batch: 385 Loss: 0.40414804220199585\n",
      "Batch: 449 Loss: 0.3749176859855652\n",
      "Batch: 513 Loss: 0.3898766338825226\n",
      "Batch: 577 Loss: 0.3881647288799286\n",
      "Batch: 641 Loss: 0.46322160959243774\n",
      "Batch: 705 Loss: 0.40820398926734924\n",
      "Batch: 769 Loss: 0.456378310918808\n",
      "Batch: 833 Loss: 0.33410295844078064\n",
      "Batch: 897 Loss: 0.5667835474014282\n",
      "Batch: 961 Loss: 0.3645538091659546\n",
      "Batch: 1025 Loss: 0.39702802896499634\n",
      "Batch: 1089 Loss: 0.3903663456439972\n",
      "Batch: 1153 Loss: 0.42420125007629395\n",
      "Batch: 1217 Loss: 0.3837633430957794\n",
      "Batch: 1281 Loss: 0.4136068522930145\n",
      "Batch: 1345 Loss: 0.42306193709373474\n",
      "Batch: 1409 Loss: 0.35650917887687683\n",
      "Batch: 1473 Loss: 0.40868106484413147\n",
      "Batch: 1537 Loss: 0.381822407245636\n",
      "Batch: 1601 Loss: 0.3522230088710785\n",
      "Batch: 1665 Loss: 0.4012633264064789\n",
      "Batch: 1729 Loss: 0.45995602011680603\n",
      "Batch: 1793 Loss: 0.36276641488075256\n",
      "Batch: 1857 Loss: 0.3888758420944214\n",
      "Batch: 1921 Loss: 0.41994085907936096\n",
      "Batch: 1985 Loss: 0.38800355792045593\n",
      "Batch: 2049 Loss: 0.3578566312789917\n",
      "Batch: 2113 Loss: 0.3610667586326599\n",
      "Batch: 2177 Loss: 0.4012487828731537\n",
      "Batch: 2241 Loss: 0.4460282027721405\n",
      "Batch: 2305 Loss: 0.46593424677848816\n",
      "Batch: 2369 Loss: 0.478768914937973\n",
      "Batch: 2433 Loss: 0.4402391314506531\n",
      "Batch: 2497 Loss: 0.4986911416053772\n",
      "Batch: 2561 Loss: 0.426273912191391\n",
      "Batch: 2625 Loss: 0.45328736305236816\n",
      "Batch: 2689 Loss: 0.4629835784435272\n",
      "Batch: 2753 Loss: 0.38119062781333923\n",
      "Batch: 2817 Loss: 0.5294444561004639\n",
      "Batch: 2881 Loss: 0.45566922426223755\n",
      "Batch: 2945 Loss: 0.40068429708480835\n",
      "Batch: 3009 Loss: 0.5456445217132568\n",
      "Batch: 3073 Loss: 0.4305431544780731\n",
      "Batch: 3137 Loss: 0.4025428295135498\n",
      "Batch: 3201 Loss: 0.3957303464412689\n",
      "Batch: 3265 Loss: 0.3712507486343384\n",
      "Batch: 3329 Loss: 0.40012428164482117\n",
      "Batch: 3393 Loss: 0.42759859561920166\n",
      "Batch: 3457 Loss: 0.38848963379859924\n",
      "Batch: 3521 Loss: 0.32104215025901794\n",
      "Batch: 3585 Loss: 0.3010559380054474\n",
      "Batch: 3649 Loss: 0.470102995634079\n",
      "Batch: 3713 Loss: 0.38464051485061646\n",
      "Batch: 3777 Loss: 0.4082208573818207\n",
      "Batch: 3841 Loss: 0.41080302000045776\n",
      "Batch: 3905 Loss: 0.37290191650390625\n",
      "Batch: 3969 Loss: 0.5194289088249207\n",
      "Batch: 4033 Loss: 0.39037248492240906\n",
      "Batch: 4097 Loss: 0.39147958159446716\n",
      "Batch: 4161 Loss: 0.4505113959312439\n",
      "Batch: 4225 Loss: 0.33161354064941406\n",
      "Batch: 4289 Loss: 0.3548787534236908\n",
      "Batch: 4353 Loss: 0.4792049825191498\n",
      "Batch: 4417 Loss: 0.6140412092208862\n",
      "Batch: 4481 Loss: 0.6630291938781738\n",
      "Batch: 4545 Loss: 0.537260115146637\n",
      "Batch: 4609 Loss: 0.3687085211277008\n",
      "Batch: 4673 Loss: 0.3485514223575592\n",
      "Batch: 4737 Loss: 0.44471827149391174\n",
      "Batch: 4801 Loss: 0.362726092338562\n",
      "Batch: 4865 Loss: 0.35446566343307495\n",
      "Batch: 4929 Loss: 0.40297985076904297\n",
      "Batch: 4993 Loss: 0.5130844712257385\n",
      "Batch: 5057 Loss: 0.49835294485092163\n",
      "Batch: 5121 Loss: 0.3859151303768158\n",
      "Batch: 5185 Loss: 0.8422618508338928\n",
      "Batch: 5249 Loss: 0.36540624499320984\n",
      "Batch: 5313 Loss: 0.43729838728904724\n",
      "Batch: 5377 Loss: 0.4234165549278259\n",
      "Batch: 5441 Loss: 0.5358730554580688\n",
      "Batch: 5505 Loss: 0.4856392443180084\n",
      "Batch: 5569 Loss: 0.5248532295227051\n",
      "Batch: 5633 Loss: 0.3907495439052582\n",
      "Batch: 5697 Loss: 0.4584895372390747\n",
      "Batch: 5761 Loss: 0.573516845703125\n",
      "Batch: 5825 Loss: 0.43135184049606323\n",
      "Batch: 5889 Loss: 0.3815266489982605\n",
      "Batch: 5953 Loss: 0.38365471363067627\n",
      "Batch: 6017 Loss: 0.32002025842666626\n",
      "Batch: 6081 Loss: 0.2967781126499176\n",
      "Batch: 6145 Loss: 0.40424686670303345\n",
      "Batch: 6209 Loss: 0.3427007794380188\n",
      "Batch: 6273 Loss: 0.45641857385635376\n",
      "Batch: 6337 Loss: 0.33129575848579407\n",
      "Batch: 6401 Loss: 0.3346359133720398\n",
      "Batch: 6465 Loss: 0.3748767077922821\n",
      "Batch: 6529 Loss: 0.3524957597255707\n",
      "Batch: 6593 Loss: 0.3754800260066986\n",
      "Batch: 6657 Loss: 0.3133474886417389\n",
      "Batch: 6721 Loss: 0.42076626420021057\n",
      "Batch: 6785 Loss: 0.41070330142974854\n",
      "Batch: 6849 Loss: 0.4115161895751953\n",
      "Batch: 6913 Loss: 0.39009544253349304\n",
      "Batch: 6977 Loss: 0.4251357614994049\n",
      "Batch: 7041 Loss: 0.41655775904655457\n",
      "Batch: 7105 Loss: 0.3631552457809448\n",
      "Batch: 7169 Loss: 0.40684765577316284\n",
      "Batch: 7233 Loss: 0.3532334566116333\n",
      "Batch: 7297 Loss: 0.41155746579170227\n",
      "Batch: 7361 Loss: 0.38269534707069397\n",
      "Batch: 7425 Loss: 0.4671756327152252\n",
      "Batch: 7489 Loss: 0.5609248280525208\n",
      "Batch: 7553 Loss: 0.36549344658851624\n",
      "Batch: 7617 Loss: 0.3648260831832886\n",
      "Batch: 7681 Loss: 0.44165530800819397\n",
      "Batch: 7745 Loss: 0.4539478123188019\n",
      "Batch: 7809 Loss: 0.4144928753376007\n",
      "Batch: 7873 Loss: 0.3308020532131195\n",
      "Batch: 7937 Loss: 0.5390962958335876\n",
      "Batch: 8001 Loss: 0.3936181664466858\n",
      "Batch: 8065 Loss: 0.5366312265396118\n",
      "Batch: 8129 Loss: 0.3962532579898834\n",
      "Batch: 8193 Loss: 0.4365812838077545\n",
      "Batch: 8257 Loss: 0.46285372972488403\n",
      "Batch: 8321 Loss: 0.6319582462310791\n",
      "Batch: 8385 Loss: 0.31083932518959045\n",
      "Batch: 8449 Loss: 0.34688374400138855\n",
      "Batch: 8513 Loss: 0.6315906643867493\n",
      "Batch: 8577 Loss: 0.3231009244918823\n",
      "Batch: 8641 Loss: 0.4932307302951813\n",
      "Batch: 8705 Loss: 0.3935471773147583\n",
      "Batch: 8769 Loss: 0.4629993736743927\n",
      "Batch: 8833 Loss: 0.5161846280097961\n",
      "Batch: 8897 Loss: 0.7889975905418396\n",
      "Batch: 8961 Loss: 0.3925907015800476\n",
      "Batch: 9025 Loss: 0.3878819942474365\n",
      "Batch: 9089 Loss: 0.39829733967781067\n",
      "Batch: 9153 Loss: 0.4591875374317169\n",
      "Batch: 9217 Loss: 0.4924362301826477\n",
      "Batch: 9281 Loss: 0.46056339144706726\n",
      "Batch: 9345 Loss: 0.35635891556739807\n",
      "Batch: 9409 Loss: 0.48478034138679504\n",
      "Batch: 9473 Loss: 0.5444273352622986\n",
      "Batch: 9537 Loss: 0.4646030366420746\n",
      "Batch: 9601 Loss: 0.35889384150505066\n",
      "Batch: 9665 Loss: 0.33422428369522095\n",
      "Batch: 9729 Loss: 0.43407830595970154\n",
      "Batch: 9793 Loss: 0.37751761078834534\n",
      "Batch: 9857 Loss: 0.42776668071746826\n",
      "Batch: 9921 Loss: 0.39301589131355286\n",
      "Batch: 9985 Loss: 0.4333168566226959\n",
      "Batch: 10049 Loss: 0.5033568143844604\n",
      "Batch: 10113 Loss: 0.38937070965766907\n",
      "Batch: 10177 Loss: 0.49141860008239746\n",
      "Batch: 10241 Loss: 0.36467212438583374\n",
      "Batch: 10305 Loss: 0.4377557039260864\n",
      "Batch: 10369 Loss: 0.47986099123954773\n",
      "Batch: 10433 Loss: 0.3996836841106415\n",
      "Batch: 10497 Loss: 0.39244547486305237\n",
      "Batch: 10561 Loss: 0.36493340134620667\n",
      "Batch: 10625 Loss: 0.4280446767807007\n",
      "Batch: 10689 Loss: 0.41059523820877075\n",
      "Batch: 10753 Loss: 0.3504047989845276\n",
      "Batch: 10817 Loss: 0.3094343841075897\n",
      "Batch: 10881 Loss: 0.3669881522655487\n",
      "Batch: 10945 Loss: 0.32748743891716003\n",
      "Batch: 11009 Loss: 0.366771399974823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 11073 Loss: 0.43257880210876465\n",
      "Batch: 11137 Loss: 0.3512808084487915\n",
      "Batch: 11201 Loss: 0.3624700605869293\n",
      "Batch: 11265 Loss: 0.5103209018707275\n",
      "Batch: 11329 Loss: 0.6370322704315186\n",
      "Batch: 11393 Loss: 0.2811545133590698\n",
      "Batch: 11457 Loss: 0.35804513096809387\n",
      "Batch: 11521 Loss: 0.3707764148712158\n",
      "Batch: 11585 Loss: 0.4904496669769287\n",
      "Batch: 11649 Loss: 0.3223038613796234\n",
      "Batch: 11713 Loss: 0.4236648976802826\n",
      "Batch: 11777 Loss: 0.5989441275596619\n",
      "Batch: 11841 Loss: 0.5576196908950806\n",
      "Batch: 11905 Loss: 0.4357636868953705\n",
      "Batch: 11969 Loss: 0.40409713983535767\n",
      "Batch: 12033 Loss: 0.3711528480052948\n",
      "Batch: 12097 Loss: 0.9116984009742737\n",
      "Batch: 12161 Loss: 0.5049751996994019\n",
      "Batch: 12225 Loss: 0.29521358013153076\n",
      "Batch: 12289 Loss: 0.31193792819976807\n",
      "Batch: 12353 Loss: 0.4128456711769104\n",
      "Batch: 12417 Loss: 0.34463372826576233\n",
      "Batch: 12481 Loss: 0.3805789053440094\n",
      "Batch: 12545 Loss: 0.47523513436317444\n",
      "Batch: 12609 Loss: 0.5108979940414429\n",
      "Batch: 12673 Loss: 0.5393178462982178\n",
      "Batch: 12737 Loss: 0.4473745822906494\n",
      "Batch: 12801 Loss: 0.366741806268692\n",
      "Batch: 12865 Loss: 0.31256604194641113\n",
      "Batch: 12929 Loss: 0.6427680850028992\n",
      "Epoch: 39\n",
      "Batch: 1 Loss: 0.39773160219192505\n",
      "Batch: 65 Loss: 0.45915988087654114\n",
      "Batch: 129 Loss: 0.3905707895755768\n",
      "Batch: 193 Loss: 0.5826561450958252\n",
      "Batch: 257 Loss: 0.41899988055229187\n",
      "Batch: 321 Loss: 0.4046362638473511\n",
      "Batch: 385 Loss: 0.4043048024177551\n",
      "Batch: 449 Loss: 0.37420913577079773\n",
      "Batch: 513 Loss: 0.3893950581550598\n",
      "Batch: 577 Loss: 0.38885340094566345\n",
      "Batch: 641 Loss: 0.46384504437446594\n",
      "Batch: 705 Loss: 0.4072551727294922\n",
      "Batch: 769 Loss: 0.4542025327682495\n",
      "Batch: 833 Loss: 0.333987832069397\n",
      "Batch: 897 Loss: 0.563850462436676\n",
      "Batch: 961 Loss: 0.36320340633392334\n",
      "Batch: 1025 Loss: 0.3954046070575714\n",
      "Batch: 1089 Loss: 0.388439416885376\n",
      "Batch: 1153 Loss: 0.4229399263858795\n",
      "Batch: 1217 Loss: 0.383421391248703\n",
      "Batch: 1281 Loss: 0.41409561038017273\n",
      "Batch: 1345 Loss: 0.42275470495224\n",
      "Batch: 1409 Loss: 0.35669833421707153\n",
      "Batch: 1473 Loss: 0.40688464045524597\n",
      "Batch: 1537 Loss: 0.3847866952419281\n",
      "Batch: 1601 Loss: 0.3272569179534912\n",
      "Batch: 1665 Loss: 0.36704495549201965\n",
      "Batch: 1729 Loss: 0.4295060932636261\n",
      "Batch: 1793 Loss: 0.33281251788139343\n",
      "Batch: 1857 Loss: 0.37849780917167664\n",
      "Batch: 1921 Loss: 0.42119401693344116\n",
      "Batch: 1985 Loss: 0.3665447235107422\n",
      "Batch: 2049 Loss: 0.33347874879837036\n",
      "Batch: 2113 Loss: 0.34550970792770386\n",
      "Batch: 2177 Loss: 0.39363420009613037\n",
      "Batch: 2241 Loss: 0.43732312321662903\n",
      "Batch: 2305 Loss: 0.45302197337150574\n",
      "Batch: 2369 Loss: 0.4700828790664673\n",
      "Batch: 2433 Loss: 0.4335968792438507\n",
      "Batch: 2497 Loss: 0.49013346433639526\n",
      "Batch: 2561 Loss: 0.403905987739563\n",
      "Batch: 2625 Loss: 0.4212336838245392\n",
      "Batch: 2689 Loss: 0.4361313283443451\n",
      "Batch: 2753 Loss: 0.35683441162109375\n",
      "Batch: 2817 Loss: 0.5197529792785645\n",
      "Batch: 2881 Loss: 0.4529516100883484\n",
      "Batch: 2945 Loss: 0.39568907022476196\n",
      "Batch: 3009 Loss: 0.544185996055603\n",
      "Batch: 3073 Loss: 0.4295305609703064\n",
      "Batch: 3137 Loss: 0.39452919363975525\n",
      "Batch: 3201 Loss: 0.38053789734840393\n",
      "Batch: 3265 Loss: 0.3683624267578125\n",
      "Batch: 3329 Loss: 0.3995039463043213\n",
      "Batch: 3393 Loss: 0.4216421842575073\n",
      "Batch: 3457 Loss: 0.39096537232398987\n",
      "Batch: 3521 Loss: 0.301955908536911\n",
      "Batch: 3585 Loss: 0.28772059082984924\n",
      "Batch: 3649 Loss: 0.46532735228538513\n",
      "Batch: 3713 Loss: 0.38452738523483276\n",
      "Batch: 3777 Loss: 0.40630611777305603\n",
      "Batch: 3841 Loss: 0.4064862132072449\n",
      "Batch: 3905 Loss: 0.37359583377838135\n",
      "Batch: 3969 Loss: 0.5205883979797363\n",
      "Batch: 4033 Loss: 0.3914180397987366\n",
      "Batch: 4097 Loss: 0.39036092162132263\n",
      "Batch: 4161 Loss: 0.4503323435783386\n",
      "Batch: 4225 Loss: 0.33112502098083496\n",
      "Batch: 4289 Loss: 0.3525354862213135\n",
      "Batch: 4353 Loss: 0.4788558781147003\n",
      "Batch: 4417 Loss: 0.6131361722946167\n",
      "Batch: 4481 Loss: 0.6643299460411072\n",
      "Batch: 4545 Loss: 0.5374360680580139\n",
      "Batch: 4609 Loss: 0.36835816502571106\n",
      "Batch: 4673 Loss: 0.3485558331012726\n",
      "Batch: 4737 Loss: 0.44427594542503357\n",
      "Batch: 4801 Loss: 0.36153513193130493\n",
      "Batch: 4865 Loss: 0.3521253764629364\n",
      "Batch: 4929 Loss: 0.4010767638683319\n",
      "Batch: 4993 Loss: 0.5093109607696533\n",
      "Batch: 5057 Loss: 0.49406784772872925\n",
      "Batch: 5121 Loss: 0.3857260048389435\n",
      "Batch: 5185 Loss: 0.8403075933456421\n",
      "Batch: 5249 Loss: 0.3647873103618622\n",
      "Batch: 5313 Loss: 0.43742063641548157\n",
      "Batch: 5377 Loss: 0.4216237962245941\n",
      "Batch: 5441 Loss: 0.5280574560165405\n",
      "Batch: 5505 Loss: 0.4872174561023712\n",
      "Batch: 5569 Loss: 0.5246681571006775\n",
      "Batch: 5633 Loss: 0.3927749991416931\n",
      "Batch: 5697 Loss: 0.45905372500419617\n",
      "Batch: 5761 Loss: 0.5734339356422424\n",
      "Batch: 5825 Loss: 0.43149757385253906\n",
      "Batch: 5889 Loss: 0.3809601664543152\n",
      "Batch: 5953 Loss: 0.38377073407173157\n",
      "Batch: 6017 Loss: 0.321638286113739\n",
      "Batch: 6081 Loss: 0.297746479511261\n",
      "Batch: 6145 Loss: 0.4058448374271393\n",
      "Batch: 6209 Loss: 0.3422001600265503\n",
      "Batch: 6273 Loss: 0.45879775285720825\n",
      "Batch: 6337 Loss: 0.3301677405834198\n",
      "Batch: 6401 Loss: 0.3343730568885803\n",
      "Batch: 6465 Loss: 0.37540337443351746\n",
      "Batch: 6529 Loss: 0.3528868556022644\n",
      "Batch: 6593 Loss: 0.37344738841056824\n",
      "Batch: 6657 Loss: 0.3097201883792877\n",
      "Batch: 6721 Loss: 0.4195922017097473\n",
      "Batch: 6785 Loss: 0.414234459400177\n",
      "Batch: 6849 Loss: 0.4120757281780243\n",
      "Batch: 6913 Loss: 0.39127418398857117\n",
      "Batch: 6977 Loss: 0.42544296383857727\n",
      "Batch: 7041 Loss: 0.41523993015289307\n",
      "Batch: 7105 Loss: 0.33897653222084045\n",
      "Batch: 7169 Loss: 0.3940422236919403\n",
      "Batch: 7233 Loss: 0.35089418292045593\n",
      "Batch: 7297 Loss: 0.4131965637207031\n",
      "Batch: 7361 Loss: 0.38416093587875366\n",
      "Batch: 7425 Loss: 0.46661943197250366\n",
      "Batch: 7489 Loss: 0.5606876611709595\n",
      "Batch: 7553 Loss: 0.36506617069244385\n",
      "Batch: 7617 Loss: 0.3656744062900543\n",
      "Batch: 7681 Loss: 0.4398471415042877\n",
      "Batch: 7745 Loss: 0.45275557041168213\n",
      "Batch: 7809 Loss: 0.42045754194259644\n",
      "Batch: 7873 Loss: 0.3429541289806366\n",
      "Batch: 7937 Loss: 0.5403333902359009\n",
      "Batch: 8001 Loss: 0.39549145102500916\n",
      "Batch: 8065 Loss: 0.5366106629371643\n",
      "Batch: 8129 Loss: 0.3956933319568634\n",
      "Batch: 8193 Loss: 0.43816524744033813\n",
      "Batch: 8257 Loss: 0.4627865254878998\n",
      "Batch: 8321 Loss: 0.6316317915916443\n",
      "Batch: 8385 Loss: 0.31028974056243896\n",
      "Batch: 8449 Loss: 0.3466135263442993\n",
      "Batch: 8513 Loss: 0.6313709616661072\n",
      "Batch: 8577 Loss: 0.3249438405036926\n",
      "Batch: 8641 Loss: 0.49136409163475037\n",
      "Batch: 8705 Loss: 0.3976346552371979\n",
      "Batch: 8769 Loss: 0.462111234664917\n",
      "Batch: 8833 Loss: 0.5164790749549866\n",
      "Batch: 8897 Loss: 0.7872249484062195\n",
      "Batch: 8961 Loss: 0.391915887594223\n",
      "Batch: 9025 Loss: 0.38750118017196655\n",
      "Batch: 9089 Loss: 0.398173987865448\n",
      "Batch: 9153 Loss: 0.45725318789482117\n",
      "Batch: 9217 Loss: 0.49142733216285706\n",
      "Batch: 9281 Loss: 0.45047301054000854\n",
      "Batch: 9345 Loss: 0.3666589856147766\n",
      "Batch: 9409 Loss: 0.49614855647087097\n",
      "Batch: 9473 Loss: 0.5573163032531738\n",
      "Batch: 9537 Loss: 0.4749721884727478\n",
      "Batch: 9601 Loss: 0.3608250916004181\n",
      "Batch: 9665 Loss: 0.334728866815567\n",
      "Batch: 9729 Loss: 0.4363572895526886\n",
      "Batch: 9793 Loss: 0.3789254426956177\n",
      "Batch: 9857 Loss: 0.42673739790916443\n",
      "Batch: 9921 Loss: 0.391512006521225\n",
      "Batch: 9985 Loss: 0.4378111660480499\n",
      "Batch: 10049 Loss: 0.5067235231399536\n",
      "Batch: 10113 Loss: 0.3935902416706085\n",
      "Batch: 10177 Loss: 0.48680657148361206\n",
      "Batch: 10241 Loss: 0.36376023292541504\n",
      "Batch: 10305 Loss: 0.43707194924354553\n",
      "Batch: 10369 Loss: 0.47907230257987976\n",
      "Batch: 10433 Loss: 0.3991546034812927\n",
      "Batch: 10497 Loss: 0.39290377497673035\n",
      "Batch: 10561 Loss: 0.36488211154937744\n",
      "Batch: 10625 Loss: 0.43568482995033264\n",
      "Batch: 10689 Loss: 0.40899166464805603\n",
      "Batch: 10753 Loss: 0.34984689950942993\n",
      "Batch: 10817 Loss: 0.309417188167572\n",
      "Batch: 10881 Loss: 0.3554692566394806\n",
      "Batch: 10945 Loss: 0.36042606830596924\n",
      "Batch: 11009 Loss: 0.3732025623321533\n",
      "Batch: 11073 Loss: 0.4607669413089752\n",
      "Batch: 11137 Loss: 0.374897837638855\n",
      "Batch: 11201 Loss: 0.40414905548095703\n",
      "Batch: 11265 Loss: 0.5279682874679565\n",
      "Batch: 11329 Loss: 0.6560578942298889\n",
      "Batch: 11393 Loss: 0.27998706698417664\n",
      "Batch: 11457 Loss: 0.35754016041755676\n",
      "Batch: 11521 Loss: 0.39722901582717896\n",
      "Batch: 11585 Loss: 0.4889408349990845\n",
      "Batch: 11649 Loss: 0.321904718875885\n",
      "Batch: 11713 Loss: 0.4180751442909241\n",
      "Batch: 11777 Loss: 0.5958330631256104\n",
      "Batch: 11841 Loss: 0.5955377221107483\n",
      "Batch: 11905 Loss: 0.4474642872810364\n",
      "Batch: 11969 Loss: 0.4139094948768616\n",
      "Batch: 12033 Loss: 0.37184351682662964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 12097 Loss: 0.922961413860321\n",
      "Batch: 12161 Loss: 0.5148472189903259\n",
      "Batch: 12225 Loss: 0.2938784658908844\n",
      "Batch: 12289 Loss: 0.3075612187385559\n",
      "Batch: 12353 Loss: 0.4127222001552582\n",
      "Batch: 12417 Loss: 0.3432384729385376\n",
      "Batch: 12481 Loss: 0.3878643810749054\n",
      "Batch: 12545 Loss: 0.4752666652202606\n",
      "Batch: 12609 Loss: 0.5129410028457642\n",
      "Batch: 12673 Loss: 0.528333842754364\n",
      "Batch: 12737 Loss: 0.44793501496315\n",
      "Batch: 12801 Loss: 0.37451934814453125\n",
      "Batch: 12865 Loss: 0.3133493959903717\n",
      "Batch: 12929 Loss: 0.6372382044792175\n",
      "Epoch: 40\n",
      "Batch: 1 Loss: 0.398100882768631\n",
      "Batch: 65 Loss: 0.45963311195373535\n",
      "Batch: 129 Loss: 0.39194080233573914\n",
      "Batch: 193 Loss: 0.5839468240737915\n",
      "Batch: 257 Loss: 0.4208793342113495\n",
      "Batch: 321 Loss: 0.40496930480003357\n",
      "Batch: 385 Loss: 0.405853271484375\n",
      "Batch: 449 Loss: 0.3744012117385864\n",
      "Batch: 513 Loss: 0.38989531993865967\n",
      "Batch: 577 Loss: 0.3890675902366638\n",
      "Batch: 641 Loss: 0.4662681221961975\n",
      "Batch: 705 Loss: 0.4096706807613373\n",
      "Batch: 769 Loss: 0.45760661363601685\n",
      "Batch: 833 Loss: 0.33788663148880005\n",
      "Batch: 897 Loss: 0.56606525182724\n",
      "Batch: 961 Loss: 0.3652520477771759\n",
      "Batch: 1025 Loss: 0.3980381190776825\n",
      "Batch: 1089 Loss: 0.39058545231819153\n",
      "Batch: 1153 Loss: 0.4263773560523987\n",
      "Batch: 1217 Loss: 0.38496965169906616\n",
      "Batch: 1281 Loss: 0.4139835834503174\n",
      "Batch: 1345 Loss: 0.42511120438575745\n",
      "Batch: 1409 Loss: 0.3563518524169922\n",
      "Batch: 1473 Loss: 0.40441492199897766\n",
      "Batch: 1537 Loss: 0.3826751410961151\n",
      "Batch: 1601 Loss: 0.3267160952091217\n",
      "Batch: 1665 Loss: 0.3657623529434204\n",
      "Batch: 1729 Loss: 0.42769891023635864\n",
      "Batch: 1793 Loss: 0.3344632387161255\n",
      "Batch: 1857 Loss: 0.3785209655761719\n",
      "Batch: 1921 Loss: 0.4209521412849426\n",
      "Batch: 1985 Loss: 0.3603988289833069\n",
      "Batch: 2049 Loss: 0.3328819274902344\n",
      "Batch: 2113 Loss: 0.3596191108226776\n",
      "Batch: 2177 Loss: 0.393642395734787\n",
      "Batch: 2241 Loss: 0.43766841292381287\n",
      "Batch: 2305 Loss: 0.45270049571990967\n",
      "Batch: 2369 Loss: 0.47052475810050964\n",
      "Batch: 2433 Loss: 0.4294672906398773\n",
      "Batch: 2497 Loss: 0.4883306622505188\n",
      "Batch: 2561 Loss: 0.4028177857398987\n",
      "Batch: 2625 Loss: 0.42031383514404297\n",
      "Batch: 2689 Loss: 0.4359702467918396\n",
      "Batch: 2753 Loss: 0.3532969653606415\n",
      "Batch: 2817 Loss: 0.52211594581604\n",
      "Batch: 2881 Loss: 0.4432559609413147\n",
      "Batch: 2945 Loss: 0.3877980709075928\n",
      "Batch: 3009 Loss: 0.5475338697433472\n",
      "Batch: 3073 Loss: 0.4305017590522766\n",
      "Batch: 3137 Loss: 0.39436113834381104\n",
      "Batch: 3201 Loss: 0.3799193203449249\n",
      "Batch: 3265 Loss: 0.3680001199245453\n",
      "Batch: 3329 Loss: 0.39975282549858093\n",
      "Batch: 3393 Loss: 0.42229336500167847\n",
      "Batch: 3457 Loss: 0.3865998089313507\n",
      "Batch: 3521 Loss: 0.2991238832473755\n",
      "Batch: 3585 Loss: 0.28585392236709595\n",
      "Batch: 3649 Loss: 0.4643469750881195\n",
      "Batch: 3713 Loss: 0.3849579095840454\n",
      "Batch: 3777 Loss: 0.40686243772506714\n",
      "Batch: 3841 Loss: 0.40566837787628174\n",
      "Batch: 3905 Loss: 0.37376266717910767\n",
      "Batch: 3969 Loss: 0.5192710757255554\n",
      "Batch: 4033 Loss: 0.39192280173301697\n",
      "Batch: 4097 Loss: 0.3907845914363861\n",
      "Batch: 4161 Loss: 0.45021429657936096\n",
      "Batch: 4225 Loss: 0.3303264379501343\n",
      "Batch: 4289 Loss: 0.3522716462612152\n",
      "Batch: 4353 Loss: 0.4792913496494293\n",
      "Batch: 4417 Loss: 0.6103471517562866\n",
      "Batch: 4481 Loss: 0.6594492197036743\n",
      "Batch: 4545 Loss: 0.5353921055793762\n",
      "Batch: 4609 Loss: 0.3670792877674103\n",
      "Batch: 4673 Loss: 0.34641706943511963\n",
      "Batch: 4737 Loss: 0.44524767994880676\n",
      "Batch: 4801 Loss: 0.36115461587905884\n",
      "Batch: 4865 Loss: 0.3505421280860901\n",
      "Batch: 4929 Loss: 0.4015258550643921\n",
      "Batch: 4993 Loss: 0.509077250957489\n",
      "Batch: 5057 Loss: 0.4940389096736908\n",
      "Batch: 5121 Loss: 0.38658520579338074\n",
      "Batch: 5185 Loss: 0.8460317850112915\n",
      "Batch: 5249 Loss: 0.3652311861515045\n",
      "Batch: 5313 Loss: 0.43656590580940247\n",
      "Batch: 5377 Loss: 0.42227616906166077\n",
      "Batch: 5441 Loss: 0.5355016589164734\n",
      "Batch: 5505 Loss: 0.47661879658699036\n",
      "Batch: 5569 Loss: 0.5111148357391357\n",
      "Batch: 5633 Loss: 0.3860892653465271\n",
      "Batch: 5697 Loss: 0.43450984358787537\n",
      "Batch: 5761 Loss: 0.5492702722549438\n",
      "Batch: 5825 Loss: 0.42644640803337097\n",
      "Batch: 5889 Loss: 0.3814879357814789\n",
      "Batch: 5953 Loss: 0.38357576727867126\n",
      "Batch: 6017 Loss: 0.32131072878837585\n",
      "Batch: 6081 Loss: 0.29895228147506714\n",
      "Batch: 6145 Loss: 0.41393736004829407\n",
      "Batch: 6209 Loss: 0.34131333231925964\n",
      "Batch: 6273 Loss: 0.4572540819644928\n",
      "Batch: 6337 Loss: 0.3307819962501526\n",
      "Batch: 6401 Loss: 0.33345213532447815\n",
      "Batch: 6465 Loss: 0.37457478046417236\n",
      "Batch: 6529 Loss: 0.35239970684051514\n",
      "Batch: 6593 Loss: 0.3746688663959503\n",
      "Batch: 6657 Loss: 0.3096509873867035\n",
      "Batch: 6721 Loss: 0.41671010851860046\n",
      "Batch: 6785 Loss: 0.41037750244140625\n",
      "Batch: 6849 Loss: 0.4095441401004791\n",
      "Batch: 6913 Loss: 0.3909054398536682\n",
      "Batch: 6977 Loss: 0.42570143938064575\n",
      "Batch: 7041 Loss: 0.41583603620529175\n",
      "Batch: 7105 Loss: 0.33239492774009705\n",
      "Batch: 7169 Loss: 0.39344558119773865\n",
      "Batch: 7233 Loss: 0.3485352396965027\n",
      "Batch: 7297 Loss: 0.411393940448761\n",
      "Batch: 7361 Loss: 0.38326695561408997\n",
      "Batch: 7425 Loss: 0.4668826460838318\n",
      "Batch: 7489 Loss: 0.560005247592926\n",
      "Batch: 7553 Loss: 0.36447587609291077\n",
      "Batch: 7617 Loss: 0.36326974630355835\n",
      "Batch: 7681 Loss: 0.4402374029159546\n",
      "Batch: 7745 Loss: 0.45271244645118713\n",
      "Batch: 7809 Loss: 0.41574108600616455\n",
      "Batch: 7873 Loss: 0.32862386107444763\n",
      "Batch: 7937 Loss: 0.5376924276351929\n",
      "Batch: 8001 Loss: 0.39169347286224365\n",
      "Batch: 8065 Loss: 0.5361800193786621\n",
      "Batch: 8129 Loss: 0.3946264386177063\n",
      "Batch: 8193 Loss: 0.43624281883239746\n",
      "Batch: 8257 Loss: 0.46304628252983093\n",
      "Batch: 8321 Loss: 0.6312088370323181\n",
      "Batch: 8385 Loss: 0.3107123076915741\n",
      "Batch: 8449 Loss: 0.3459424674510956\n",
      "Batch: 8513 Loss: 0.6317738890647888\n",
      "Batch: 8577 Loss: 0.3232017755508423\n",
      "Batch: 8641 Loss: 0.48929619789123535\n",
      "Batch: 8705 Loss: 0.4007316529750824\n",
      "Batch: 8769 Loss: 0.4621843993663788\n",
      "Batch: 8833 Loss: 0.539447009563446\n",
      "Batch: 8897 Loss: 0.7905236482620239\n",
      "Batch: 8961 Loss: 0.39132159948349\n",
      "Batch: 9025 Loss: 0.38697317242622375\n",
      "Batch: 9089 Loss: 0.3979945480823517\n",
      "Batch: 9153 Loss: 0.4617680609226227\n",
      "Batch: 9217 Loss: 0.49491554498672485\n",
      "Batch: 9281 Loss: 0.44738346338272095\n",
      "Batch: 9345 Loss: 0.3571294844150543\n",
      "Batch: 9409 Loss: 0.4827987253665924\n",
      "Batch: 9473 Loss: 0.5423254370689392\n",
      "Batch: 9537 Loss: 0.4638632535934448\n",
      "Batch: 9601 Loss: 0.3603440225124359\n",
      "Batch: 9665 Loss: 0.33424851298332214\n",
      "Batch: 9729 Loss: 0.4337025284767151\n",
      "Batch: 9793 Loss: 0.37741318345069885\n",
      "Batch: 9857 Loss: 0.4269011914730072\n",
      "Batch: 9921 Loss: 0.39463284611701965\n",
      "Batch: 9985 Loss: 0.43184882402420044\n",
      "Batch: 10049 Loss: 0.4985760450363159\n",
      "Batch: 10113 Loss: 0.38819408416748047\n",
      "Batch: 10177 Loss: 0.4886661171913147\n",
      "Batch: 10241 Loss: 0.36327534914016724\n",
      "Batch: 10305 Loss: 0.43682751059532166\n",
      "Batch: 10369 Loss: 0.4798772633075714\n",
      "Batch: 10433 Loss: 0.39883944392204285\n",
      "Batch: 10497 Loss: 0.3916681408882141\n",
      "Batch: 10561 Loss: 0.36533135175704956\n",
      "Batch: 10625 Loss: 0.43284499645233154\n",
      "Batch: 10689 Loss: 0.414417028427124\n",
      "Batch: 10753 Loss: 0.3499045968055725\n",
      "Batch: 10817 Loss: 0.30911320447921753\n",
      "Batch: 10881 Loss: 0.3555811941623688\n",
      "Batch: 10945 Loss: 0.33225172758102417\n",
      "Batch: 11009 Loss: 0.3819755017757416\n",
      "Batch: 11073 Loss: 0.4466046988964081\n",
      "Batch: 11137 Loss: 0.3498242199420929\n",
      "Batch: 11201 Loss: 0.36321234703063965\n",
      "Batch: 11265 Loss: 0.5087475180625916\n",
      "Batch: 11329 Loss: 0.6360583305358887\n",
      "Batch: 11393 Loss: 0.27893462777137756\n",
      "Batch: 11457 Loss: 0.3576006293296814\n",
      "Batch: 11521 Loss: 0.3723001480102539\n",
      "Batch: 11585 Loss: 0.4905303120613098\n",
      "Batch: 11649 Loss: 0.3219859302043915\n",
      "Batch: 11713 Loss: 0.4144737720489502\n",
      "Batch: 11777 Loss: 0.598450779914856\n",
      "Batch: 11841 Loss: 0.5598995089530945\n",
      "Batch: 11905 Loss: 0.4350639581680298\n",
      "Batch: 11969 Loss: 0.40370577573776245\n",
      "Batch: 12033 Loss: 0.37286075949668884\n",
      "Batch: 12097 Loss: 0.9108337759971619\n",
      "Batch: 12161 Loss: 0.501765787601471\n",
      "Batch: 12225 Loss: 0.29500827193260193\n",
      "Batch: 12289 Loss: 0.309626042842865\n",
      "Batch: 12353 Loss: 0.4095565974712372\n",
      "Batch: 12417 Loss: 0.3419811427593231\n",
      "Batch: 12481 Loss: 0.3781910240650177\n",
      "Batch: 12545 Loss: 0.4755260944366455\n",
      "Batch: 12609 Loss: 0.5146010518074036\n",
      "Batch: 12673 Loss: 0.5284886360168457\n",
      "Batch: 12737 Loss: 0.4484802186489105\n",
      "Batch: 12801 Loss: 0.3686712682247162\n",
      "Batch: 12865 Loss: 0.3124966323375702\n",
      "Batch: 12929 Loss: 0.6433534026145935\n",
      "Epoch: 41\n",
      "Batch: 1 Loss: 0.39771002531051636\n",
      "Batch: 65 Loss: 0.4583422839641571\n",
      "Batch: 129 Loss: 0.3898527920246124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 193 Loss: 0.581304132938385\n",
      "Batch: 257 Loss: 0.41858887672424316\n",
      "Batch: 321 Loss: 0.40383854508399963\n",
      "Batch: 385 Loss: 0.40682193636894226\n",
      "Batch: 449 Loss: 0.3749794363975525\n",
      "Batch: 513 Loss: 0.38951215147972107\n",
      "Batch: 577 Loss: 0.3883896470069885\n",
      "Batch: 641 Loss: 0.4640982449054718\n",
      "Batch: 705 Loss: 0.4075598418712616\n",
      "Batch: 769 Loss: 0.4555002748966217\n",
      "Batch: 833 Loss: 0.33502036333084106\n",
      "Batch: 897 Loss: 0.5652174949645996\n",
      "Batch: 961 Loss: 0.36118069291114807\n",
      "Batch: 1025 Loss: 0.3960905075073242\n",
      "Batch: 1089 Loss: 0.38972020149230957\n",
      "Batch: 1153 Loss: 0.4238855242729187\n",
      "Batch: 1217 Loss: 0.3829364478588104\n",
      "Batch: 1281 Loss: 0.4144115149974823\n",
      "Batch: 1345 Loss: 0.4229642152786255\n",
      "Batch: 1409 Loss: 0.35599285364151\n",
      "Batch: 1473 Loss: 0.4027658998966217\n",
      "Batch: 1537 Loss: 0.3828633725643158\n",
      "Batch: 1601 Loss: 0.32485198974609375\n",
      "Batch: 1665 Loss: 0.36664509773254395\n",
      "Batch: 1729 Loss: 0.42638686299324036\n",
      "Batch: 1793 Loss: 0.33369505405426025\n",
      "Batch: 1857 Loss: 0.3770066499710083\n",
      "Batch: 1921 Loss: 0.41913744807243347\n",
      "Batch: 1985 Loss: 0.36167094111442566\n",
      "Batch: 2049 Loss: 0.33185306191444397\n",
      "Batch: 2113 Loss: 0.3526831567287445\n",
      "Batch: 2177 Loss: 0.3923439383506775\n",
      "Batch: 2241 Loss: 0.43631991744041443\n",
      "Batch: 2305 Loss: 0.45361238718032837\n",
      "Batch: 2369 Loss: 0.46900761127471924\n",
      "Batch: 2433 Loss: 0.4293656051158905\n",
      "Batch: 2497 Loss: 0.4867050349712372\n",
      "Batch: 2561 Loss: 0.4018494784832001\n",
      "Batch: 2625 Loss: 0.4205300211906433\n",
      "Batch: 2689 Loss: 0.4353260397911072\n",
      "Batch: 2753 Loss: 0.3539319336414337\n",
      "Batch: 2817 Loss: 0.5189215540885925\n",
      "Batch: 2881 Loss: 0.44177818298339844\n",
      "Batch: 2945 Loss: 0.38399192690849304\n",
      "Batch: 3009 Loss: 0.5451192259788513\n",
      "Batch: 3073 Loss: 0.4283472001552582\n",
      "Batch: 3137 Loss: 0.3934919238090515\n",
      "Batch: 3201 Loss: 0.37932291626930237\n",
      "Batch: 3265 Loss: 0.36691516637802124\n",
      "Batch: 3329 Loss: 0.39862483739852905\n",
      "Batch: 3393 Loss: 0.4216325581073761\n",
      "Batch: 3457 Loss: 0.38732632994651794\n",
      "Batch: 3521 Loss: 0.29945874214172363\n",
      "Batch: 3585 Loss: 0.282936692237854\n",
      "Batch: 3649 Loss: 0.46451863646507263\n",
      "Batch: 3713 Loss: 0.3843682110309601\n",
      "Batch: 3777 Loss: 0.40540972352027893\n",
      "Batch: 3841 Loss: 0.4066014885902405\n",
      "Batch: 3905 Loss: 0.374203085899353\n",
      "Batch: 3969 Loss: 0.51889568567276\n",
      "Batch: 4033 Loss: 0.3904237449169159\n",
      "Batch: 4097 Loss: 0.389411985874176\n",
      "Batch: 4161 Loss: 0.4492090940475464\n",
      "Batch: 4225 Loss: 0.32959648966789246\n",
      "Batch: 4289 Loss: 0.35165658593177795\n",
      "Batch: 4353 Loss: 0.47708210349082947\n",
      "Batch: 4417 Loss: 0.6075628995895386\n",
      "Batch: 4481 Loss: 0.6569579243659973\n",
      "Batch: 4545 Loss: 0.5346983671188354\n",
      "Batch: 4609 Loss: 0.3677669167518616\n",
      "Batch: 4673 Loss: 0.34662628173828125\n",
      "Batch: 4737 Loss: 0.4447072148323059\n",
      "Batch: 4801 Loss: 0.36111849546432495\n",
      "Batch: 4865 Loss: 0.3505951464176178\n",
      "Batch: 4929 Loss: 0.4003218114376068\n",
      "Batch: 4993 Loss: 0.508905291557312\n",
      "Batch: 5057 Loss: 0.49585410952568054\n",
      "Batch: 5121 Loss: 0.3854195475578308\n",
      "Batch: 5185 Loss: 0.8412483334541321\n",
      "Batch: 5249 Loss: 0.36485564708709717\n",
      "Batch: 5313 Loss: 0.43645617365837097\n",
      "Batch: 5377 Loss: 0.42052391171455383\n",
      "Batch: 5441 Loss: 0.5299583077430725\n",
      "Batch: 5505 Loss: 0.4804050624370575\n",
      "Batch: 5569 Loss: 0.5208498239517212\n",
      "Batch: 5633 Loss: 0.390577107667923\n",
      "Batch: 5697 Loss: 0.4571787416934967\n",
      "Batch: 5761 Loss: 0.5565195679664612\n",
      "Batch: 5825 Loss: 0.426242470741272\n",
      "Batch: 5889 Loss: 0.3812221884727478\n",
      "Batch: 5953 Loss: 0.3833826780319214\n",
      "Batch: 6017 Loss: 0.3201570212841034\n",
      "Batch: 6081 Loss: 0.29448941349983215\n",
      "Batch: 6145 Loss: 0.4141438603401184\n",
      "Batch: 6209 Loss: 0.3404039144515991\n",
      "Batch: 6273 Loss: 0.4560394287109375\n",
      "Batch: 6337 Loss: 0.33031144738197327\n",
      "Batch: 6401 Loss: 0.3339642584323883\n",
      "Batch: 6465 Loss: 0.37421953678131104\n",
      "Batch: 6529 Loss: 0.3526575565338135\n",
      "Batch: 6593 Loss: 0.3722911775112152\n",
      "Batch: 6657 Loss: 0.3089267313480377\n",
      "Batch: 6721 Loss: 0.416799932718277\n",
      "Batch: 6785 Loss: 0.4094166159629822\n",
      "Batch: 6849 Loss: 0.4086351692676544\n",
      "Batch: 6913 Loss: 0.3905876576900482\n",
      "Batch: 6977 Loss: 0.4251782298088074\n",
      "Batch: 7041 Loss: 0.4148731827735901\n",
      "Batch: 7105 Loss: 0.3348000943660736\n",
      "Batch: 7169 Loss: 0.39327529072761536\n",
      "Batch: 7233 Loss: 0.3465973734855652\n",
      "Batch: 7297 Loss: 0.4111119210720062\n",
      "Batch: 7361 Loss: 0.38319340348243713\n",
      "Batch: 7425 Loss: 0.4662569463253021\n",
      "Batch: 7489 Loss: 0.5601240992546082\n",
      "Batch: 7553 Loss: 0.36466383934020996\n",
      "Batch: 7617 Loss: 0.3641468286514282\n",
      "Batch: 7681 Loss: 0.44073721766471863\n",
      "Batch: 7745 Loss: 0.4525434374809265\n",
      "Batch: 7809 Loss: 0.41624781489372253\n",
      "Batch: 7873 Loss: 0.3288750946521759\n",
      "Batch: 7937 Loss: 0.5437353849411011\n",
      "Batch: 8001 Loss: 0.39769241213798523\n",
      "Batch: 8065 Loss: 0.5381125211715698\n",
      "Batch: 8129 Loss: 0.3992789089679718\n",
      "Batch: 8193 Loss: 0.4354889690876007\n",
      "Batch: 8257 Loss: 0.4627193212509155\n",
      "Batch: 8321 Loss: 0.6307945251464844\n",
      "Batch: 8385 Loss: 0.31069350242614746\n",
      "Batch: 8449 Loss: 0.34588563442230225\n",
      "Batch: 8513 Loss: 0.6313487887382507\n",
      "Batch: 8577 Loss: 0.3271966874599457\n",
      "Batch: 8641 Loss: 0.4855377674102783\n",
      "Batch: 8705 Loss: 0.3910822570323944\n",
      "Batch: 8769 Loss: 0.4602411389350891\n",
      "Batch: 8833 Loss: 0.5179912447929382\n",
      "Batch: 8897 Loss: 0.787662148475647\n",
      "Batch: 8961 Loss: 0.3920114040374756\n",
      "Batch: 9025 Loss: 0.3868022561073303\n",
      "Batch: 9089 Loss: 0.39734309911727905\n",
      "Batch: 9153 Loss: 0.45726916193962097\n",
      "Batch: 9217 Loss: 0.5019434690475464\n",
      "Batch: 9281 Loss: 0.4507841169834137\n",
      "Batch: 9345 Loss: 0.35569247603416443\n",
      "Batch: 9409 Loss: 0.48138365149497986\n",
      "Batch: 9473 Loss: 0.5415944457054138\n",
      "Batch: 9537 Loss: 0.46261927485466003\n",
      "Batch: 9601 Loss: 0.3584725260734558\n",
      "Batch: 9665 Loss: 0.33509522676467896\n",
      "Batch: 9729 Loss: 0.4335668683052063\n",
      "Batch: 9793 Loss: 0.37731578946113586\n",
      "Batch: 9857 Loss: 0.42685797810554504\n",
      "Batch: 9921 Loss: 0.3921974003314972\n",
      "Batch: 9985 Loss: 0.4331550598144531\n",
      "Batch: 10049 Loss: 0.498907208442688\n",
      "Batch: 10113 Loss: 0.38748544454574585\n",
      "Batch: 10177 Loss: 0.4845476746559143\n",
      "Batch: 10241 Loss: 0.3630995452404022\n",
      "Batch: 10305 Loss: 0.4366554021835327\n",
      "Batch: 10369 Loss: 0.47935569286346436\n",
      "Batch: 10433 Loss: 0.39882171154022217\n",
      "Batch: 10497 Loss: 0.39210745692253113\n",
      "Batch: 10561 Loss: 0.3649980127811432\n",
      "Batch: 10625 Loss: 0.4292021095752716\n",
      "Batch: 10689 Loss: 0.41644635796546936\n",
      "Batch: 10753 Loss: 0.3512338697910309\n",
      "Batch: 10817 Loss: 0.3089403510093689\n",
      "Batch: 10881 Loss: 0.3656459450721741\n",
      "Batch: 10945 Loss: 0.3258422613143921\n",
      "Batch: 11009 Loss: 0.3698626458644867\n",
      "Batch: 11073 Loss: 0.4308062493801117\n",
      "Batch: 11137 Loss: 0.35158446431159973\n",
      "Batch: 11201 Loss: 0.3615188002586365\n",
      "Batch: 11265 Loss: 0.5093300938606262\n",
      "Batch: 11329 Loss: 0.6542767286300659\n",
      "Batch: 11393 Loss: 0.2796427607536316\n",
      "Batch: 11457 Loss: 0.35857459902763367\n",
      "Batch: 11521 Loss: 0.37218669056892395\n",
      "Batch: 11585 Loss: 0.4906941056251526\n",
      "Batch: 11649 Loss: 0.32157668471336365\n",
      "Batch: 11713 Loss: 0.4144739806652069\n",
      "Batch: 11777 Loss: 0.598091185092926\n",
      "Batch: 11841 Loss: 0.5534164309501648\n",
      "Batch: 11905 Loss: 0.43566957116127014\n",
      "Batch: 11969 Loss: 0.40093421936035156\n",
      "Batch: 12033 Loss: 0.3730177581310272\n",
      "Batch: 12097 Loss: 0.9184877872467041\n",
      "Batch: 12161 Loss: 0.5109108686447144\n",
      "Batch: 12225 Loss: 0.2942880392074585\n",
      "Batch: 12289 Loss: 0.3065224885940552\n",
      "Batch: 12353 Loss: 0.40891191363334656\n",
      "Batch: 12417 Loss: 0.3422997295856476\n",
      "Batch: 12481 Loss: 0.37878406047821045\n",
      "Batch: 12545 Loss: 0.47544023394584656\n",
      "Batch: 12609 Loss: 0.512397050857544\n",
      "Batch: 12673 Loss: 0.5282173156738281\n",
      "Batch: 12737 Loss: 0.4478701651096344\n",
      "Batch: 12801 Loss: 0.3691800832748413\n",
      "Batch: 12865 Loss: 0.3118704855442047\n",
      "Batch: 12929 Loss: 0.6405223608016968\n",
      "Epoch: 42\n",
      "Batch: 1 Loss: 0.39832746982574463\n",
      "Batch: 65 Loss: 0.4588763415813446\n",
      "Batch: 129 Loss: 0.3909913897514343\n",
      "Batch: 193 Loss: 0.582289457321167\n",
      "Batch: 257 Loss: 0.41706496477127075\n",
      "Batch: 321 Loss: 0.4029265344142914\n",
      "Batch: 385 Loss: 0.40567976236343384\n",
      "Batch: 449 Loss: 0.37535566091537476\n",
      "Batch: 513 Loss: 0.3889482617378235\n",
      "Batch: 577 Loss: 0.38764041662216187\n",
      "Batch: 641 Loss: 0.46316418051719666\n",
      "Batch: 705 Loss: 0.4064745604991913\n",
      "Batch: 769 Loss: 0.45428329706192017\n",
      "Batch: 833 Loss: 0.3331320285797119\n",
      "Batch: 897 Loss: 0.564176619052887\n",
      "Batch: 961 Loss: 0.3588855266571045\n",
      "Batch: 1025 Loss: 0.3972541391849518\n",
      "Batch: 1089 Loss: 0.3915509283542633\n",
      "Batch: 1153 Loss: 0.42525485157966614\n",
      "Batch: 1217 Loss: 0.38381659984588623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1281 Loss: 0.4143387973308563\n",
      "Batch: 1345 Loss: 0.42364048957824707\n",
      "Batch: 1409 Loss: 0.3563632369041443\n",
      "Batch: 1473 Loss: 0.4065759778022766\n",
      "Batch: 1537 Loss: 0.3840969502925873\n",
      "Batch: 1601 Loss: 0.32867518067359924\n",
      "Batch: 1665 Loss: 0.365949809551239\n",
      "Batch: 1729 Loss: 0.42941516637802124\n",
      "Batch: 1793 Loss: 0.33366331458091736\n",
      "Batch: 1857 Loss: 0.37686407566070557\n",
      "Batch: 1921 Loss: 0.41873112320899963\n",
      "Batch: 1985 Loss: 0.3675687313079834\n",
      "Batch: 2049 Loss: 0.33688536286354065\n",
      "Batch: 2113 Loss: 0.36435768008232117\n",
      "Batch: 2177 Loss: 0.3926634192466736\n",
      "Batch: 2241 Loss: 0.4385468363761902\n",
      "Batch: 2305 Loss: 0.4533737301826477\n",
      "Batch: 2369 Loss: 0.46876776218414307\n",
      "Batch: 2433 Loss: 0.43277424573898315\n",
      "Batch: 2497 Loss: 0.49222633242607117\n",
      "Batch: 2561 Loss: 0.4031527042388916\n",
      "Batch: 2625 Loss: 0.42060261964797974\n",
      "Batch: 2689 Loss: 0.43595534563064575\n",
      "Batch: 2753 Loss: 0.35969698429107666\n",
      "Batch: 2817 Loss: 0.5194124579429626\n",
      "Batch: 2881 Loss: 0.45058250427246094\n",
      "Batch: 2945 Loss: 0.3919963836669922\n",
      "Batch: 3009 Loss: 0.5457743406295776\n",
      "Batch: 3073 Loss: 0.4280111789703369\n",
      "Batch: 3137 Loss: 0.3933795690536499\n",
      "Batch: 3201 Loss: 0.3812785744667053\n",
      "Batch: 3265 Loss: 0.36866000294685364\n",
      "Batch: 3329 Loss: 0.39891764521598816\n",
      "Batch: 3393 Loss: 0.42218026518821716\n",
      "Batch: 3457 Loss: 0.38761863112449646\n",
      "Batch: 3521 Loss: 0.29859381914138794\n",
      "Batch: 3585 Loss: 0.2849518954753876\n",
      "Batch: 3649 Loss: 0.4645574688911438\n",
      "Batch: 3713 Loss: 0.3837742209434509\n",
      "Batch: 3777 Loss: 0.405091255903244\n",
      "Batch: 3841 Loss: 0.4056715667247772\n",
      "Batch: 3905 Loss: 0.3723912537097931\n",
      "Batch: 3969 Loss: 0.517078161239624\n",
      "Batch: 4033 Loss: 0.38854771852493286\n",
      "Batch: 4097 Loss: 0.3892948627471924\n",
      "Batch: 4161 Loss: 0.4506571888923645\n",
      "Batch: 4225 Loss: 0.33041438460350037\n",
      "Batch: 4289 Loss: 0.3539689779281616\n",
      "Batch: 4353 Loss: 0.47741422057151794\n",
      "Batch: 4417 Loss: 0.6075890064239502\n",
      "Batch: 4481 Loss: 0.656307578086853\n",
      "Batch: 4545 Loss: 0.5342320799827576\n",
      "Batch: 4609 Loss: 0.3677411377429962\n",
      "Batch: 4673 Loss: 0.3468697965145111\n",
      "Batch: 4737 Loss: 0.44410330057144165\n",
      "Batch: 4801 Loss: 0.3609030544757843\n",
      "Batch: 4865 Loss: 0.3505787253379822\n",
      "Batch: 4929 Loss: 0.3995441496372223\n",
      "Batch: 4993 Loss: 0.5080185532569885\n",
      "Batch: 5057 Loss: 0.49496379494667053\n",
      "Batch: 5121 Loss: 0.38693422079086304\n",
      "Batch: 5185 Loss: 0.8416765928268433\n",
      "Batch: 5249 Loss: 0.3656115233898163\n",
      "Batch: 5313 Loss: 0.43569236993789673\n",
      "Batch: 5377 Loss: 0.4225708246231079\n",
      "Batch: 5441 Loss: 0.5235034823417664\n",
      "Batch: 5505 Loss: 0.47948092222213745\n",
      "Batch: 5569 Loss: 0.5189636945724487\n",
      "Batch: 5633 Loss: 0.3906043469905853\n",
      "Batch: 5697 Loss: 0.43762239813804626\n",
      "Batch: 5761 Loss: 0.549514651298523\n",
      "Batch: 5825 Loss: 0.42680802941322327\n",
      "Batch: 5889 Loss: 0.38109028339385986\n",
      "Batch: 5953 Loss: 0.38315680623054504\n",
      "Batch: 6017 Loss: 0.3210526704788208\n",
      "Batch: 6081 Loss: 0.2955033481121063\n",
      "Batch: 6145 Loss: 0.41053348779678345\n",
      "Batch: 6209 Loss: 0.34783223271369934\n",
      "Batch: 6273 Loss: 0.455521821975708\n",
      "Batch: 6337 Loss: 0.33142128586769104\n",
      "Batch: 6401 Loss: 0.33342644572257996\n",
      "Batch: 6465 Loss: 0.37381598353385925\n",
      "Batch: 6529 Loss: 0.3530194163322449\n",
      "Batch: 6593 Loss: 0.37399765849113464\n",
      "Batch: 6657 Loss: 0.30867329239845276\n",
      "Batch: 6721 Loss: 0.41954168677330017\n",
      "Batch: 6785 Loss: 0.42591241002082825\n",
      "Batch: 6849 Loss: 0.40848129987716675\n",
      "Batch: 6913 Loss: 0.3908441662788391\n",
      "Batch: 6977 Loss: 0.426474928855896\n",
      "Batch: 7041 Loss: 0.41722118854522705\n",
      "Batch: 7105 Loss: 0.3318246006965637\n",
      "Batch: 7169 Loss: 0.400012344121933\n",
      "Batch: 7233 Loss: 0.35263535380363464\n",
      "Batch: 7297 Loss: 0.4120631814002991\n",
      "Batch: 7361 Loss: 0.3821985721588135\n",
      "Batch: 7425 Loss: 0.4687761962413788\n",
      "Batch: 7489 Loss: 0.5599576830863953\n",
      "Batch: 7553 Loss: 0.3640029728412628\n",
      "Batch: 7617 Loss: 0.3626002073287964\n",
      "Batch: 7681 Loss: 0.4384801685810089\n",
      "Batch: 7745 Loss: 0.4526822566986084\n",
      "Batch: 7809 Loss: 0.41594257950782776\n",
      "Batch: 7873 Loss: 0.3285238444805145\n",
      "Batch: 7937 Loss: 0.5374993085861206\n",
      "Batch: 8001 Loss: 0.3933023512363434\n",
      "Batch: 8065 Loss: 0.5394306182861328\n",
      "Batch: 8129 Loss: 0.39635059237480164\n",
      "Batch: 8193 Loss: 0.4379485845565796\n",
      "Batch: 8257 Loss: 0.461525022983551\n",
      "Batch: 8321 Loss: 0.6319901347160339\n",
      "Batch: 8385 Loss: 0.3107225298881531\n",
      "Batch: 8449 Loss: 0.3457680642604828\n",
      "Batch: 8513 Loss: 0.6314067244529724\n",
      "Batch: 8577 Loss: 0.3227563798427582\n",
      "Batch: 8641 Loss: 0.4902176260948181\n",
      "Batch: 8705 Loss: 0.3922913372516632\n",
      "Batch: 8769 Loss: 0.45989105105400085\n",
      "Batch: 8833 Loss: 0.5170609354972839\n",
      "Batch: 8897 Loss: 0.7872008085250854\n",
      "Batch: 8961 Loss: 0.39175987243652344\n",
      "Batch: 9025 Loss: 0.3866961598396301\n",
      "Batch: 9089 Loss: 0.3977375328540802\n",
      "Batch: 9153 Loss: 0.457278847694397\n",
      "Batch: 9217 Loss: 0.49276119470596313\n",
      "Batch: 9281 Loss: 0.44508299231529236\n",
      "Batch: 9345 Loss: 0.35042163729667664\n",
      "Batch: 9409 Loss: 0.48120182752609253\n",
      "Batch: 9473 Loss: 0.5424513220787048\n",
      "Batch: 9537 Loss: 0.46923497319221497\n",
      "Batch: 9601 Loss: 0.3583570420742035\n",
      "Batch: 9665 Loss: 0.3343294858932495\n",
      "Batch: 9729 Loss: 0.4341798722743988\n",
      "Batch: 9793 Loss: 0.3778994679450989\n",
      "Batch: 9857 Loss: 0.4270406663417816\n",
      "Batch: 9921 Loss: 0.3923948407173157\n",
      "Batch: 9985 Loss: 0.4319505989551544\n",
      "Batch: 10049 Loss: 0.4990284740924835\n",
      "Batch: 10113 Loss: 0.38799726963043213\n",
      "Batch: 10177 Loss: 0.47000059485435486\n",
      "Batch: 10241 Loss: 0.3640134930610657\n",
      "Batch: 10305 Loss: 0.4371874928474426\n",
      "Batch: 10369 Loss: 0.47916245460510254\n",
      "Batch: 10433 Loss: 0.39904865622520447\n",
      "Batch: 10497 Loss: 0.39192867279052734\n",
      "Batch: 10561 Loss: 0.36486607789993286\n",
      "Batch: 10625 Loss: 0.42872747778892517\n",
      "Batch: 10689 Loss: 0.40223780274391174\n",
      "Batch: 10753 Loss: 0.35040804743766785\n",
      "Batch: 10817 Loss: 0.3088866174221039\n",
      "Batch: 10881 Loss: 0.3516876697540283\n",
      "Batch: 10945 Loss: 0.32471147179603577\n",
      "Batch: 11009 Loss: 0.3640860319137573\n",
      "Batch: 11073 Loss: 0.4402850270271301\n",
      "Batch: 11137 Loss: 0.34946227073669434\n",
      "Batch: 11201 Loss: 0.36574381589889526\n",
      "Batch: 11265 Loss: 0.5086632370948792\n",
      "Batch: 11329 Loss: 0.6523092985153198\n",
      "Batch: 11393 Loss: 0.27954456210136414\n",
      "Batch: 11457 Loss: 0.3580634891986847\n",
      "Batch: 11521 Loss: 0.3721872568130493\n",
      "Batch: 11585 Loss: 0.49031904339790344\n",
      "Batch: 11649 Loss: 0.3214534521102905\n",
      "Batch: 11713 Loss: 0.4159686267375946\n",
      "Batch: 11777 Loss: 0.597029447555542\n",
      "Batch: 11841 Loss: 0.5677809119224548\n",
      "Batch: 11905 Loss: 0.43487653136253357\n",
      "Batch: 11969 Loss: 0.40142127871513367\n",
      "Batch: 12033 Loss: 0.3714134991168976\n",
      "Batch: 12097 Loss: 0.9135504961013794\n",
      "Batch: 12161 Loss: 0.5044683218002319\n",
      "Batch: 12225 Loss: 0.29431891441345215\n",
      "Batch: 12289 Loss: 0.3073762357234955\n",
      "Batch: 12353 Loss: 0.4093943238258362\n",
      "Batch: 12417 Loss: 0.34245765209198\n",
      "Batch: 12481 Loss: 0.3819524347782135\n",
      "Batch: 12545 Loss: 0.47519850730895996\n",
      "Batch: 12609 Loss: 0.51495361328125\n",
      "Batch: 12673 Loss: 0.5293344259262085\n",
      "Batch: 12737 Loss: 0.44910117983818054\n",
      "Batch: 12801 Loss: 0.3671025335788727\n",
      "Batch: 12865 Loss: 0.3117309808731079\n",
      "Batch: 12929 Loss: 0.6402105093002319\n",
      "Epoch: 43\n",
      "Batch: 1 Loss: 0.39852631092071533\n",
      "Batch: 65 Loss: 0.4594493508338928\n",
      "Batch: 129 Loss: 0.39134252071380615\n",
      "Batch: 193 Loss: 0.582528293132782\n",
      "Batch: 257 Loss: 0.4177516996860504\n",
      "Batch: 321 Loss: 0.4029790461063385\n",
      "Batch: 385 Loss: 0.40523794293403625\n",
      "Batch: 449 Loss: 0.37547481060028076\n",
      "Batch: 513 Loss: 0.3899984061717987\n",
      "Batch: 577 Loss: 0.3879174292087555\n",
      "Batch: 641 Loss: 0.4641575515270233\n",
      "Batch: 705 Loss: 0.4071590304374695\n",
      "Batch: 769 Loss: 0.4541366398334503\n",
      "Batch: 833 Loss: 0.33509451150894165\n",
      "Batch: 897 Loss: 0.5647926926612854\n",
      "Batch: 961 Loss: 0.3640212416648865\n",
      "Batch: 1025 Loss: 0.39637911319732666\n",
      "Batch: 1089 Loss: 0.39123860001564026\n",
      "Batch: 1153 Loss: 0.426006019115448\n",
      "Batch: 1217 Loss: 0.38413411378860474\n",
      "Batch: 1281 Loss: 0.4136488437652588\n",
      "Batch: 1345 Loss: 0.42332834005355835\n",
      "Batch: 1409 Loss: 0.3558240532875061\n",
      "Batch: 1473 Loss: 0.40385258197784424\n",
      "Batch: 1537 Loss: 0.3833548128604889\n",
      "Batch: 1601 Loss: 0.3244037330150604\n",
      "Batch: 1665 Loss: 0.36590078473091125\n",
      "Batch: 1729 Loss: 0.4267995357513428\n",
      "Batch: 1793 Loss: 0.3352085053920746\n",
      "Batch: 1857 Loss: 0.376213401556015\n",
      "Batch: 1921 Loss: 0.4179975986480713\n",
      "Batch: 1985 Loss: 0.35791611671447754\n",
      "Batch: 2049 Loss: 0.3331398069858551\n",
      "Batch: 2113 Loss: 0.35850226879119873\n",
      "Batch: 2177 Loss: 0.3917884826660156\n",
      "Batch: 2241 Loss: 0.435484915971756\n",
      "Batch: 2305 Loss: 0.4489295184612274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2369 Loss: 0.4668128788471222\n",
      "Batch: 2433 Loss: 0.42939722537994385\n",
      "Batch: 2497 Loss: 0.4874078929424286\n",
      "Batch: 2561 Loss: 0.40106484293937683\n",
      "Batch: 2625 Loss: 0.4211273193359375\n",
      "Batch: 2689 Loss: 0.43512919545173645\n",
      "Batch: 2753 Loss: 0.35265177488327026\n",
      "Batch: 2817 Loss: 0.5187493562698364\n",
      "Batch: 2881 Loss: 0.4416382610797882\n",
      "Batch: 2945 Loss: 0.3810639977455139\n",
      "Batch: 3009 Loss: 0.5428377389907837\n",
      "Batch: 3073 Loss: 0.42729637026786804\n",
      "Batch: 3137 Loss: 0.3918858766555786\n",
      "Batch: 3201 Loss: 0.3785717785358429\n",
      "Batch: 3265 Loss: 0.36667242646217346\n",
      "Batch: 3329 Loss: 0.3984203636646271\n",
      "Batch: 3393 Loss: 0.42075181007385254\n",
      "Batch: 3457 Loss: 0.3862503468990326\n",
      "Batch: 3521 Loss: 0.2993733882904053\n",
      "Batch: 3585 Loss: 0.2828212082386017\n",
      "Batch: 3649 Loss: 0.46339184045791626\n",
      "Batch: 3713 Loss: 0.383598268032074\n",
      "Batch: 3777 Loss: 0.4053623676300049\n",
      "Batch: 3841 Loss: 0.408075749874115\n",
      "Batch: 3905 Loss: 0.3813580572605133\n",
      "Batch: 3969 Loss: 0.524154782295227\n",
      "Batch: 4033 Loss: 0.38892853260040283\n",
      "Batch: 4097 Loss: 0.3898097276687622\n",
      "Batch: 4161 Loss: 0.4517785310745239\n",
      "Batch: 4225 Loss: 0.3298647105693817\n",
      "Batch: 4289 Loss: 0.35192328691482544\n",
      "Batch: 4353 Loss: 0.4765281677246094\n",
      "Batch: 4417 Loss: 0.6066559553146362\n",
      "Batch: 4481 Loss: 0.6562102437019348\n",
      "Batch: 4545 Loss: 0.5346096754074097\n",
      "Batch: 4609 Loss: 0.3680172264575958\n",
      "Batch: 4673 Loss: 0.34613996744155884\n",
      "Batch: 4737 Loss: 0.44372865557670593\n",
      "Batch: 4801 Loss: 0.3616931736469269\n",
      "Batch: 4865 Loss: 0.3501979410648346\n",
      "Batch: 4929 Loss: 0.3991403877735138\n",
      "Batch: 4993 Loss: 0.5066249966621399\n",
      "Batch: 5057 Loss: 0.4937155842781067\n",
      "Batch: 5121 Loss: 0.3899206817150116\n",
      "Batch: 5185 Loss: 0.8425107002258301\n",
      "Batch: 5249 Loss: 0.36542701721191406\n",
      "Batch: 5313 Loss: 0.43683865666389465\n",
      "Batch: 5377 Loss: 0.4203088581562042\n",
      "Batch: 5441 Loss: 0.5208310484886169\n",
      "Batch: 5505 Loss: 0.4709317982196808\n",
      "Batch: 5569 Loss: 0.5215534567832947\n",
      "Batch: 5633 Loss: 0.38302162289619446\n",
      "Batch: 5697 Loss: 0.4303896427154541\n",
      "Batch: 5761 Loss: 0.5481862425804138\n",
      "Batch: 5825 Loss: 0.4253668189048767\n",
      "Batch: 5889 Loss: 0.38188251852989197\n",
      "Batch: 5953 Loss: 0.3828039765357971\n",
      "Batch: 6017 Loss: 0.32109344005584717\n",
      "Batch: 6081 Loss: 0.29671958088874817\n",
      "Batch: 6145 Loss: 0.412640243768692\n",
      "Batch: 6209 Loss: 0.3393827974796295\n",
      "Batch: 6273 Loss: 0.45700645446777344\n",
      "Batch: 6337 Loss: 0.3300169110298157\n",
      "Batch: 6401 Loss: 0.33346712589263916\n",
      "Batch: 6465 Loss: 0.37498074769973755\n",
      "Batch: 6529 Loss: 0.35214540362358093\n",
      "Batch: 6593 Loss: 0.3712829351425171\n",
      "Batch: 6657 Loss: 0.3103395998477936\n",
      "Batch: 6721 Loss: 0.4333667755126953\n",
      "Batch: 6785 Loss: 0.40778231620788574\n",
      "Batch: 6849 Loss: 0.4086257815361023\n",
      "Batch: 6913 Loss: 0.3922233581542969\n",
      "Batch: 6977 Loss: 0.425285279750824\n",
      "Batch: 7041 Loss: 0.4155111014842987\n",
      "Batch: 7105 Loss: 0.3329774737358093\n",
      "Batch: 7169 Loss: 0.4069680869579315\n",
      "Batch: 7233 Loss: 0.34915629029273987\n",
      "Batch: 7297 Loss: 0.4108697772026062\n",
      "Batch: 7361 Loss: 0.3813905119895935\n",
      "Batch: 7425 Loss: 0.4737570881843567\n",
      "Batch: 7489 Loss: 0.5591838359832764\n",
      "Batch: 7553 Loss: 0.36487823724746704\n",
      "Batch: 7617 Loss: 0.36439579725265503\n",
      "Batch: 7681 Loss: 0.4370819330215454\n",
      "Batch: 7745 Loss: 0.45167309045791626\n",
      "Batch: 7809 Loss: 0.41564178466796875\n",
      "Batch: 7873 Loss: 0.32720109820365906\n",
      "Batch: 7937 Loss: 0.5370007753372192\n",
      "Batch: 8001 Loss: 0.3932429254055023\n",
      "Batch: 8065 Loss: 0.5406650304794312\n",
      "Batch: 8129 Loss: 0.40137261152267456\n",
      "Batch: 8193 Loss: 0.4383922219276428\n",
      "Batch: 8257 Loss: 0.46156978607177734\n",
      "Batch: 8321 Loss: 0.6312074065208435\n",
      "Batch: 8385 Loss: 0.3103726804256439\n",
      "Batch: 8449 Loss: 0.34527841210365295\n",
      "Batch: 8513 Loss: 0.6312223672866821\n",
      "Batch: 8577 Loss: 0.32267311215400696\n",
      "Batch: 8641 Loss: 0.48637494444847107\n",
      "Batch: 8705 Loss: 0.39764881134033203\n",
      "Batch: 8769 Loss: 0.4605236053466797\n",
      "Batch: 8833 Loss: 0.5250067710876465\n",
      "Batch: 8897 Loss: 0.7865195274353027\n",
      "Batch: 8961 Loss: 0.3914525806903839\n",
      "Batch: 9025 Loss: 0.3867340087890625\n",
      "Batch: 9089 Loss: 0.39773181080818176\n",
      "Batch: 9153 Loss: 0.46083003282546997\n",
      "Batch: 9217 Loss: 0.48997360467910767\n",
      "Batch: 9281 Loss: 0.44534173607826233\n",
      "Batch: 9345 Loss: 0.35096803307533264\n",
      "Batch: 9409 Loss: 0.4796239137649536\n",
      "Batch: 9473 Loss: 0.5413838624954224\n",
      "Batch: 9537 Loss: 0.4636843204498291\n",
      "Batch: 9601 Loss: 0.3591002821922302\n",
      "Batch: 9665 Loss: 0.33408036828041077\n",
      "Batch: 9729 Loss: 0.4331316649913788\n",
      "Batch: 9793 Loss: 0.3774234354496002\n",
      "Batch: 9857 Loss: 0.4265052378177643\n",
      "Batch: 9921 Loss: 0.3922496438026428\n",
      "Batch: 9985 Loss: 0.4326469600200653\n",
      "Batch: 10049 Loss: 0.4985087215900421\n",
      "Batch: 10113 Loss: 0.3906908929347992\n",
      "Batch: 10177 Loss: 0.4739781618118286\n",
      "Batch: 10241 Loss: 0.3665800988674164\n",
      "Batch: 10305 Loss: 0.43894895911216736\n",
      "Batch: 10369 Loss: 0.47906360030174255\n",
      "Batch: 10433 Loss: 0.40004852414131165\n",
      "Batch: 10497 Loss: 0.3908472955226898\n",
      "Batch: 10561 Loss: 0.3647296130657196\n",
      "Batch: 10625 Loss: 0.43002790212631226\n",
      "Batch: 10689 Loss: 0.41349419951438904\n",
      "Batch: 10753 Loss: 0.3502703309059143\n",
      "Batch: 10817 Loss: 0.30903372168540955\n",
      "Batch: 10881 Loss: 0.3691152036190033\n",
      "Batch: 10945 Loss: 0.3493892252445221\n",
      "Batch: 11009 Loss: 0.3655249774456024\n",
      "Batch: 11073 Loss: 0.42973142862319946\n",
      "Batch: 11137 Loss: 0.3484064042568207\n",
      "Batch: 11201 Loss: 0.36246299743652344\n",
      "Batch: 11265 Loss: 0.5152480602264404\n",
      "Batch: 11329 Loss: 0.6432296633720398\n",
      "Batch: 11393 Loss: 0.2788703441619873\n",
      "Batch: 11457 Loss: 0.3579629957675934\n",
      "Batch: 11521 Loss: 0.3696978688240051\n",
      "Batch: 11585 Loss: 0.4897193908691406\n",
      "Batch: 11649 Loss: 0.32159966230392456\n",
      "Batch: 11713 Loss: 0.41535645723342896\n",
      "Batch: 11777 Loss: 0.5979421138763428\n",
      "Batch: 11841 Loss: 0.5522409081459045\n",
      "Batch: 11905 Loss: 0.43453800678253174\n",
      "Batch: 11969 Loss: 0.39980727434158325\n",
      "Batch: 12033 Loss: 0.37213006615638733\n",
      "Batch: 12097 Loss: 0.910768449306488\n",
      "Batch: 12161 Loss: 0.5066888332366943\n",
      "Batch: 12225 Loss: 0.2950202226638794\n",
      "Batch: 12289 Loss: 0.3078206181526184\n",
      "Batch: 12353 Loss: 0.4083825349807739\n",
      "Batch: 12417 Loss: 0.34209850430488586\n",
      "Batch: 12481 Loss: 0.37894919514656067\n",
      "Batch: 12545 Loss: 0.47541871666908264\n",
      "Batch: 12609 Loss: 0.5096859335899353\n",
      "Batch: 12673 Loss: 0.5433087348937988\n",
      "Batch: 12737 Loss: 0.44802892208099365\n",
      "Batch: 12801 Loss: 0.36991003155708313\n",
      "Batch: 12865 Loss: 0.3206913471221924\n",
      "Batch: 12929 Loss: 0.6376516222953796\n",
      "Epoch: 44\n",
      "Batch: 1 Loss: 0.39876869320869446\n",
      "Batch: 65 Loss: 0.45873507857322693\n",
      "Batch: 129 Loss: 0.390499472618103\n",
      "Batch: 193 Loss: 0.5825546383857727\n",
      "Batch: 257 Loss: 0.4179406464099884\n",
      "Batch: 321 Loss: 0.40260374546051025\n",
      "Batch: 385 Loss: 0.40646645426750183\n",
      "Batch: 449 Loss: 0.3760758638381958\n",
      "Batch: 513 Loss: 0.3901631236076355\n",
      "Batch: 577 Loss: 0.38733822107315063\n",
      "Batch: 641 Loss: 0.46383845806121826\n",
      "Batch: 705 Loss: 0.4063294231891632\n",
      "Batch: 769 Loss: 0.45338690280914307\n",
      "Batch: 833 Loss: 0.3359105587005615\n",
      "Batch: 897 Loss: 0.5651965141296387\n",
      "Batch: 961 Loss: 0.36403408646583557\n",
      "Batch: 1025 Loss: 0.397377073764801\n",
      "Batch: 1089 Loss: 0.39126771688461304\n",
      "Batch: 1153 Loss: 0.4259410798549652\n",
      "Batch: 1217 Loss: 0.3836555480957031\n",
      "Batch: 1281 Loss: 0.41327783465385437\n",
      "Batch: 1345 Loss: 0.42257246375083923\n",
      "Batch: 1409 Loss: 0.35493215918540955\n",
      "Batch: 1473 Loss: 0.4035661220550537\n",
      "Batch: 1537 Loss: 0.38337475061416626\n",
      "Batch: 1601 Loss: 0.3244641125202179\n",
      "Batch: 1665 Loss: 0.3661264181137085\n",
      "Batch: 1729 Loss: 0.4261327385902405\n",
      "Batch: 1793 Loss: 0.33429065346717834\n",
      "Batch: 1857 Loss: 0.37600642442703247\n",
      "Batch: 1921 Loss: 0.4168779253959656\n",
      "Batch: 1985 Loss: 0.35786715149879456\n",
      "Batch: 2049 Loss: 0.33155742287635803\n",
      "Batch: 2113 Loss: 0.3513559103012085\n",
      "Batch: 2177 Loss: 0.3925052285194397\n",
      "Batch: 2241 Loss: 0.4364469647407532\n",
      "Batch: 2305 Loss: 0.45279833674430847\n",
      "Batch: 2369 Loss: 0.46933504939079285\n",
      "Batch: 2433 Loss: 0.4285050928592682\n",
      "Batch: 2497 Loss: 0.4853309392929077\n",
      "Batch: 2561 Loss: 0.40035760402679443\n",
      "Batch: 2625 Loss: 0.4208381474018097\n",
      "Batch: 2689 Loss: 0.4351786971092224\n",
      "Batch: 2753 Loss: 0.3570192754268646\n",
      "Batch: 2817 Loss: 0.5285261869430542\n",
      "Batch: 2881 Loss: 0.44368043541908264\n",
      "Batch: 2945 Loss: 0.38465526700019836\n",
      "Batch: 3009 Loss: 0.5429366230964661\n",
      "Batch: 3073 Loss: 0.427375853061676\n",
      "Batch: 3137 Loss: 0.392768919467926\n",
      "Batch: 3201 Loss: 0.3794229030609131\n",
      "Batch: 3265 Loss: 0.3664037585258484\n",
      "Batch: 3329 Loss: 0.39774519205093384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 3393 Loss: 0.4203377366065979\n",
      "Batch: 3457 Loss: 0.38645341992378235\n",
      "Batch: 3521 Loss: 0.2989189624786377\n",
      "Batch: 3585 Loss: 0.2824394404888153\n",
      "Batch: 3649 Loss: 0.46299612522125244\n",
      "Batch: 3713 Loss: 0.3837418854236603\n",
      "Batch: 3777 Loss: 0.40522676706314087\n",
      "Batch: 3841 Loss: 0.40529361367225647\n",
      "Batch: 3905 Loss: 0.37546002864837646\n",
      "Batch: 3969 Loss: 0.5195978879928589\n",
      "Batch: 4033 Loss: 0.38881954550743103\n",
      "Batch: 4097 Loss: 0.3886205852031708\n",
      "Batch: 4161 Loss: 0.4542633891105652\n",
      "Batch: 4225 Loss: 0.32886824011802673\n",
      "Batch: 4289 Loss: 0.3513396382331848\n",
      "Batch: 4353 Loss: 0.47684165835380554\n",
      "Batch: 4417 Loss: 0.6063248515129089\n",
      "Batch: 4481 Loss: 0.6563036441802979\n",
      "Batch: 4545 Loss: 0.53377765417099\n",
      "Batch: 4609 Loss: 0.3670448958873749\n",
      "Batch: 4673 Loss: 0.34646913409233093\n",
      "Batch: 4737 Loss: 0.44552677869796753\n",
      "Batch: 4801 Loss: 0.36584120988845825\n",
      "Batch: 4865 Loss: 0.35038381814956665\n",
      "Batch: 4929 Loss: 0.40031301975250244\n",
      "Batch: 4993 Loss: 0.5078737139701843\n",
      "Batch: 5057 Loss: 0.49246013164520264\n",
      "Batch: 5121 Loss: 0.3860308825969696\n",
      "Batch: 5185 Loss: 0.8431996703147888\n",
      "Batch: 5249 Loss: 0.3647034466266632\n",
      "Batch: 5313 Loss: 0.43597322702407837\n",
      "Batch: 5377 Loss: 0.4218274652957916\n",
      "Batch: 5441 Loss: 0.5026416182518005\n",
      "Batch: 5505 Loss: 0.47348350286483765\n",
      "Batch: 5569 Loss: 0.524824321269989\n",
      "Batch: 5633 Loss: 0.3760644197463989\n",
      "Batch: 5697 Loss: 0.4300520420074463\n",
      "Batch: 5761 Loss: 0.5472920536994934\n",
      "Batch: 5825 Loss: 0.4257928431034088\n",
      "Batch: 5889 Loss: 0.38052594661712646\n",
      "Batch: 5953 Loss: 0.3827097713947296\n",
      "Batch: 6017 Loss: 0.31948819756507874\n",
      "Batch: 6081 Loss: 0.2957889139652252\n",
      "Batch: 6145 Loss: 0.4064539670944214\n",
      "Batch: 6209 Loss: 0.34334662556648254\n",
      "Batch: 6273 Loss: 0.45603147149086\n",
      "Batch: 6337 Loss: 0.32990676164627075\n",
      "Batch: 6401 Loss: 0.3337480425834656\n",
      "Batch: 6465 Loss: 0.3742624819278717\n",
      "Batch: 6529 Loss: 0.3510403335094452\n",
      "Batch: 6593 Loss: 0.3713310956954956\n",
      "Batch: 6657 Loss: 0.31390196084976196\n",
      "Batch: 6721 Loss: 0.4154549837112427\n",
      "Batch: 6785 Loss: 0.4074629843235016\n",
      "Batch: 6849 Loss: 0.4124278426170349\n",
      "Batch: 6913 Loss: 0.396980345249176\n",
      "Batch: 6977 Loss: 0.4244972765445709\n",
      "Batch: 7041 Loss: 0.41476526856422424\n",
      "Batch: 7105 Loss: 0.3550320267677307\n",
      "Batch: 7169 Loss: 0.3925212621688843\n",
      "Batch: 7233 Loss: 0.35142412781715393\n",
      "Batch: 7297 Loss: 0.41099125146865845\n",
      "Batch: 7361 Loss: 0.38317587971687317\n",
      "Batch: 7425 Loss: 0.46509620547294617\n",
      "Batch: 7489 Loss: 0.5589429140090942\n",
      "Batch: 7553 Loss: 0.3639715313911438\n",
      "Batch: 7617 Loss: 0.36358049511909485\n",
      "Batch: 7681 Loss: 0.43863245844841003\n",
      "Batch: 7745 Loss: 0.4521164298057556\n",
      "Batch: 7809 Loss: 0.4175666570663452\n",
      "Batch: 7873 Loss: 0.3267425000667572\n",
      "Batch: 7937 Loss: 0.5372282266616821\n",
      "Batch: 8001 Loss: 0.39416366815567017\n",
      "Batch: 8065 Loss: 0.53369140625\n",
      "Batch: 8129 Loss: 0.39261341094970703\n",
      "Batch: 8193 Loss: 0.4384539723396301\n",
      "Batch: 8257 Loss: 0.46107831597328186\n",
      "Batch: 8321 Loss: 0.6291075944900513\n",
      "Batch: 8385 Loss: 0.3105989098548889\n",
      "Batch: 8449 Loss: 0.3454230725765228\n",
      "Batch: 8513 Loss: 0.6307132840156555\n",
      "Batch: 8577 Loss: 0.3261435329914093\n",
      "Batch: 8641 Loss: 0.48458656668663025\n",
      "Batch: 8705 Loss: 0.39052316546440125\n",
      "Batch: 8769 Loss: 0.4592726528644562\n",
      "Batch: 8833 Loss: 0.5153018236160278\n",
      "Batch: 8897 Loss: 0.7866305708885193\n",
      "Batch: 8961 Loss: 0.3912433683872223\n",
      "Batch: 9025 Loss: 0.3862951695919037\n",
      "Batch: 9089 Loss: 0.39776942133903503\n",
      "Batch: 9153 Loss: 0.47070953249931335\n",
      "Batch: 9217 Loss: 0.489032506942749\n",
      "Batch: 9281 Loss: 0.44462770223617554\n",
      "Batch: 9345 Loss: 0.35077568888664246\n",
      "Batch: 9409 Loss: 0.48143619298934937\n",
      "Batch: 9473 Loss: 0.5420195460319519\n",
      "Batch: 9537 Loss: 0.46454399824142456\n",
      "Batch: 9601 Loss: 0.35750672221183777\n",
      "Batch: 9665 Loss: 0.33370357751846313\n",
      "Batch: 9729 Loss: 0.43329834938049316\n",
      "Batch: 9793 Loss: 0.3777030408382416\n",
      "Batch: 9857 Loss: 0.4263646900653839\n",
      "Batch: 9921 Loss: 0.39258602261543274\n",
      "Batch: 9985 Loss: 0.4302440285682678\n",
      "Batch: 10049 Loss: 0.49849262833595276\n",
      "Batch: 10113 Loss: 0.38745197653770447\n",
      "Batch: 10177 Loss: 0.4796621799468994\n",
      "Batch: 10241 Loss: 0.36391136050224304\n",
      "Batch: 10305 Loss: 0.43670955300331116\n",
      "Batch: 10369 Loss: 0.47850051522254944\n",
      "Batch: 10433 Loss: 0.3985672891139984\n",
      "Batch: 10497 Loss: 0.3917645215988159\n",
      "Batch: 10561 Loss: 0.3637126684188843\n",
      "Batch: 10625 Loss: 0.42892953753471375\n",
      "Batch: 10689 Loss: 0.41017016768455505\n",
      "Batch: 10753 Loss: 0.3498819172382355\n",
      "Batch: 10817 Loss: 0.30855339765548706\n",
      "Batch: 10881 Loss: 0.3581007719039917\n",
      "Batch: 10945 Loss: 0.3262782394886017\n",
      "Batch: 11009 Loss: 0.3565168082714081\n",
      "Batch: 11073 Loss: 0.4314833879470825\n",
      "Batch: 11137 Loss: 0.3482475280761719\n",
      "Batch: 11201 Loss: 0.3620048761367798\n",
      "Batch: 11265 Loss: 0.5086632966995239\n",
      "Batch: 11329 Loss: 0.634419322013855\n",
      "Batch: 11393 Loss: 0.2800182104110718\n",
      "Batch: 11457 Loss: 0.35676318407058716\n",
      "Batch: 11521 Loss: 0.3688356578350067\n",
      "Batch: 11585 Loss: 0.4892413020133972\n",
      "Batch: 11649 Loss: 0.32120874524116516\n",
      "Batch: 11713 Loss: 0.4134766459465027\n",
      "Batch: 11777 Loss: 0.5998632311820984\n",
      "Batch: 11841 Loss: 0.5624953508377075\n",
      "Batch: 11905 Loss: 0.43432900309562683\n",
      "Batch: 11969 Loss: 0.3994426727294922\n",
      "Batch: 12033 Loss: 0.37193459272384644\n",
      "Batch: 12097 Loss: 0.9144814014434814\n",
      "Batch: 12161 Loss: 0.5013353228569031\n",
      "Batch: 12225 Loss: 0.2937711179256439\n",
      "Batch: 12289 Loss: 0.3066568076610565\n",
      "Batch: 12353 Loss: 0.4082336127758026\n",
      "Batch: 12417 Loss: 0.3419007956981659\n",
      "Batch: 12481 Loss: 0.376953125\n",
      "Batch: 12545 Loss: 0.47458285093307495\n",
      "Batch: 12609 Loss: 0.5124485492706299\n",
      "Batch: 12673 Loss: 0.5276157259941101\n",
      "Batch: 12737 Loss: 0.45360442996025085\n",
      "Batch: 12801 Loss: 0.3701826333999634\n",
      "Batch: 12865 Loss: 0.31174236536026\n",
      "Batch: 12929 Loss: 0.6421775221824646\n",
      "Epoch: 45\n",
      "Batch: 1 Loss: 0.39777013659477234\n",
      "Batch: 65 Loss: 0.45915713906288147\n",
      "Batch: 129 Loss: 0.39059531688690186\n",
      "Batch: 193 Loss: 0.5791811943054199\n",
      "Batch: 257 Loss: 0.4150586426258087\n",
      "Batch: 321 Loss: 0.4011385142803192\n",
      "Batch: 385 Loss: 0.40492716431617737\n",
      "Batch: 449 Loss: 0.3765034079551697\n",
      "Batch: 513 Loss: 0.38917362689971924\n",
      "Batch: 577 Loss: 0.38637810945510864\n",
      "Batch: 641 Loss: 0.46336543560028076\n",
      "Batch: 705 Loss: 0.40595394372940063\n",
      "Batch: 769 Loss: 0.45332086086273193\n",
      "Batch: 833 Loss: 0.3343612253665924\n",
      "Batch: 897 Loss: 0.5643808841705322\n",
      "Batch: 961 Loss: 0.3623543381690979\n",
      "Batch: 1025 Loss: 0.3967868387699127\n",
      "Batch: 1089 Loss: 0.39074596762657166\n",
      "Batch: 1153 Loss: 0.42553508281707764\n",
      "Batch: 1217 Loss: 0.383539080619812\n",
      "Batch: 1281 Loss: 0.41381561756134033\n",
      "Batch: 1345 Loss: 0.4222384989261627\n",
      "Batch: 1409 Loss: 0.3537067770957947\n",
      "Batch: 1473 Loss: 0.4006088972091675\n",
      "Batch: 1537 Loss: 0.38377249240875244\n",
      "Batch: 1601 Loss: 0.323986679315567\n",
      "Batch: 1665 Loss: 0.3656645119190216\n",
      "Batch: 1729 Loss: 0.42611145973205566\n",
      "Batch: 1793 Loss: 0.33249199390411377\n",
      "Batch: 1857 Loss: 0.3808403015136719\n",
      "Batch: 1921 Loss: 0.41814300417900085\n",
      "Batch: 1985 Loss: 0.35815784335136414\n",
      "Batch: 2049 Loss: 0.3312918245792389\n",
      "Batch: 2113 Loss: 0.3462086319923401\n",
      "Batch: 2177 Loss: 0.3927026093006134\n",
      "Batch: 2241 Loss: 0.43484625220298767\n",
      "Batch: 2305 Loss: 0.44899749755859375\n",
      "Batch: 2369 Loss: 0.46698126196861267\n",
      "Batch: 2433 Loss: 0.429212749004364\n",
      "Batch: 2497 Loss: 0.4869908392429352\n",
      "Batch: 2561 Loss: 0.4062696695327759\n",
      "Batch: 2625 Loss: 0.4206971824169159\n",
      "Batch: 2689 Loss: 0.43492797017097473\n",
      "Batch: 2753 Loss: 0.3535930812358856\n",
      "Batch: 2817 Loss: 0.5264192819595337\n",
      "Batch: 2881 Loss: 0.4444751739501953\n",
      "Batch: 2945 Loss: 0.38415685296058655\n",
      "Batch: 3009 Loss: 0.5436844229698181\n",
      "Batch: 3073 Loss: 0.4267474412918091\n",
      "Batch: 3137 Loss: 0.3931547701358795\n",
      "Batch: 3201 Loss: 0.37855035066604614\n",
      "Batch: 3265 Loss: 0.3664972484111786\n",
      "Batch: 3329 Loss: 0.3976743817329407\n",
      "Batch: 3393 Loss: 0.42414480447769165\n",
      "Batch: 3457 Loss: 0.39026781916618347\n",
      "Batch: 3521 Loss: 0.29801103472709656\n",
      "Batch: 3585 Loss: 0.2838224768638611\n",
      "Batch: 3649 Loss: 0.46290871500968933\n",
      "Batch: 3713 Loss: 0.38360270857810974\n",
      "Batch: 3777 Loss: 0.4043341279029846\n",
      "Batch: 3841 Loss: 0.4058513343334198\n",
      "Batch: 3905 Loss: 0.3752593696117401\n",
      "Batch: 3969 Loss: 0.5193400979042053\n",
      "Batch: 4033 Loss: 0.3905215859413147\n",
      "Batch: 4097 Loss: 0.38832855224609375\n",
      "Batch: 4161 Loss: 0.45243528485298157\n",
      "Batch: 4225 Loss: 0.32865527272224426\n",
      "Batch: 4289 Loss: 0.3518492877483368\n",
      "Batch: 4353 Loss: 0.4768090546131134\n",
      "Batch: 4417 Loss: 0.6060052514076233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 4481 Loss: 0.6552725434303284\n",
      "Batch: 4545 Loss: 0.5336328148841858\n",
      "Batch: 4609 Loss: 0.3670290410518646\n",
      "Batch: 4673 Loss: 0.3454090654850006\n",
      "Batch: 4737 Loss: 0.4441801905632019\n",
      "Batch: 4801 Loss: 0.36256736516952515\n",
      "Batch: 4865 Loss: 0.349608451128006\n",
      "Batch: 4929 Loss: 0.39930349588394165\n",
      "Batch: 4993 Loss: 0.5061423778533936\n",
      "Batch: 5057 Loss: 0.49458444118499756\n",
      "Batch: 5121 Loss: 0.3851260542869568\n",
      "Batch: 5185 Loss: 0.8407230377197266\n",
      "Batch: 5249 Loss: 0.36561763286590576\n",
      "Batch: 5313 Loss: 0.43547600507736206\n",
      "Batch: 5377 Loss: 0.4195583164691925\n",
      "Batch: 5441 Loss: 0.4997239410877228\n",
      "Batch: 5505 Loss: 0.47670596837997437\n",
      "Batch: 5569 Loss: 0.5237212777137756\n",
      "Batch: 5633 Loss: 0.3779832124710083\n",
      "Batch: 5697 Loss: 0.42869868874549866\n",
      "Batch: 5761 Loss: 0.5470102429389954\n",
      "Batch: 5825 Loss: 0.4246566593647003\n",
      "Batch: 5889 Loss: 0.3813466727733612\n",
      "Batch: 5953 Loss: 0.3826831579208374\n",
      "Batch: 6017 Loss: 0.3186447024345398\n",
      "Batch: 6081 Loss: 0.29485467076301575\n",
      "Batch: 6145 Loss: 0.4024507403373718\n",
      "Batch: 6209 Loss: 0.34714627265930176\n",
      "Batch: 6273 Loss: 0.4575521647930145\n",
      "Batch: 6337 Loss: 0.330374151468277\n",
      "Batch: 6401 Loss: 0.33411136269569397\n",
      "Batch: 6465 Loss: 0.37310925126075745\n",
      "Batch: 6529 Loss: 0.3518713414669037\n",
      "Batch: 6593 Loss: 0.37163862586021423\n",
      "Batch: 6657 Loss: 0.3080587089061737\n",
      "Batch: 6721 Loss: 0.43738308548927307\n",
      "Batch: 6785 Loss: 0.4105483889579773\n",
      "Batch: 6849 Loss: 0.4081380367279053\n",
      "Batch: 6913 Loss: 0.39067476987838745\n",
      "Batch: 6977 Loss: 0.42555657029151917\n",
      "Batch: 7041 Loss: 0.41919514536857605\n",
      "Batch: 7105 Loss: 0.3447612524032593\n",
      "Batch: 7169 Loss: 0.3927300274372101\n",
      "Batch: 7233 Loss: 0.3532428741455078\n",
      "Batch: 7297 Loss: 0.41170576214790344\n",
      "Batch: 7361 Loss: 0.38208991289138794\n",
      "Batch: 7425 Loss: 0.46553680300712585\n",
      "Batch: 7489 Loss: 0.5595166683197021\n",
      "Batch: 7553 Loss: 0.36377599835395813\n",
      "Batch: 7617 Loss: 0.36337894201278687\n",
      "Batch: 7681 Loss: 0.4377634525299072\n",
      "Batch: 7745 Loss: 0.4513103663921356\n",
      "Batch: 7809 Loss: 0.4153958559036255\n",
      "Batch: 7873 Loss: 0.3258538544178009\n",
      "Batch: 7937 Loss: 0.5371922850608826\n",
      "Batch: 8001 Loss: 0.3909231126308441\n",
      "Batch: 8065 Loss: 0.5339375138282776\n",
      "Batch: 8129 Loss: 0.39261266589164734\n",
      "Batch: 8193 Loss: 0.43860024213790894\n",
      "Batch: 8257 Loss: 0.4595860540866852\n",
      "Batch: 8321 Loss: 0.6302540898323059\n",
      "Batch: 8385 Loss: 0.31201010942459106\n",
      "Batch: 8449 Loss: 0.3455737829208374\n",
      "Batch: 8513 Loss: 0.6309394240379333\n",
      "Batch: 8577 Loss: 0.32352083921432495\n",
      "Batch: 8641 Loss: 0.48977264761924744\n",
      "Batch: 8705 Loss: 0.3949034512042999\n",
      "Batch: 8769 Loss: 0.45855391025543213\n",
      "Batch: 8833 Loss: 0.515677809715271\n",
      "Batch: 8897 Loss: 0.7858719229698181\n",
      "Batch: 8961 Loss: 0.390434205532074\n",
      "Batch: 9025 Loss: 0.386536180973053\n",
      "Batch: 9089 Loss: 0.3957328200340271\n",
      "Batch: 9153 Loss: 0.4534372091293335\n",
      "Batch: 9217 Loss: 0.49401184916496277\n",
      "Batch: 9281 Loss: 0.4455314874649048\n",
      "Batch: 9345 Loss: 0.3493378460407257\n",
      "Batch: 9409 Loss: 0.47871410846710205\n",
      "Batch: 9473 Loss: 0.5410729050636292\n",
      "Batch: 9537 Loss: 0.46699437499046326\n",
      "Batch: 9601 Loss: 0.35554781556129456\n",
      "Batch: 9665 Loss: 0.33376049995422363\n",
      "Batch: 9729 Loss: 0.4323962926864624\n",
      "Batch: 9793 Loss: 0.37737399339675903\n",
      "Batch: 9857 Loss: 0.42684099078178406\n",
      "Batch: 9921 Loss: 0.3915840983390808\n",
      "Batch: 9985 Loss: 0.4314655661582947\n",
      "Batch: 10049 Loss: 0.4971328377723694\n",
      "Batch: 10113 Loss: 0.38669976592063904\n",
      "Batch: 10177 Loss: 0.48178741335868835\n",
      "Batch: 10241 Loss: 0.3628639578819275\n",
      "Batch: 10305 Loss: 0.43675288558006287\n",
      "Batch: 10369 Loss: 0.47845229506492615\n",
      "Batch: 10433 Loss: 0.3984750211238861\n",
      "Batch: 10497 Loss: 0.39186564087867737\n",
      "Batch: 10561 Loss: 0.36599263548851013\n",
      "Batch: 10625 Loss: 0.42719194293022156\n",
      "Batch: 10689 Loss: 0.4044315814971924\n",
      "Batch: 10753 Loss: 0.349559485912323\n",
      "Batch: 10817 Loss: 0.3089478611946106\n",
      "Batch: 10881 Loss: 0.35341981053352356\n",
      "Batch: 10945 Loss: 0.33157575130462646\n",
      "Batch: 11009 Loss: 0.3826826214790344\n",
      "Batch: 11073 Loss: 0.4585725665092468\n",
      "Batch: 11137 Loss: 0.3485129475593567\n",
      "Batch: 11201 Loss: 0.36144378781318665\n",
      "Batch: 11265 Loss: 0.5084283351898193\n",
      "Batch: 11329 Loss: 0.6478925943374634\n",
      "Batch: 11393 Loss: 0.28176456689834595\n",
      "Batch: 11457 Loss: 0.358500212430954\n",
      "Batch: 11521 Loss: 0.371711790561676\n",
      "Batch: 11585 Loss: 0.48929694294929504\n",
      "Batch: 11649 Loss: 0.3214832544326782\n",
      "Batch: 11713 Loss: 0.41307440400123596\n",
      "Batch: 11777 Loss: 0.5998594760894775\n",
      "Batch: 11841 Loss: 0.5653114318847656\n",
      "Batch: 11905 Loss: 0.4423758387565613\n",
      "Batch: 11969 Loss: 0.3986581861972809\n",
      "Batch: 12033 Loss: 0.3718169629573822\n",
      "Batch: 12097 Loss: 0.9143968820571899\n",
      "Batch: 12161 Loss: 0.5016433000564575\n",
      "Batch: 12225 Loss: 0.2942514419555664\n",
      "Batch: 12289 Loss: 0.3062282204627991\n",
      "Batch: 12353 Loss: 0.4111965596675873\n",
      "Batch: 12417 Loss: 0.3418661952018738\n",
      "Batch: 12481 Loss: 0.37668177485466003\n",
      "Batch: 12545 Loss: 0.47488299012184143\n",
      "Batch: 12609 Loss: 0.5197608470916748\n",
      "Batch: 12673 Loss: 0.5264338254928589\n",
      "Batch: 12737 Loss: 0.4528481662273407\n",
      "Batch: 12801 Loss: 0.3690854012966156\n",
      "Batch: 12865 Loss: 0.3120596706867218\n",
      "Batch: 12929 Loss: 0.6404916644096375\n",
      "Epoch: 46\n",
      "Batch: 1 Loss: 0.3976389765739441\n",
      "Batch: 65 Loss: 0.45832449197769165\n",
      "Batch: 129 Loss: 0.3884653151035309\n",
      "Batch: 193 Loss: 0.5774844884872437\n",
      "Batch: 257 Loss: 0.41270673274993896\n",
      "Batch: 321 Loss: 0.3991747200489044\n",
      "Batch: 385 Loss: 0.4040152132511139\n",
      "Batch: 449 Loss: 0.37638935446739197\n",
      "Batch: 513 Loss: 0.3881673514842987\n",
      "Batch: 577 Loss: 0.3853393793106079\n",
      "Batch: 641 Loss: 0.4622240364551544\n",
      "Batch: 705 Loss: 0.40594568848609924\n",
      "Batch: 769 Loss: 0.4532913565635681\n",
      "Batch: 833 Loss: 0.3320266604423523\n",
      "Batch: 897 Loss: 0.5694535970687866\n",
      "Batch: 961 Loss: 0.3667624592781067\n",
      "Batch: 1025 Loss: 0.39738816022872925\n",
      "Batch: 1089 Loss: 0.38991159200668335\n",
      "Batch: 1153 Loss: 0.422529011964798\n",
      "Batch: 1217 Loss: 0.3809134066104889\n",
      "Batch: 1281 Loss: 0.4155888855457306\n",
      "Batch: 1345 Loss: 0.42120686173439026\n",
      "Batch: 1409 Loss: 0.3545352816581726\n",
      "Batch: 1473 Loss: 0.40058714151382446\n",
      "Batch: 1537 Loss: 0.3827976882457733\n",
      "Batch: 1601 Loss: 0.3260948956012726\n",
      "Batch: 1665 Loss: 0.3657027781009674\n",
      "Batch: 1729 Loss: 0.4257037937641144\n",
      "Batch: 1793 Loss: 0.33312034606933594\n",
      "Batch: 1857 Loss: 0.37461188435554504\n",
      "Batch: 1921 Loss: 0.41657307744026184\n",
      "Batch: 1985 Loss: 0.3582824468612671\n",
      "Batch: 2049 Loss: 0.330805242061615\n",
      "Batch: 2113 Loss: 0.3423921763896942\n",
      "Batch: 2177 Loss: 0.39146196842193604\n",
      "Batch: 2241 Loss: 0.434894859790802\n",
      "Batch: 2305 Loss: 0.4472976326942444\n",
      "Batch: 2369 Loss: 0.46970343589782715\n",
      "Batch: 2433 Loss: 0.42873355746269226\n",
      "Batch: 2497 Loss: 0.48514729738235474\n",
      "Batch: 2561 Loss: 0.40025660395622253\n",
      "Batch: 2625 Loss: 0.42095279693603516\n",
      "Batch: 2689 Loss: 0.43446728587150574\n",
      "Batch: 2753 Loss: 0.34963735938072205\n",
      "Batch: 2817 Loss: 0.5179470181465149\n",
      "Batch: 2881 Loss: 0.4406852722167969\n",
      "Batch: 2945 Loss: 0.3810158669948578\n",
      "Batch: 3009 Loss: 0.5424030423164368\n",
      "Batch: 3073 Loss: 0.4258515536785126\n",
      "Batch: 3137 Loss: 0.3905368447303772\n",
      "Batch: 3201 Loss: 0.37883448600769043\n",
      "Batch: 3265 Loss: 0.3663102388381958\n",
      "Batch: 3329 Loss: 0.3972761034965515\n",
      "Batch: 3393 Loss: 0.41909709572792053\n",
      "Batch: 3457 Loss: 0.38291919231414795\n",
      "Batch: 3521 Loss: 0.2978222668170929\n",
      "Batch: 3585 Loss: 0.2809610366821289\n",
      "Batch: 3649 Loss: 0.46271631121635437\n",
      "Batch: 3713 Loss: 0.38362058997154236\n",
      "Batch: 3777 Loss: 0.40388521552085876\n",
      "Batch: 3841 Loss: 0.4036405682563782\n",
      "Batch: 3905 Loss: 0.3767014741897583\n",
      "Batch: 3969 Loss: 0.5182129144668579\n",
      "Batch: 4033 Loss: 0.38861992955207825\n",
      "Batch: 4097 Loss: 0.3875529170036316\n",
      "Batch: 4161 Loss: 0.4508638083934784\n",
      "Batch: 4225 Loss: 0.3280172049999237\n",
      "Batch: 4289 Loss: 0.35188302397727966\n",
      "Batch: 4353 Loss: 0.48104822635650635\n",
      "Batch: 4417 Loss: 0.6047846674919128\n",
      "Batch: 4481 Loss: 0.6565141081809998\n",
      "Batch: 4545 Loss: 0.5402693152427673\n",
      "Batch: 4609 Loss: 0.36851125955581665\n",
      "Batch: 4673 Loss: 0.34603145718574524\n",
      "Batch: 4737 Loss: 0.44361236691474915\n",
      "Batch: 4801 Loss: 0.36010482907295227\n",
      "Batch: 4865 Loss: 0.3504921793937683\n",
      "Batch: 4929 Loss: 0.399005651473999\n",
      "Batch: 4993 Loss: 0.5062927007675171\n",
      "Batch: 5057 Loss: 0.49232470989227295\n",
      "Batch: 5121 Loss: 0.3841855227947235\n",
      "Batch: 5185 Loss: 0.838985025882721\n",
      "Batch: 5249 Loss: 0.3659387230873108\n",
      "Batch: 5313 Loss: 0.4357709288597107\n",
      "Batch: 5377 Loss: 0.4220474660396576\n",
      "Batch: 5441 Loss: 0.4989788234233856\n",
      "Batch: 5505 Loss: 0.4729762673377991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 5569 Loss: 0.5211613774299622\n",
      "Batch: 5633 Loss: 0.3770032227039337\n",
      "Batch: 5697 Loss: 0.427537202835083\n",
      "Batch: 5761 Loss: 0.5466140508651733\n",
      "Batch: 5825 Loss: 0.425060510635376\n",
      "Batch: 5889 Loss: 0.3801485598087311\n",
      "Batch: 5953 Loss: 0.3827598989009857\n",
      "Batch: 6017 Loss: 0.3181201219558716\n",
      "Batch: 6081 Loss: 0.2942960858345032\n",
      "Batch: 6145 Loss: 0.4018620252609253\n",
      "Batch: 6209 Loss: 0.34119346737861633\n",
      "Batch: 6273 Loss: 0.45523375272750854\n",
      "Batch: 6337 Loss: 0.33007580041885376\n",
      "Batch: 6401 Loss: 0.33376479148864746\n",
      "Batch: 6465 Loss: 0.3730441629886627\n",
      "Batch: 6529 Loss: 0.3519212007522583\n",
      "Batch: 6593 Loss: 0.37082812190055847\n",
      "Batch: 6657 Loss: 0.30801600217819214\n",
      "Batch: 6721 Loss: 0.41355976462364197\n",
      "Batch: 6785 Loss: 0.4082566499710083\n",
      "Batch: 6849 Loss: 0.413469135761261\n",
      "Batch: 6913 Loss: 0.3903532326221466\n",
      "Batch: 6977 Loss: 0.4247344136238098\n",
      "Batch: 7041 Loss: 0.4139726161956787\n",
      "Batch: 7105 Loss: 0.3468983471393585\n",
      "Batch: 7169 Loss: 0.3928382694721222\n",
      "Batch: 7233 Loss: 0.3507678806781769\n",
      "Batch: 7297 Loss: 0.41051390767097473\n",
      "Batch: 7361 Loss: 0.38273900747299194\n",
      "Batch: 7425 Loss: 0.4640108644962311\n",
      "Batch: 7489 Loss: 0.5607815980911255\n",
      "Batch: 7553 Loss: 0.36434561014175415\n",
      "Batch: 7617 Loss: 0.3639165163040161\n",
      "Batch: 7681 Loss: 0.4394361674785614\n",
      "Batch: 7745 Loss: 0.4507037103176117\n",
      "Batch: 7809 Loss: 0.4153648018836975\n",
      "Batch: 7873 Loss: 0.33051687479019165\n",
      "Batch: 7937 Loss: 0.5410094261169434\n",
      "Batch: 8001 Loss: 0.39022600650787354\n",
      "Batch: 8065 Loss: 0.5335142016410828\n",
      "Batch: 8129 Loss: 0.391950786113739\n",
      "Batch: 8193 Loss: 0.4403744637966156\n",
      "Batch: 8257 Loss: 0.46582305431365967\n",
      "Batch: 8321 Loss: 0.6316309571266174\n",
      "Batch: 8385 Loss: 0.30986636877059937\n",
      "Batch: 8449 Loss: 0.34581559896469116\n",
      "Batch: 8513 Loss: 0.6307999491691589\n",
      "Batch: 8577 Loss: 0.32388174533843994\n",
      "Batch: 8641 Loss: 0.48906993865966797\n",
      "Batch: 8705 Loss: 0.3949858546257019\n",
      "Batch: 8769 Loss: 0.46210238337516785\n",
      "Batch: 8833 Loss: 0.531445324420929\n",
      "Batch: 8897 Loss: 0.7881317138671875\n",
      "Batch: 8961 Loss: 0.3905099928379059\n",
      "Batch: 9025 Loss: 0.3869684338569641\n",
      "Batch: 9089 Loss: 0.39794814586639404\n",
      "Batch: 9153 Loss: 0.45989203453063965\n",
      "Batch: 9217 Loss: 0.4980645775794983\n",
      "Batch: 9281 Loss: 0.44412532448768616\n",
      "Batch: 9345 Loss: 0.3484453856945038\n",
      "Batch: 9409 Loss: 0.4782106280326843\n",
      "Batch: 9473 Loss: 0.5403592586517334\n",
      "Batch: 9537 Loss: 0.46555671095848083\n",
      "Batch: 9601 Loss: 0.35627514123916626\n",
      "Batch: 9665 Loss: 0.3332727551460266\n",
      "Batch: 9729 Loss: 0.43224313855171204\n",
      "Batch: 9793 Loss: 0.3775327801704407\n",
      "Batch: 9857 Loss: 0.426750123500824\n",
      "Batch: 9921 Loss: 0.39223816990852356\n",
      "Batch: 9985 Loss: 0.4298706650733948\n",
      "Batch: 10049 Loss: 0.49662554264068604\n",
      "Batch: 10113 Loss: 0.3929547965526581\n",
      "Batch: 10177 Loss: 0.47372743487358093\n",
      "Batch: 10241 Loss: 0.36290013790130615\n",
      "Batch: 10305 Loss: 0.43626970052719116\n",
      "Batch: 10369 Loss: 0.47888699173927307\n",
      "Batch: 10433 Loss: 0.39873453974723816\n",
      "Batch: 10497 Loss: 0.3912452459335327\n",
      "Batch: 10561 Loss: 0.3655939996242523\n",
      "Batch: 10625 Loss: 0.42654794454574585\n",
      "Batch: 10689 Loss: 0.4098562002182007\n",
      "Batch: 10753 Loss: 0.3548054099082947\n",
      "Batch: 10817 Loss: 0.3082323968410492\n",
      "Batch: 10881 Loss: 0.35170480608940125\n",
      "Batch: 10945 Loss: 0.32352903485298157\n",
      "Batch: 11009 Loss: 0.35582301020622253\n",
      "Batch: 11073 Loss: 0.4294174015522003\n",
      "Batch: 11137 Loss: 0.34793105721473694\n",
      "Batch: 11201 Loss: 0.36017876863479614\n",
      "Batch: 11265 Loss: 0.512748122215271\n",
      "Batch: 11329 Loss: 0.64409339427948\n",
      "Batch: 11393 Loss: 0.27972275018692017\n",
      "Batch: 11457 Loss: 0.3576940596103668\n",
      "Batch: 11521 Loss: 0.369876503944397\n",
      "Batch: 11585 Loss: 0.49004462361335754\n",
      "Batch: 11649 Loss: 0.32154107093811035\n",
      "Batch: 11713 Loss: 0.41301411390304565\n",
      "Batch: 11777 Loss: 0.5977598428726196\n",
      "Batch: 11841 Loss: 0.5515233874320984\n",
      "Batch: 11905 Loss: 0.4337327480316162\n",
      "Batch: 11969 Loss: 0.39844998717308044\n",
      "Batch: 12033 Loss: 0.37149307131767273\n",
      "Batch: 12097 Loss: 0.9126869440078735\n",
      "Batch: 12161 Loss: 0.5055122375488281\n",
      "Batch: 12225 Loss: 0.2945992946624756\n",
      "Batch: 12289 Loss: 0.30664584040641785\n",
      "Batch: 12353 Loss: 0.4082720875740051\n",
      "Batch: 12417 Loss: 0.34153443574905396\n",
      "Batch: 12481 Loss: 0.376496285200119\n",
      "Batch: 12545 Loss: 0.4754489064216614\n",
      "Batch: 12609 Loss: 0.5157747268676758\n",
      "Batch: 12673 Loss: 0.5304796099662781\n",
      "Batch: 12737 Loss: 0.44747623801231384\n",
      "Batch: 12801 Loss: 0.3692578375339508\n",
      "Batch: 12865 Loss: 0.3190562427043915\n",
      "Batch: 12929 Loss: 0.636565625667572\n",
      "Epoch: 47\n",
      "Batch: 1 Loss: 0.3969365358352661\n",
      "Batch: 65 Loss: 0.4576724171638489\n",
      "Batch: 129 Loss: 0.38961660861968994\n",
      "Batch: 193 Loss: 0.5801680684089661\n",
      "Batch: 257 Loss: 0.42122718691825867\n",
      "Batch: 321 Loss: 0.40126851201057434\n",
      "Batch: 385 Loss: 0.406605064868927\n",
      "Batch: 449 Loss: 0.37594616413116455\n",
      "Batch: 513 Loss: 0.3895823657512665\n",
      "Batch: 577 Loss: 0.38646766543388367\n",
      "Batch: 641 Loss: 0.46479496359825134\n",
      "Batch: 705 Loss: 0.4068501889705658\n",
      "Batch: 769 Loss: 0.4531921148300171\n",
      "Batch: 833 Loss: 0.33531686663627625\n",
      "Batch: 897 Loss: 0.5645147562026978\n",
      "Batch: 961 Loss: 0.3644302487373352\n",
      "Batch: 1025 Loss: 0.3974055051803589\n",
      "Batch: 1089 Loss: 0.38995686173439026\n",
      "Batch: 1153 Loss: 0.4262612760066986\n",
      "Batch: 1217 Loss: 0.38372114300727844\n",
      "Batch: 1281 Loss: 0.41385287046432495\n",
      "Batch: 1345 Loss: 0.42265936732292175\n",
      "Batch: 1409 Loss: 0.3551538586616516\n",
      "Batch: 1473 Loss: 0.4032403826713562\n",
      "Batch: 1537 Loss: 0.3819131553173065\n",
      "Batch: 1601 Loss: 0.32377856969833374\n",
      "Batch: 1665 Loss: 0.36560365557670593\n",
      "Batch: 1729 Loss: 0.42583680152893066\n",
      "Batch: 1793 Loss: 0.3345986604690552\n",
      "Batch: 1857 Loss: 0.3776024878025055\n",
      "Batch: 1921 Loss: 0.4166804850101471\n",
      "Batch: 1985 Loss: 0.3580682575702667\n",
      "Batch: 2049 Loss: 0.33151012659072876\n",
      "Batch: 2113 Loss: 0.34209129214286804\n",
      "Batch: 2177 Loss: 0.39133718609809875\n",
      "Batch: 2241 Loss: 0.43394526839256287\n",
      "Batch: 2305 Loss: 0.44711893796920776\n",
      "Batch: 2369 Loss: 0.465657502412796\n",
      "Batch: 2433 Loss: 0.4286821782588959\n",
      "Batch: 2497 Loss: 0.4855496883392334\n",
      "Batch: 2561 Loss: 0.4070926904678345\n",
      "Batch: 2625 Loss: 0.4205766022205353\n",
      "Batch: 2689 Loss: 0.4340217709541321\n",
      "Batch: 2753 Loss: 0.35178229212760925\n",
      "Batch: 2817 Loss: 0.5173997282981873\n",
      "Batch: 2881 Loss: 0.43949201703071594\n",
      "Batch: 2945 Loss: 0.38386356830596924\n",
      "Batch: 3009 Loss: 0.5424649119377136\n",
      "Batch: 3073 Loss: 0.425776869058609\n",
      "Batch: 3137 Loss: 0.3902539014816284\n",
      "Batch: 3201 Loss: 0.3786146640777588\n",
      "Batch: 3265 Loss: 0.36664894223213196\n",
      "Batch: 3329 Loss: 0.39729708433151245\n",
      "Batch: 3393 Loss: 0.4185336232185364\n",
      "Batch: 3457 Loss: 0.3829459249973297\n",
      "Batch: 3521 Loss: 0.2974637746810913\n",
      "Batch: 3585 Loss: 0.28191307187080383\n",
      "Batch: 3649 Loss: 0.4620983600616455\n",
      "Batch: 3713 Loss: 0.382854700088501\n",
      "Batch: 3777 Loss: 0.4041556119918823\n",
      "Batch: 3841 Loss: 0.4049636721611023\n",
      "Batch: 3905 Loss: 0.37020343542099\n",
      "Batch: 3969 Loss: 0.5154848694801331\n",
      "Batch: 4033 Loss: 0.3881922662258148\n",
      "Batch: 4097 Loss: 0.3871825337409973\n",
      "Batch: 4161 Loss: 0.4496667981147766\n",
      "Batch: 4225 Loss: 0.328542023897171\n",
      "Batch: 4289 Loss: 0.3518069088459015\n",
      "Batch: 4353 Loss: 0.47756513953208923\n",
      "Batch: 4417 Loss: 0.6052570939064026\n",
      "Batch: 4481 Loss: 0.6730092763900757\n",
      "Batch: 4545 Loss: 0.5378207564353943\n",
      "Batch: 4609 Loss: 0.3668978214263916\n",
      "Batch: 4673 Loss: 0.3455020785331726\n",
      "Batch: 4737 Loss: 0.44359728693962097\n",
      "Batch: 4801 Loss: 0.35991916060447693\n",
      "Batch: 4865 Loss: 0.3512204587459564\n",
      "Batch: 4929 Loss: 0.4025498628616333\n",
      "Batch: 4993 Loss: 0.5048084259033203\n",
      "Batch: 5057 Loss: 0.4936058521270752\n",
      "Batch: 5121 Loss: 0.386035293340683\n",
      "Batch: 5185 Loss: 0.8417812585830688\n",
      "Batch: 5249 Loss: 0.3653855621814728\n",
      "Batch: 5313 Loss: 0.4361775815486908\n",
      "Batch: 5377 Loss: 0.4225441515445709\n",
      "Batch: 5441 Loss: 0.5148155093193054\n",
      "Batch: 5505 Loss: 0.46704965829849243\n",
      "Batch: 5569 Loss: 0.5226946473121643\n",
      "Batch: 5633 Loss: 0.38099610805511475\n",
      "Batch: 5697 Loss: 0.42787066102027893\n",
      "Batch: 5761 Loss: 0.5474218726158142\n",
      "Batch: 5825 Loss: 0.4248273968696594\n",
      "Batch: 5889 Loss: 0.38001546263694763\n",
      "Batch: 5953 Loss: 0.38250797986984253\n",
      "Batch: 6017 Loss: 0.31884828209877014\n",
      "Batch: 6081 Loss: 0.2944885492324829\n",
      "Batch: 6145 Loss: 0.4041290879249573\n",
      "Batch: 6209 Loss: 0.33984607458114624\n",
      "Batch: 6273 Loss: 0.4556790292263031\n",
      "Batch: 6337 Loss: 0.32975614070892334\n",
      "Batch: 6401 Loss: 0.33327993750572205\n",
      "Batch: 6465 Loss: 0.37374693155288696\n",
      "Batch: 6529 Loss: 0.3514830470085144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 6593 Loss: 0.370140016078949\n",
      "Batch: 6657 Loss: 0.3091422915458679\n",
      "Batch: 6721 Loss: 0.4211236834526062\n",
      "Batch: 6785 Loss: 0.4073486030101776\n",
      "Batch: 6849 Loss: 0.4093124270439148\n",
      "Batch: 6913 Loss: 0.3905157744884491\n",
      "Batch: 6977 Loss: 0.42445147037506104\n",
      "Batch: 7041 Loss: 0.41518333554267883\n",
      "Batch: 7105 Loss: 0.3284432291984558\n",
      "Batch: 7169 Loss: 0.3923080265522003\n",
      "Batch: 7233 Loss: 0.3507133722305298\n",
      "Batch: 7297 Loss: 0.41097787022590637\n",
      "Batch: 7361 Loss: 0.38229236006736755\n",
      "Batch: 7425 Loss: 0.4651913046836853\n",
      "Batch: 7489 Loss: 0.5585435628890991\n",
      "Batch: 7553 Loss: 0.36369845271110535\n",
      "Batch: 7617 Loss: 0.3634454607963562\n",
      "Batch: 7681 Loss: 0.43997281789779663\n",
      "Batch: 7745 Loss: 0.45146504044532776\n",
      "Batch: 7809 Loss: 0.41565439105033875\n",
      "Batch: 7873 Loss: 0.33000773191452026\n",
      "Batch: 7937 Loss: 0.538555383682251\n",
      "Batch: 8001 Loss: 0.38976603746414185\n",
      "Batch: 8065 Loss: 0.5330522656440735\n",
      "Batch: 8129 Loss: 0.3918055295944214\n",
      "Batch: 8193 Loss: 0.43914350867271423\n",
      "Batch: 8257 Loss: 0.4667646288871765\n",
      "Batch: 8321 Loss: 0.6308879256248474\n",
      "Batch: 8385 Loss: 0.3097229599952698\n",
      "Batch: 8449 Loss: 0.34503039717674255\n",
      "Batch: 8513 Loss: 0.630796492099762\n",
      "Batch: 8577 Loss: 0.32210516929626465\n",
      "Batch: 8641 Loss: 0.49070316553115845\n",
      "Batch: 8705 Loss: 0.3897467851638794\n",
      "Batch: 8769 Loss: 0.4573979675769806\n",
      "Batch: 8833 Loss: 0.5118115544319153\n",
      "Batch: 8897 Loss: 0.7843655943870544\n",
      "Batch: 8961 Loss: 0.3905915915966034\n",
      "Batch: 9025 Loss: 0.38590699434280396\n",
      "Batch: 9089 Loss: 0.3952842652797699\n",
      "Batch: 9153 Loss: 0.4571526348590851\n",
      "Batch: 9217 Loss: 0.48823440074920654\n",
      "Batch: 9281 Loss: 0.4443175494670868\n",
      "Batch: 9345 Loss: 0.3481180667877197\n",
      "Batch: 9409 Loss: 0.4768315851688385\n",
      "Batch: 9473 Loss: 0.5396921634674072\n",
      "Batch: 9537 Loss: 0.4631952941417694\n",
      "Batch: 9601 Loss: 0.3567350208759308\n",
      "Batch: 9665 Loss: 0.3327217102050781\n",
      "Batch: 9729 Loss: 0.43232616782188416\n",
      "Batch: 9793 Loss: 0.3770463168621063\n",
      "Batch: 9857 Loss: 0.4269370436668396\n",
      "Batch: 9921 Loss: 0.3922461271286011\n",
      "Batch: 9985 Loss: 0.4407830536365509\n",
      "Batch: 10049 Loss: 0.5115426182746887\n",
      "Batch: 10113 Loss: 0.39414116740226746\n",
      "Batch: 10177 Loss: 0.4957095682621002\n",
      "Batch: 10241 Loss: 0.36331307888031006\n",
      "Batch: 10305 Loss: 0.43600523471832275\n",
      "Batch: 10369 Loss: 0.4790806174278259\n",
      "Batch: 10433 Loss: 0.3989640176296234\n",
      "Batch: 10497 Loss: 0.391143798828125\n",
      "Batch: 10561 Loss: 0.3652023673057556\n",
      "Batch: 10625 Loss: 0.43612849712371826\n",
      "Batch: 10689 Loss: 0.4318382441997528\n",
      "Batch: 10753 Loss: 0.3494269549846649\n",
      "Batch: 10817 Loss: 0.3086678385734558\n",
      "Batch: 10881 Loss: 0.37460216879844666\n",
      "Batch: 10945 Loss: 0.36072221398353577\n",
      "Batch: 11009 Loss: 0.43706727027893066\n",
      "Batch: 11073 Loss: 0.45888519287109375\n",
      "Batch: 11137 Loss: 0.36702513694763184\n",
      "Batch: 11201 Loss: 0.3696613311767578\n",
      "Batch: 11265 Loss: 0.5262821316719055\n",
      "Batch: 11329 Loss: 0.6773717403411865\n",
      "Batch: 11393 Loss: 0.3446532189846039\n",
      "Batch: 11457 Loss: 0.4281730651855469\n",
      "Batch: 11521 Loss: 0.43847692012786865\n",
      "Batch: 11585 Loss: 0.5125715136528015\n",
      "Batch: 11649 Loss: 0.35599377751350403\n",
      "Batch: 11713 Loss: 0.44657570123672485\n",
      "Batch: 11777 Loss: 0.61400306224823\n",
      "Batch: 11841 Loss: 0.575179398059845\n",
      "Batch: 11905 Loss: 0.4353507161140442\n",
      "Batch: 11969 Loss: 0.4523456394672394\n",
      "Batch: 12033 Loss: 0.39302462339401245\n",
      "Batch: 12097 Loss: 0.9583224654197693\n",
      "Batch: 12161 Loss: 0.5361261963844299\n",
      "Batch: 12225 Loss: 0.32874158024787903\n",
      "Batch: 12289 Loss: 0.3310837149620056\n",
      "Batch: 12353 Loss: 0.4219247102737427\n",
      "Batch: 12417 Loss: 0.34221428632736206\n",
      "Batch: 12481 Loss: 0.38398098945617676\n",
      "Batch: 12545 Loss: 0.49591174721717834\n",
      "Batch: 12609 Loss: 0.5355173349380493\n",
      "Batch: 12673 Loss: 0.5266757011413574\n",
      "Batch: 12737 Loss: 0.4594781994819641\n",
      "Batch: 12801 Loss: 0.37472519278526306\n",
      "Batch: 12865 Loss: 0.3288514018058777\n",
      "Batch: 12929 Loss: 0.6688116192817688\n",
      "Epoch: 48\n",
      "Batch: 1 Loss: 0.4034518003463745\n",
      "Batch: 65 Loss: 0.47246691584587097\n",
      "Batch: 129 Loss: 0.3982940912246704\n",
      "Batch: 193 Loss: 0.5909285545349121\n",
      "Batch: 257 Loss: 0.4235547184944153\n",
      "Batch: 321 Loss: 0.40892890095710754\n",
      "Batch: 385 Loss: 0.41399210691452026\n",
      "Batch: 449 Loss: 0.38397976756095886\n",
      "Batch: 513 Loss: 0.4000994861125946\n",
      "Batch: 577 Loss: 0.40763700008392334\n",
      "Batch: 641 Loss: 0.4870681166648865\n",
      "Batch: 705 Loss: 0.43151989579200745\n",
      "Batch: 769 Loss: 0.47515740990638733\n",
      "Batch: 833 Loss: 0.3622910976409912\n",
      "Batch: 897 Loss: 0.5782394409179688\n",
      "Batch: 961 Loss: 0.3867521584033966\n",
      "Batch: 1025 Loss: 0.4206012487411499\n",
      "Batch: 1089 Loss: 0.40750235319137573\n",
      "Batch: 1153 Loss: 0.4441682696342468\n",
      "Batch: 1217 Loss: 0.3961630165576935\n",
      "Batch: 1281 Loss: 0.4199084937572479\n",
      "Batch: 1345 Loss: 0.4398172199726105\n",
      "Batch: 1409 Loss: 0.3644846975803375\n",
      "Batch: 1473 Loss: 0.4140183925628662\n",
      "Batch: 1537 Loss: 0.39052656292915344\n",
      "Batch: 1601 Loss: 0.3418826162815094\n",
      "Batch: 1665 Loss: 0.38509318232536316\n",
      "Batch: 1729 Loss: 0.4456545412540436\n",
      "Batch: 1793 Loss: 0.35037267208099365\n",
      "Batch: 1857 Loss: 0.3833880126476288\n",
      "Batch: 1921 Loss: 0.41858914494514465\n",
      "Batch: 1985 Loss: 0.37543800473213196\n",
      "Batch: 2049 Loss: 0.35264304280281067\n",
      "Batch: 2113 Loss: 0.37252113223075867\n",
      "Batch: 2177 Loss: 0.3921295404434204\n",
      "Batch: 2241 Loss: 0.44750314950942993\n",
      "Batch: 2305 Loss: 0.5012999176979065\n",
      "Batch: 2369 Loss: 0.5215821862220764\n",
      "Batch: 2433 Loss: 0.4509996175765991\n",
      "Batch: 2497 Loss: 0.5023770332336426\n",
      "Batch: 2561 Loss: 0.41115254163742065\n",
      "Batch: 2625 Loss: 0.43731603026390076\n",
      "Batch: 2689 Loss: 0.45184460282325745\n",
      "Batch: 2753 Loss: 0.37188875675201416\n",
      "Batch: 2817 Loss: 0.5168720483779907\n",
      "Batch: 2881 Loss: 0.4468346834182739\n",
      "Batch: 2945 Loss: 0.39523622393608093\n",
      "Batch: 3009 Loss: 0.5433967113494873\n",
      "Batch: 3073 Loss: 0.428436279296875\n",
      "Batch: 3137 Loss: 0.4025352895259857\n",
      "Batch: 3201 Loss: 0.4021734297275543\n",
      "Batch: 3265 Loss: 0.40166226029396057\n",
      "Batch: 3329 Loss: 0.4064081311225891\n",
      "Batch: 3393 Loss: 0.4214169681072235\n",
      "Batch: 3457 Loss: 0.3831344246864319\n",
      "Batch: 3521 Loss: 0.3114970922470093\n",
      "Batch: 3585 Loss: 0.2960488796234131\n",
      "Batch: 3649 Loss: 0.4680616855621338\n",
      "Batch: 3713 Loss: 0.3822111487388611\n",
      "Batch: 3777 Loss: 0.4042474031448364\n",
      "Batch: 3841 Loss: 0.42811208963394165\n",
      "Batch: 3905 Loss: 0.38651737570762634\n",
      "Batch: 3969 Loss: 0.5167310237884521\n",
      "Batch: 4033 Loss: 0.3891986012458801\n",
      "Batch: 4097 Loss: 0.387519896030426\n",
      "Batch: 4161 Loss: 0.45123597979545593\n",
      "Batch: 4225 Loss: 0.34643399715423584\n",
      "Batch: 4289 Loss: 0.3619077205657959\n",
      "Batch: 4353 Loss: 0.49482467770576477\n",
      "Batch: 4417 Loss: 0.6080639958381653\n",
      "Batch: 4481 Loss: 0.6561933755874634\n",
      "Batch: 4545 Loss: 0.5585819482803345\n",
      "Batch: 4609 Loss: 0.3801611661911011\n",
      "Batch: 4673 Loss: 0.36510607600212097\n",
      "Batch: 4737 Loss: 0.44745317101478577\n",
      "Batch: 4801 Loss: 0.3745685815811157\n",
      "Batch: 4865 Loss: 0.3547852337360382\n",
      "Batch: 4929 Loss: 0.4004165232181549\n",
      "Batch: 4993 Loss: 0.5306317806243896\n",
      "Batch: 5057 Loss: 0.5191347599029541\n",
      "Batch: 5121 Loss: 0.4380355477333069\n",
      "Batch: 5185 Loss: 0.8864973783493042\n",
      "Batch: 5249 Loss: 0.37977519631385803\n",
      "Batch: 5313 Loss: 0.4578917324542999\n",
      "Batch: 5377 Loss: 0.4319141209125519\n",
      "Batch: 5441 Loss: 0.5008795261383057\n",
      "Batch: 5505 Loss: 0.46330511569976807\n",
      "Batch: 5569 Loss: 0.5250505208969116\n",
      "Batch: 5633 Loss: 0.3775486648082733\n",
      "Batch: 5697 Loss: 0.42852139472961426\n",
      "Batch: 5761 Loss: 0.5471159219741821\n",
      "Batch: 5825 Loss: 0.4390413165092468\n",
      "Batch: 5889 Loss: 0.387109637260437\n",
      "Batch: 5953 Loss: 0.39732053875923157\n",
      "Batch: 6017 Loss: 0.32971301674842834\n",
      "Batch: 6081 Loss: 0.2949298024177551\n",
      "Batch: 6145 Loss: 0.4025089144706726\n",
      "Batch: 6209 Loss: 0.3465571999549866\n",
      "Batch: 6273 Loss: 0.46054840087890625\n",
      "Batch: 6337 Loss: 0.3488888144493103\n",
      "Batch: 6401 Loss: 0.3473326563835144\n",
      "Batch: 6465 Loss: 0.3862876296043396\n",
      "Batch: 6529 Loss: 0.36014893651008606\n",
      "Batch: 6593 Loss: 0.37233036756515503\n",
      "Batch: 6657 Loss: 0.31542396545410156\n",
      "Batch: 6721 Loss: 0.4320853352546692\n",
      "Batch: 6785 Loss: 0.4077287018299103\n",
      "Batch: 6849 Loss: 0.4120693802833557\n",
      "Batch: 6913 Loss: 0.3950011730194092\n",
      "Batch: 6977 Loss: 0.43374523520469666\n",
      "Batch: 7041 Loss: 0.43098342418670654\n",
      "Batch: 7105 Loss: 0.34225353598594666\n",
      "Batch: 7169 Loss: 0.3943709135055542\n",
      "Batch: 7233 Loss: 0.3512520492076874\n",
      "Batch: 7297 Loss: 0.4171304702758789\n",
      "Batch: 7361 Loss: 0.3837321400642395\n",
      "Batch: 7425 Loss: 0.4697018563747406\n",
      "Batch: 7489 Loss: 0.566800057888031\n",
      "Batch: 7553 Loss: 0.3804982006549835\n",
      "Batch: 7617 Loss: 0.374316930770874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 7681 Loss: 0.452227920293808\n",
      "Batch: 7745 Loss: 0.45846042037010193\n",
      "Batch: 7809 Loss: 0.4206087589263916\n",
      "Batch: 7873 Loss: 0.3293689489364624\n",
      "Batch: 7937 Loss: 0.535714864730835\n",
      "Batch: 8001 Loss: 0.3905866742134094\n",
      "Batch: 8065 Loss: 0.5358048677444458\n",
      "Batch: 8129 Loss: 0.3928598165512085\n",
      "Batch: 8193 Loss: 0.45920881628990173\n",
      "Batch: 8257 Loss: 0.4637144207954407\n",
      "Batch: 8321 Loss: 0.6343038082122803\n",
      "Batch: 8385 Loss: 0.31888115406036377\n",
      "Batch: 8449 Loss: 0.3547744154930115\n",
      "Batch: 8513 Loss: 0.6352112293243408\n",
      "Batch: 8577 Loss: 0.3247746527194977\n",
      "Batch: 8641 Loss: 0.4904254972934723\n",
      "Batch: 8705 Loss: 0.3898472189903259\n",
      "Batch: 8769 Loss: 0.4609697163105011\n",
      "Batch: 8833 Loss: 0.5118924379348755\n",
      "Batch: 8897 Loss: 0.7818402647972107\n",
      "Batch: 8961 Loss: 0.3954712152481079\n",
      "Batch: 9025 Loss: 0.39483073353767395\n",
      "Batch: 9089 Loss: 0.40142810344696045\n",
      "Batch: 9153 Loss: 0.4609338641166687\n",
      "Batch: 9217 Loss: 0.48834171891212463\n",
      "Batch: 9281 Loss: 0.4436900317668915\n",
      "Batch: 9345 Loss: 0.34964290261268616\n",
      "Batch: 9409 Loss: 0.47904130816459656\n",
      "Batch: 9473 Loss: 0.5422112941741943\n",
      "Batch: 9537 Loss: 0.46767333149909973\n",
      "Batch: 9601 Loss: 0.36426445841789246\n",
      "Batch: 9665 Loss: 0.3360389471054077\n",
      "Batch: 9729 Loss: 0.4378814697265625\n",
      "Batch: 9793 Loss: 0.3805893063545227\n",
      "Batch: 9857 Loss: 0.4332573711872101\n",
      "Batch: 9921 Loss: 0.3933752179145813\n",
      "Batch: 9985 Loss: 0.4296795129776001\n",
      "Batch: 10049 Loss: 0.4966723620891571\n",
      "Batch: 10113 Loss: 0.38720032572746277\n",
      "Batch: 10177 Loss: 0.4743511378765106\n",
      "Batch: 10241 Loss: 0.3673345446586609\n",
      "Batch: 10305 Loss: 0.4375115931034088\n",
      "Batch: 10369 Loss: 0.4875970184803009\n",
      "Batch: 10433 Loss: 0.4090723693370819\n",
      "Batch: 10497 Loss: 0.40077388286590576\n",
      "Batch: 10561 Loss: 0.36710819602012634\n",
      "Batch: 10625 Loss: 0.43665099143981934\n",
      "Batch: 10689 Loss: 0.40145954489707947\n",
      "Batch: 10753 Loss: 0.3534576892852783\n",
      "Batch: 10817 Loss: 0.31164464354515076\n",
      "Batch: 10881 Loss: 0.3601440191268921\n",
      "Batch: 10945 Loss: 0.3309417963027954\n",
      "Batch: 11009 Loss: 0.3828164041042328\n",
      "Batch: 11073 Loss: 0.42905426025390625\n",
      "Batch: 11137 Loss: 0.348005086183548\n",
      "Batch: 11201 Loss: 0.3624034821987152\n",
      "Batch: 11265 Loss: 0.5141242146492004\n",
      "Batch: 11329 Loss: 0.6491686105728149\n",
      "Batch: 11393 Loss: 0.28414615988731384\n",
      "Batch: 11457 Loss: 0.35772669315338135\n",
      "Batch: 11521 Loss: 0.3689562678337097\n",
      "Batch: 11585 Loss: 0.4927900433540344\n",
      "Batch: 11649 Loss: 0.32701095938682556\n",
      "Batch: 11713 Loss: 0.41768768429756165\n",
      "Batch: 11777 Loss: 0.6089080572128296\n",
      "Batch: 11841 Loss: 0.5582032799720764\n",
      "Batch: 11905 Loss: 0.43365633487701416\n",
      "Batch: 11969 Loss: 0.3978743255138397\n",
      "Batch: 12033 Loss: 0.37034282088279724\n",
      "Batch: 12097 Loss: 0.9133743643760681\n",
      "Batch: 12161 Loss: 0.5052617192268372\n",
      "Batch: 12225 Loss: 0.3005441725254059\n",
      "Batch: 12289 Loss: 0.3094543218612671\n",
      "Batch: 12353 Loss: 0.4079474210739136\n",
      "Batch: 12417 Loss: 0.3415513336658478\n",
      "Batch: 12481 Loss: 0.37565845251083374\n",
      "Batch: 12545 Loss: 0.4764748811721802\n",
      "Batch: 12609 Loss: 0.5133486390113831\n",
      "Batch: 12673 Loss: 0.5248482823371887\n",
      "Batch: 12737 Loss: 0.44927462935447693\n",
      "Batch: 12801 Loss: 0.37060970067977905\n",
      "Batch: 12865 Loss: 0.3117808699607849\n",
      "Batch: 12929 Loss: 0.6359304189682007\n",
      "Epoch: 49\n",
      "Batch: 1 Loss: 0.4003584682941437\n",
      "Batch: 65 Loss: 0.4638440012931824\n",
      "Batch: 129 Loss: 0.39915022253990173\n",
      "Batch: 193 Loss: 0.5953177809715271\n",
      "Batch: 257 Loss: 0.4230727553367615\n",
      "Batch: 321 Loss: 0.4079879820346832\n",
      "Batch: 385 Loss: 0.41126880049705505\n",
      "Batch: 449 Loss: 0.37530645728111267\n",
      "Batch: 513 Loss: 0.3946196138858795\n",
      "Batch: 577 Loss: 0.39173945784568787\n",
      "Batch: 641 Loss: 0.4719613492488861\n",
      "Batch: 705 Loss: 0.4162188768386841\n",
      "Batch: 769 Loss: 0.4660189747810364\n",
      "Batch: 833 Loss: 0.3516349196434021\n",
      "Batch: 897 Loss: 0.572012722492218\n",
      "Batch: 961 Loss: 0.3766636550426483\n",
      "Batch: 1025 Loss: 0.406897634267807\n",
      "Batch: 1089 Loss: 0.3910266160964966\n",
      "Batch: 1153 Loss: 0.42548301815986633\n",
      "Batch: 1217 Loss: 0.38807621598243713\n",
      "Batch: 1281 Loss: 0.4140598475933075\n",
      "Batch: 1345 Loss: 0.4240473210811615\n",
      "Batch: 1409 Loss: 0.35691142082214355\n",
      "Batch: 1473 Loss: 0.40763017535209656\n",
      "Batch: 1537 Loss: 0.38469037413597107\n",
      "Batch: 1601 Loss: 0.33205339312553406\n",
      "Batch: 1665 Loss: 0.3701477348804474\n",
      "Batch: 1729 Loss: 0.4316696524620056\n",
      "Batch: 1793 Loss: 0.3354809582233429\n",
      "Batch: 1857 Loss: 0.38346952199935913\n",
      "Batch: 1921 Loss: 0.4164794981479645\n",
      "Batch: 1985 Loss: 0.3623155951499939\n",
      "Batch: 2049 Loss: 0.3321071267127991\n",
      "Batch: 2113 Loss: 0.3555733561515808\n",
      "Batch: 2177 Loss: 0.3911781311035156\n",
      "Batch: 2241 Loss: 0.43321314454078674\n",
      "Batch: 2305 Loss: 0.4488065242767334\n",
      "Batch: 2369 Loss: 0.46627935767173767\n",
      "Batch: 2433 Loss: 0.43657147884368896\n",
      "Batch: 2497 Loss: 0.506542980670929\n",
      "Batch: 2561 Loss: 0.40490031242370605\n",
      "Batch: 2625 Loss: 0.4523589313030243\n",
      "Batch: 2689 Loss: 0.438884973526001\n",
      "Batch: 2753 Loss: 0.3510226011276245\n",
      "Batch: 2817 Loss: 0.5238775610923767\n",
      "Batch: 2881 Loss: 0.4463558793067932\n",
      "Batch: 2945 Loss: 0.3821379244327545\n",
      "Batch: 3009 Loss: 0.5423083305358887\n",
      "Batch: 3073 Loss: 0.42602434754371643\n",
      "Batch: 3137 Loss: 0.3916279077529907\n",
      "Batch: 3201 Loss: 0.38142189383506775\n",
      "Batch: 3265 Loss: 0.3685327470302582\n",
      "Batch: 3329 Loss: 0.39867010712623596\n",
      "Batch: 3393 Loss: 0.4183920919895172\n",
      "Batch: 3457 Loss: 0.3856804072856903\n",
      "Batch: 3521 Loss: 0.32743003964424133\n",
      "Batch: 3585 Loss: 0.2832479774951935\n",
      "Batch: 3649 Loss: 0.4616847336292267\n",
      "Batch: 3713 Loss: 0.3813008666038513\n",
      "Batch: 3777 Loss: 0.40529245138168335\n",
      "Batch: 3841 Loss: 0.40861770510673523\n",
      "Batch: 3905 Loss: 0.3697606325149536\n",
      "Batch: 3969 Loss: 0.5133559107780457\n",
      "Batch: 4033 Loss: 0.38737523555755615\n",
      "Batch: 4097 Loss: 0.38800525665283203\n",
      "Batch: 4161 Loss: 0.4505521059036255\n",
      "Batch: 4225 Loss: 0.3291797935962677\n",
      "Batch: 4289 Loss: 0.35401245951652527\n",
      "Batch: 4353 Loss: 0.4784168601036072\n",
      "Batch: 4417 Loss: 0.6053188443183899\n",
      "Batch: 4481 Loss: 0.6552184224128723\n",
      "Batch: 4545 Loss: 0.5318540334701538\n",
      "Batch: 4609 Loss: 0.3702567219734192\n",
      "Batch: 4673 Loss: 0.34955212473869324\n",
      "Batch: 4737 Loss: 0.44704335927963257\n",
      "Batch: 4801 Loss: 0.3673819601535797\n",
      "Batch: 4865 Loss: 0.34972137212753296\n",
      "Batch: 4929 Loss: 0.3992554545402527\n",
      "Batch: 4993 Loss: 0.505200982093811\n",
      "Batch: 5057 Loss: 0.4916714131832123\n",
      "Batch: 5121 Loss: 0.3872300386428833\n",
      "Batch: 5185 Loss: 0.8403356075286865\n",
      "Batch: 5249 Loss: 0.36695536971092224\n",
      "Batch: 5313 Loss: 0.4373287856578827\n",
      "Batch: 5377 Loss: 0.4199041426181793\n",
      "Batch: 5441 Loss: 0.499107301235199\n",
      "Batch: 5505 Loss: 0.46908336877822876\n",
      "Batch: 5569 Loss: 0.5177695751190186\n",
      "Batch: 5633 Loss: 0.3745073974132538\n",
      "Batch: 5697 Loss: 0.42696627974510193\n",
      "Batch: 5761 Loss: 0.5470671057701111\n",
      "Batch: 5825 Loss: 0.4267619252204895\n",
      "Batch: 5889 Loss: 0.38691043853759766\n",
      "Batch: 5953 Loss: 0.38497117161750793\n",
      "Batch: 6017 Loss: 0.3198930621147156\n",
      "Batch: 6081 Loss: 0.29657167196273804\n",
      "Batch: 6145 Loss: 0.40399911999702454\n",
      "Batch: 6209 Loss: 0.347642719745636\n",
      "Batch: 6273 Loss: 0.45620229840278625\n",
      "Batch: 6337 Loss: 0.3342025578022003\n",
      "Batch: 6401 Loss: 0.3361127972602844\n",
      "Batch: 6465 Loss: 0.3758026957511902\n",
      "Batch: 6529 Loss: 0.3508857488632202\n",
      "Batch: 6593 Loss: 0.37507739663124084\n",
      "Batch: 6657 Loss: 0.31528547406196594\n",
      "Batch: 6721 Loss: 0.4132532477378845\n",
      "Batch: 6785 Loss: 0.4086112380027771\n",
      "Batch: 6849 Loss: 0.4087298810482025\n",
      "Batch: 6913 Loss: 0.3897540867328644\n",
      "Batch: 6977 Loss: 0.42641201615333557\n",
      "Batch: 7041 Loss: 0.41806653141975403\n",
      "Batch: 7105 Loss: 0.3309432864189148\n",
      "Batch: 7169 Loss: 0.40545257925987244\n",
      "Batch: 7233 Loss: 0.35741859674453735\n",
      "Batch: 7297 Loss: 0.41005459427833557\n",
      "Batch: 7361 Loss: 0.38230669498443604\n",
      "Batch: 7425 Loss: 0.46863093972206116\n",
      "Batch: 7489 Loss: 0.559276819229126\n",
      "Batch: 7553 Loss: 0.36666497588157654\n",
      "Batch: 7617 Loss: 0.3679301142692566\n",
      "Batch: 7681 Loss: 0.44056037068367004\n",
      "Batch: 7745 Loss: 0.4539642632007599\n",
      "Batch: 7809 Loss: 0.41492778062820435\n",
      "Batch: 7873 Loss: 0.3266054391860962\n",
      "Batch: 7937 Loss: 0.5364545583724976\n",
      "Batch: 8001 Loss: 0.38953325152397156\n",
      "Batch: 8065 Loss: 0.5329312086105347\n",
      "Batch: 8129 Loss: 0.3915967643260956\n",
      "Batch: 8193 Loss: 0.43677380681037903\n",
      "Batch: 8257 Loss: 0.4592910408973694\n",
      "Batch: 8321 Loss: 0.6299349665641785\n",
      "Batch: 8385 Loss: 0.3102647364139557\n",
      "Batch: 8449 Loss: 0.3467943072319031\n",
      "Batch: 8513 Loss: 0.6316205859184265\n",
      "Batch: 8577 Loss: 0.32250067591667175\n",
      "Batch: 8641 Loss: 0.48722344636917114\n",
      "Batch: 8705 Loss: 0.39341360330581665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 8769 Loss: 0.45675402879714966\n",
      "Batch: 8833 Loss: 0.5101260542869568\n",
      "Batch: 8897 Loss: 0.7808215022087097\n",
      "Batch: 8961 Loss: 0.39105063676834106\n",
      "Batch: 9025 Loss: 0.38841408491134644\n",
      "Batch: 9089 Loss: 0.39781585335731506\n",
      "Batch: 9153 Loss: 0.45750245451927185\n",
      "Batch: 9217 Loss: 0.48772868514060974\n",
      "Batch: 9281 Loss: 0.4437682330608368\n",
      "Batch: 9345 Loss: 0.3499528169631958\n",
      "Batch: 9409 Loss: 0.4822733700275421\n",
      "Batch: 9473 Loss: 0.5407877564430237\n",
      "Batch: 9537 Loss: 0.463338166475296\n",
      "Batch: 9601 Loss: 0.3544165790081024\n",
      "Batch: 9665 Loss: 0.3337952494621277\n",
      "Batch: 9729 Loss: 0.43235310912132263\n",
      "Batch: 9793 Loss: 0.3762480616569519\n",
      "Batch: 9857 Loss: 0.4302811920642853\n",
      "Batch: 9921 Loss: 0.39237818121910095\n",
      "Batch: 9985 Loss: 0.42949187755584717\n",
      "Batch: 10049 Loss: 0.4964306950569153\n",
      "Batch: 10113 Loss: 0.38697361946105957\n",
      "Batch: 10177 Loss: 0.4680977165699005\n",
      "Batch: 10241 Loss: 0.36260655522346497\n",
      "Batch: 10305 Loss: 0.4362812340259552\n",
      "Batch: 10369 Loss: 0.4799765944480896\n",
      "Batch: 10433 Loss: 0.40104687213897705\n",
      "Batch: 10497 Loss: 0.3943025767803192\n",
      "Batch: 10561 Loss: 0.36541178822517395\n",
      "Batch: 10625 Loss: 0.42970508337020874\n",
      "Batch: 10689 Loss: 0.39974522590637207\n",
      "Batch: 10753 Loss: 0.3506043255329132\n",
      "Batch: 10817 Loss: 0.3107494115829468\n",
      "Batch: 10881 Loss: 0.3523588180541992\n",
      "Batch: 10945 Loss: 0.3249501883983612\n",
      "Batch: 11009 Loss: 0.3552682101726532\n",
      "Batch: 11073 Loss: 0.4283739924430847\n",
      "Batch: 11137 Loss: 0.3478394150733948\n",
      "Batch: 11201 Loss: 0.3604802191257477\n",
      "Batch: 11265 Loss: 0.514082670211792\n",
      "Batch: 11329 Loss: 0.6380278468132019\n",
      "Batch: 11393 Loss: 0.2980368435382843\n",
      "Batch: 11457 Loss: 0.3569876253604889\n",
      "Batch: 11521 Loss: 0.3677099943161011\n",
      "Batch: 11585 Loss: 0.48766428232192993\n",
      "Batch: 11649 Loss: 0.32302388548851013\n",
      "Batch: 11713 Loss: 0.4153646230697632\n",
      "Batch: 11777 Loss: 0.6005718111991882\n",
      "Batch: 11841 Loss: 0.5530611872673035\n",
      "Batch: 11905 Loss: 0.43312394618988037\n",
      "Batch: 11969 Loss: 0.3980623185634613\n",
      "Batch: 12033 Loss: 0.3699604570865631\n",
      "Batch: 12097 Loss: 0.9109928011894226\n",
      "Batch: 12161 Loss: 0.5021952986717224\n",
      "Batch: 12225 Loss: 0.29489073157310486\n",
      "Batch: 12289 Loss: 0.3081273138523102\n",
      "Batch: 12353 Loss: 0.40782225131988525\n",
      "Batch: 12417 Loss: 0.3414713442325592\n",
      "Batch: 12481 Loss: 0.37552493810653687\n",
      "Batch: 12545 Loss: 0.47571808099746704\n",
      "Batch: 12609 Loss: 0.5144582986831665\n",
      "Batch: 12673 Loss: 0.524559736251831\n",
      "Batch: 12737 Loss: 0.4499664902687073\n",
      "Batch: 12801 Loss: 0.37119200825691223\n",
      "Batch: 12865 Loss: 0.31125137209892273\n",
      "Batch: 12929 Loss: 0.6354072690010071\n",
      "Epoch: 50\n",
      "Batch: 1 Loss: 0.39678943157196045\n",
      "Batch: 65 Loss: 0.4602331221103668\n",
      "Batch: 129 Loss: 0.3944859802722931\n",
      "Batch: 193 Loss: 0.5878505110740662\n",
      "Batch: 257 Loss: 0.4205687940120697\n",
      "Batch: 321 Loss: 0.40204229950904846\n",
      "Batch: 385 Loss: 0.40926551818847656\n",
      "Batch: 449 Loss: 0.37424278259277344\n",
      "Batch: 513 Loss: 0.3922280967235565\n",
      "Batch: 577 Loss: 0.3895658850669861\n",
      "Batch: 641 Loss: 0.4678274989128113\n",
      "Batch: 705 Loss: 0.412955641746521\n",
      "Batch: 769 Loss: 0.46157339215278625\n",
      "Batch: 833 Loss: 0.341933012008667\n",
      "Batch: 897 Loss: 0.5649934411048889\n",
      "Batch: 961 Loss: 0.3650423586368561\n",
      "Batch: 1025 Loss: 0.3978148400783539\n",
      "Batch: 1089 Loss: 0.3900979459285736\n",
      "Batch: 1153 Loss: 0.4209277331829071\n",
      "Batch: 1217 Loss: 0.3827749788761139\n",
      "Batch: 1281 Loss: 0.4161926507949829\n",
      "Batch: 1345 Loss: 0.4212800860404968\n",
      "Batch: 1409 Loss: 0.35725027322769165\n",
      "Batch: 1473 Loss: 0.411260724067688\n",
      "Batch: 1537 Loss: 0.3844653069972992\n",
      "Batch: 1601 Loss: 0.33020326495170593\n",
      "Batch: 1665 Loss: 0.3659069240093231\n",
      "Batch: 1729 Loss: 0.42862194776535034\n",
      "Batch: 1793 Loss: 0.3356439769268036\n",
      "Batch: 1857 Loss: 0.38062071800231934\n",
      "Batch: 1921 Loss: 0.420551061630249\n",
      "Batch: 1985 Loss: 0.36063215136528015\n",
      "Batch: 2049 Loss: 0.33096498250961304\n",
      "Batch: 2113 Loss: 0.34664061665534973\n",
      "Batch: 2177 Loss: 0.3907608091831207\n",
      "Batch: 2241 Loss: 0.4339469075202942\n",
      "Batch: 2305 Loss: 0.44709551334381104\n",
      "Batch: 2369 Loss: 0.46663105487823486\n",
      "Batch: 2433 Loss: 0.4328356087207794\n",
      "Batch: 2497 Loss: 0.4875781834125519\n",
      "Batch: 2561 Loss: 0.3998721241950989\n",
      "Batch: 2625 Loss: 0.42084723711013794\n",
      "Batch: 2689 Loss: 0.43620461225509644\n",
      "Batch: 2753 Loss: 0.34953105449676514\n",
      "Batch: 2817 Loss: 0.5168690085411072\n",
      "Batch: 2881 Loss: 0.43885570764541626\n",
      "Batch: 2945 Loss: 0.38226011395454407\n",
      "Batch: 3009 Loss: 0.5421837568283081\n",
      "Batch: 3073 Loss: 0.4251496195793152\n",
      "Batch: 3137 Loss: 0.39139750599861145\n",
      "Batch: 3201 Loss: 0.3796340525150299\n",
      "Batch: 3265 Loss: 0.3679251968860626\n",
      "Batch: 3329 Loss: 0.39971500635147095\n",
      "Batch: 3393 Loss: 0.41807958483695984\n",
      "Batch: 3457 Loss: 0.38420018553733826\n",
      "Batch: 3521 Loss: 0.298491507768631\n",
      "Batch: 3585 Loss: 0.2859356999397278\n",
      "Batch: 3649 Loss: 0.46212127804756165\n",
      "Batch: 3713 Loss: 0.38581496477127075\n",
      "Batch: 3777 Loss: 0.4034363627433777\n",
      "Batch: 3841 Loss: 0.40566185116767883\n",
      "Batch: 3905 Loss: 0.38032206892967224\n",
      "Batch: 3969 Loss: 0.5137218236923218\n",
      "Batch: 4033 Loss: 0.3927115201950073\n",
      "Batch: 4097 Loss: 0.3880646824836731\n",
      "Batch: 4161 Loss: 0.45766085386276245\n",
      "Batch: 4225 Loss: 0.3287595510482788\n",
      "Batch: 4289 Loss: 0.35883763432502747\n",
      "Batch: 4353 Loss: 0.47899743914604187\n",
      "Batch: 4417 Loss: 0.60380619764328\n",
      "Batch: 4481 Loss: 0.6541491150856018\n",
      "Batch: 4545 Loss: 0.5427900552749634\n",
      "Batch: 4609 Loss: 0.36750394105911255\n",
      "Batch: 4673 Loss: 0.3470679223537445\n",
      "Batch: 4737 Loss: 0.4438016414642334\n",
      "Batch: 4801 Loss: 0.36022111773490906\n",
      "Batch: 4865 Loss: 0.34948983788490295\n",
      "Batch: 4929 Loss: 0.39816075563430786\n",
      "Batch: 4993 Loss: 0.5044272541999817\n",
      "Batch: 5057 Loss: 0.4935086667537689\n",
      "Batch: 5121 Loss: 0.3869187831878662\n",
      "Batch: 5185 Loss: 0.8444430828094482\n",
      "Batch: 5249 Loss: 0.3669135868549347\n",
      "Batch: 5313 Loss: 0.4359980523586273\n",
      "Batch: 5377 Loss: 0.4200167953968048\n",
      "Batch: 5441 Loss: 0.49891379475593567\n",
      "Batch: 5505 Loss: 0.4744717478752136\n",
      "Batch: 5569 Loss: 0.5122061371803284\n",
      "Batch: 5633 Loss: 0.37362945079803467\n",
      "Batch: 5697 Loss: 0.42729634046554565\n",
      "Batch: 5761 Loss: 0.5464388728141785\n",
      "Batch: 5825 Loss: 0.424594521522522\n",
      "Batch: 5889 Loss: 0.3803378641605377\n",
      "Batch: 5953 Loss: 0.38430213928222656\n",
      "Batch: 6017 Loss: 0.3187107741832733\n",
      "Batch: 6081 Loss: 0.29345056414604187\n",
      "Batch: 6145 Loss: 0.39998289942741394\n",
      "Batch: 6209 Loss: 0.33908411860466003\n",
      "Batch: 6273 Loss: 0.45448946952819824\n",
      "Batch: 6337 Loss: 0.33183416724205017\n",
      "Batch: 6401 Loss: 0.3344080448150635\n",
      "Batch: 6465 Loss: 0.37572428584098816\n",
      "Batch: 6529 Loss: 0.35217052698135376\n",
      "Batch: 6593 Loss: 0.36932986974716187\n",
      "Batch: 6657 Loss: 0.3073213994503021\n",
      "Batch: 6721 Loss: 0.41475510597229004\n",
      "Batch: 6785 Loss: 0.40768855810165405\n",
      "Batch: 6849 Loss: 0.40694424510002136\n",
      "Batch: 6913 Loss: 0.3899671137332916\n",
      "Batch: 6977 Loss: 0.4260092079639435\n",
      "Batch: 7041 Loss: 0.41764986515045166\n",
      "Batch: 7105 Loss: 0.3309718072414398\n",
      "Batch: 7169 Loss: 0.39298924803733826\n",
      "Batch: 7233 Loss: 0.346988707780838\n",
      "Batch: 7297 Loss: 0.4099385738372803\n",
      "Batch: 7361 Loss: 0.3832646310329437\n",
      "Batch: 7425 Loss: 0.46852853894233704\n",
      "Batch: 7489 Loss: 0.5585689544677734\n",
      "Batch: 7553 Loss: 0.3655364513397217\n",
      "Batch: 7617 Loss: 0.3653048276901245\n",
      "Batch: 7681 Loss: 0.439571738243103\n",
      "Batch: 7745 Loss: 0.45365211367607117\n",
      "Batch: 7809 Loss: 0.4166882038116455\n",
      "Batch: 7873 Loss: 0.32543012499809265\n",
      "Batch: 7937 Loss: 0.5363221764564514\n",
      "Batch: 8001 Loss: 0.38892167806625366\n",
      "Batch: 8065 Loss: 0.5343239307403564\n",
      "Batch: 8129 Loss: 0.42649585008621216\n",
      "Batch: 8193 Loss: 0.4374488592147827\n",
      "Batch: 8257 Loss: 0.46091723442077637\n",
      "Batch: 8321 Loss: 0.6300057172775269\n",
      "Batch: 8385 Loss: 0.3100360929965973\n",
      "Batch: 8449 Loss: 0.346217542886734\n",
      "Batch: 8513 Loss: 0.63209068775177\n",
      "Batch: 8577 Loss: 0.3274100422859192\n",
      "Batch: 8641 Loss: 0.4865598678588867\n",
      "Batch: 8705 Loss: 0.3944881856441498\n",
      "Batch: 8769 Loss: 0.45674484968185425\n",
      "Batch: 8833 Loss: 0.5145533680915833\n",
      "Batch: 8897 Loss: 0.7826883792877197\n",
      "Batch: 8961 Loss: 0.389997661113739\n",
      "Batch: 9025 Loss: 0.3876304626464844\n",
      "Batch: 9089 Loss: 0.39794236421585083\n",
      "Batch: 9153 Loss: 0.4562877416610718\n",
      "Batch: 9217 Loss: 0.4880913496017456\n",
      "Batch: 9281 Loss: 0.4431804418563843\n",
      "Batch: 9345 Loss: 0.34715306758880615\n",
      "Batch: 9409 Loss: 0.47603023052215576\n",
      "Batch: 9473 Loss: 0.5387274026870728\n",
      "Batch: 9537 Loss: 0.4609227478504181\n",
      "Batch: 9601 Loss: 0.3569968342781067\n",
      "Batch: 9665 Loss: 0.3344630002975464\n",
      "Batch: 9729 Loss: 0.44256702065467834\n",
      "Batch: 9793 Loss: 0.37646108865737915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 9857 Loss: 0.428533136844635\n",
      "Batch: 9921 Loss: 0.39178135991096497\n",
      "Batch: 9985 Loss: 0.4290997385978699\n",
      "Batch: 10049 Loss: 0.4958685636520386\n",
      "Batch: 10113 Loss: 0.38581472635269165\n",
      "Batch: 10177 Loss: 0.46941715478897095\n",
      "Batch: 10241 Loss: 0.3630105257034302\n",
      "Batch: 10305 Loss: 0.4364536702632904\n",
      "Batch: 10369 Loss: 0.4799461364746094\n",
      "Batch: 10433 Loss: 0.3994373083114624\n",
      "Batch: 10497 Loss: 0.39129191637039185\n",
      "Batch: 10561 Loss: 0.3672262728214264\n",
      "Batch: 10625 Loss: 0.4307982921600342\n",
      "Batch: 10689 Loss: 0.4002099633216858\n",
      "Batch: 10753 Loss: 0.3564082384109497\n",
      "Batch: 10817 Loss: 0.31119754910469055\n",
      "Batch: 10881 Loss: 0.37140870094299316\n",
      "Batch: 10945 Loss: 0.3796878457069397\n",
      "Batch: 11009 Loss: 0.40737292170524597\n",
      "Batch: 11073 Loss: 0.4359918534755707\n",
      "Batch: 11137 Loss: 0.3480255901813507\n",
      "Batch: 11201 Loss: 0.3631518483161926\n",
      "Batch: 11265 Loss: 0.5100896954536438\n",
      "Batch: 11329 Loss: 0.63584965467453\n",
      "Batch: 11393 Loss: 0.2811521291732788\n",
      "Batch: 11457 Loss: 0.3569473922252655\n",
      "Batch: 11521 Loss: 0.36798033118247986\n",
      "Batch: 11585 Loss: 0.48790961503982544\n",
      "Batch: 11649 Loss: 0.32203343510627747\n",
      "Batch: 11713 Loss: 0.41260144114494324\n",
      "Batch: 11777 Loss: 0.5994967818260193\n",
      "Batch: 11841 Loss: 0.5523163080215454\n",
      "Batch: 11905 Loss: 0.4337216913700104\n",
      "Batch: 11969 Loss: 0.39877885580062866\n",
      "Batch: 12033 Loss: 0.3693437874317169\n",
      "Batch: 12097 Loss: 0.9130523800849915\n",
      "Batch: 12161 Loss: 0.49943849444389343\n",
      "Batch: 12225 Loss: 0.2937769591808319\n",
      "Batch: 12289 Loss: 0.3070641756057739\n",
      "Batch: 12353 Loss: 0.4079042375087738\n",
      "Batch: 12417 Loss: 0.34171977639198303\n",
      "Batch: 12481 Loss: 0.37676510214805603\n",
      "Batch: 12545 Loss: 0.4756125211715698\n",
      "Batch: 12609 Loss: 0.5115348100662231\n",
      "Batch: 12673 Loss: 0.5246996879577637\n",
      "Batch: 12737 Loss: 0.45062196254730225\n",
      "Batch: 12801 Loss: 0.3690303862094879\n",
      "Batch: 12865 Loss: 0.3114556074142456\n",
      "Batch: 12929 Loss: 0.6356488466262817\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(\"Epoch:\", epoch + 1)\n",
    "    for i in range(0, len(encoder_input_data), batch_size):\n",
    "        encoder_input_batch = encoder_input_data[i:i + batch_size]\n",
    "        decoder_input_batch = decoder_input_data[i:i + batch_size]\n",
    "        decoder_target_batch = decoder_target_data[i:i + batch_size]\n",
    "        loss = model.train_on_batch(\n",
    "            [encoder_input_batch, decoder_input_batch],\n",
    "            decoder_target_batch)\n",
    "        print(\"Batch:\", i + 1, \"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5675c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('transliteration_modelFinal2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6f29f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# load the character dictionaries\n",
    "with open('input_char_indices.json', 'r') as f:\n",
    "    input_char_indices = json.load(f)\n",
    "\n",
    "with open('output_char_indices.json', 'r') as f:\n",
    "    output_char_indices = json.load(f)\n",
    "\n",
    "with open('input_indices_char.json', 'r') as f:\n",
    "    input_indices_char = json.load(f)\n",
    "\n",
    "with open('output_indices_char.json', 'r') as f:\n",
    "    output_indices_char = json.load(f)\n",
    "\n",
    "# define the maximum lengths of input and output sequences\n",
    "max_encoder_seq_length = 61\n",
    "max_decoder_seq_length = 62\n",
    "\n",
    "# load the trained model\n",
    "model = load_model('transliteration_modelFinal2.h5')\n",
    "\n",
    "# define the encoder model\n",
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# define the decoder model\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = Input(shape=(256,), name='input_3')\n",
    "decoder_state_input_c = Input(shape=(256,), name='input_4')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "# define a function to perform the actual translation\n",
    "def predict_transliteration(input_word):\n",
    "    # convert the input word to the corresponding sequence of integers\n",
    "    encoder_input_data = np.zeros((1, max_encoder_seq_length, len(input_char_indices)), dtype='float32')\n",
    "    for t, char in enumerate(input_word):\n",
    "        encoder_input_data[0, t, input_char_indices[char]] = 1.\n",
    "    # encode the input sequence\n",
    "    states_value = encoder_model.predict(encoder_input_data)\n",
    "    # create an empty target sequence of length 1\n",
    "    target_seq = np.zeros((1, 1, len(output_char_indices)))\n",
    "    # set the first character of the target sequence as the start-of-sequence character\n",
    "    target_seq[0, 0, output_char_indices[',']] = 1.\n",
    "    # predict the next character until the end-of-sequence character is generated or the maximum length is reached\n",
    "    output_word = ''\n",
    "    for t in range(1, max_decoder_seq_length):\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        # select the most probable character\n",
    "        sampled_output_char = input_indices_char[str(np.argmax(output_tokens[0, -1, :]))]\n",
    "        if sampled_output_char == '\\n':\n",
    "            break\n",
    "        output_word += sampled_output_char\n",
    "        # update the target sequence\n",
    "        target_seq = np.zeros((1, 1, len(output_char_indices)))\n",
    "        target_seq[0, 0, np.argmax(output_tokens[0, -1, :])] = 1.\n",
    "        # update states\n",
    "        states_value = [h, c]\n",
    "    return output_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c114a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
